[2018-06-08 18:02:29  start_training.py:140 -                  <module>()] Starting script
[2018-06-08 18:02:29  start_training.py: 73 -                      main()] We are going for a total of 60attempts.
[2018-06-08 18:02:29  start_training.py: 75 -                      main()] The following initial values will be used:['random', 0, 1, 2, 3, 4].
[2018-06-08 18:02:32  start_training.py: 99 -                      main()] Starting training no.1
[2018-06-08 18:02:32  start_training.py:100 -                      main()] Initial values: random.
[2018-06-08 18:02:32    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:02:32    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:02:32    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:02:32    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:02:32           model.py:138 -       _set_initial_values()] Setting random initial parameters values.
[2018-06-08 18:02:32           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:02:32           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:02:32       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:02:32       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:02:32       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:02:32       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:02:32       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:02:32       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:02:32       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:02:33       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:02:33       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:02:33       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:02:47       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:02:47       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.566485234441916
[2018-06-08 18:02:48       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.2724651479855478
[2018-06-08 18:02:49       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8405071106346652
[2018-06-08 18:02:50       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8326220670856911
[2018-06-08 18:02:51       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9344123964659858
[2018-06-08 18:02:51       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.5997138732024644
[2018-06-08 18:02:52       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7047552093034368
[2018-06-08 18:02:53       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.7851650813383186
[2018-06-08 18:02:54       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9954671164834888
[2018-06-08 18:02:54       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9485643092476203
[2018-06-08 18:02:55       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9926978693729822
[2018-06-08 18:02:56       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9997435030700033
[2018-06-08 18:02:57       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999440421750818
[2018-06-08 18:02:57       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999808740374767
[2018-06-08 18:02:58       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999877361698544
[2018-06-08 18:02:59       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9994457941796149
[2018-06-08 18:03:00       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999977543210177
[2018-06-08 18:03:00       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999987356391794
[2018-06-08 18:03:01       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999995328748181
[2018-06-08 18:03:02       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.999999727133026
[2018-06-08 18:03:03       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999998175742257
[2018-06-08 18:03:03       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999998729708595
[2018-06-08 18:03:04       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999463386823
[2018-06-08 18:03:05       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999590906379
[2018-06-08 18:03:06       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999999800739943
[2018-06-08 18:03:06       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999999910635506
[2018-06-08 18:03:07       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999772369388
[2018-06-08 18:03:08       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999951840075
[2018-06-08 18:03:09       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999981779901
[2018-06-08 18:03:09       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.999999998894421
[2018-06-08 18:03:10       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999999992025718
[2018-06-08 18:03:11       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999995569869
[2018-06-08 18:03:12       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999999996810832
[2018-06-08 18:03:13       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999997302251
[2018-06-08 18:03:13       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.999999999879123
[2018-06-08 18:03:14       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999999111056
[2018-06-08 18:03:15       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999999395791
[2018-06-08 18:03:16       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999999999640464
[2018-06-08 18:03:16       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999999999643062
[2018-06-08 18:03:17       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999999813626
[2018-06-08 18:03:18       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999999999868223
[2018-06-08 18:03:19       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999999999921784
[2018-06-08 18:03:20       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999999930445
[2018-06-08 18:03:20       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999999999954493
[2018-06-08 18:03:21       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999999999971496
[2018-06-08 18:03:22       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999999973456
[2018-06-08 18:03:22       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999999982616
[2018-06-08 18:03:23       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999999999988622
[2018-06-08 18:03:24       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999999999991884
[2018-06-08 18:03:25       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999999999993089
[2018-06-08 18:03:26       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999999999995512
[2018-06-08 18:03:26       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999999999996884
[2018-06-08 18:03:27       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.999999999999772
[2018-06-08 18:03:28       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999999999998163
[2018-06-08 18:03:29       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999999999998777
[2018-06-08 18:03:29       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.999999999999908
[2018-06-08 18:03:30       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999999999308
[2018-06-08 18:03:31       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999999999999464
[2018-06-08 18:03:32       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999999999999636
[2018-06-08 18:03:32       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999999999999697
[2018-06-08 18:03:33       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999999999999762
[2018-06-08 18:03:34       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999999999999802
[2018-06-08 18:03:35       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999999999999869
[2018-06-08 18:03:36       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999999999999923
[2018-06-08 18:03:36       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999999999999928
[2018-06-08 18:03:37       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999999999999968
[2018-06-08 18:03:38       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999999999999938
[2018-06-08 18:03:39       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999999999999963
[2018-06-08 18:03:40       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999999999999999
[2018-06-08 18:03:40       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999999999999971
[2018-06-08 18:03:41       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999999999999981
[2018-06-08 18:03:42       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999999999999963
[2018-06-08 18:03:42       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999999999999966
[2018-06-08 18:03:43       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999999999999999
[2018-06-08 18:03:44       Optimizer.py:490 -                      _run()]   Epoch no. 74: 1.0000000000000002
[2018-06-08 18:03:45       Optimizer.py:490 -                      _run()]   Epoch no. 75: 1.0000000000000004
[2018-06-08 18:03:46       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999999999999994
[2018-06-08 18:03:46       Optimizer.py:490 -                      _run()]   Epoch no. 77: 1.000000000000001
[2018-06-08 18:03:47       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999999999999969
[2018-06-08 18:03:48       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999999999999983
[2018-06-08 18:03:49       Optimizer.py:490 -                      _run()]   Epoch no. 80: 1.000000000000001
[2018-06-08 18:03:49       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999999999999999
[2018-06-08 18:03:50       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999999999999989
[2018-06-08 18:03:51       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999999999999986
[2018-06-08 18:03:52       Optimizer.py:490 -                      _run()]   Epoch no. 84: 1.0000000000000016
[2018-06-08 18:03:52       Optimizer.py:490 -                      _run()]   Epoch no. 85: 1.0000000000000013
[2018-06-08 18:03:53       Optimizer.py:490 -                      _run()]   Epoch no. 86: 1.0000000000000018
[2018-06-08 18:03:54       Optimizer.py:490 -                      _run()]   Epoch no. 87: 1.0000000000000038
[2018-06-08 18:03:55       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999999999999926
[2018-06-08 18:03:55       Optimizer.py:490 -                      _run()]   Epoch no. 89: 1.0000000000000013
[2018-06-08 18:03:56       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.999999999999997
[2018-06-08 18:03:57       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999999999999959
[2018-06-08 18:03:58       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999999999999968
[2018-06-08 18:03:59       Optimizer.py:490 -                      _run()]   Epoch no. 93: 1.0000000000000033
[2018-06-08 18:03:59       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.999999999999998
[2018-06-08 18:04:00       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999999999999999
[2018-06-08 18:04:01       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999999999999993
[2018-06-08 18:04:02       Optimizer.py:490 -                      _run()]   Epoch no. 97: 1.0000000000000018
[2018-06-08 18:04:03       Optimizer.py:490 -                      _run()]   Epoch no. 98: 1.000000000000003
[2018-06-08 18:04:03       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999999999999958
[2018-06-08 18:04:03       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:04:03       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:04:03       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:04:03       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_1.pickle"
[2018-06-08 18:04:03  start_training.py:128 -                      main()] Fidelity obtained: 0.999999999999995
[2018-06-08 18:04:06  start_training.py: 99 -                      main()] Starting training no.2
[2018-06-08 18:04:06  start_training.py:100 -                      main()] Initial values: random.
[2018-06-08 18:04:06    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:04:06    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:04:06    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:04:06    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:04:06           model.py:138 -       _set_initial_values()] Setting random initial parameters values.
[2018-06-08 18:04:06           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:04:06           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:04:06       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:04:06       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:04:06       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:04:06       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:04:06       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:04:06       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:04:06       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:04:06       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:04:06       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:04:06       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:04:10       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:04:11       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.4671151805520889
[2018-06-08 18:04:11       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.2417032764317608
[2018-06-08 18:04:12       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7958315264107935
[2018-06-08 18:04:13       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8415803810582697
[2018-06-08 18:04:14       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8657034456788145
[2018-06-08 18:04:14       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9538581719517342
[2018-06-08 18:04:15       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9288958158588799
[2018-06-08 18:04:16       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9169112119197781
[2018-06-08 18:04:17       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9112346734645698
[2018-06-08 18:04:17       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8909375751660822
[2018-06-08 18:04:18       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9007584734002202
[2018-06-08 18:04:19       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9515779046239154
[2018-06-08 18:04:20       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8511819399326761
[2018-06-08 18:04:21       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9562165167473168
[2018-06-08 18:04:21       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9637400194712523
[2018-06-08 18:04:22       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9537074167662418
[2018-06-08 18:04:23       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9604321223560226
[2018-06-08 18:04:24       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9658924638255455
[2018-06-08 18:04:25       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9319256762019584
[2018-06-08 18:04:26       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9579470483170026
[2018-06-08 18:04:26       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9350814360592088
[2018-06-08 18:04:27       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9609055823323206
[2018-06-08 18:04:28       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9628987958085935
[2018-06-08 18:04:29       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9610250833274947
[2018-06-08 18:04:30       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9599574846812814
[2018-06-08 18:04:30       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9516854998413937
[2018-06-08 18:04:31       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9564877887882157
[2018-06-08 18:04:32       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9536311474664518
[2018-06-08 18:04:33       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9332293717543878
[2018-06-08 18:04:34       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9583534705824924
[2018-06-08 18:04:34       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9650291753523014
[2018-06-08 18:04:35       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9671297158560549
[2018-06-08 18:04:36       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9648997595887343
[2018-06-08 18:04:37       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9660799829111306
[2018-06-08 18:04:38       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9623434374964215
[2018-06-08 18:04:39       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9575666455656627
[2018-06-08 18:04:39       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9615403318599239
[2018-06-08 18:04:40       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.960295720048427
[2018-06-08 18:04:41       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9503850267229275
[2018-06-08 18:04:42       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9535170963618412
[2018-06-08 18:04:43       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9634580658971484
[2018-06-08 18:04:43       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9568834939723875
[2018-06-08 18:04:44       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9638143616288727
[2018-06-08 18:04:45       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.963833369015662
[2018-06-08 18:04:46       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9661585797180072
[2018-06-08 18:04:47       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9641421096942031
[2018-06-08 18:04:48       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9663893022189817
[2018-06-08 18:04:48       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9653242863583015
[2018-06-08 18:04:49       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9665406832872905
[2018-06-08 18:04:50       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9660429474414322
[2018-06-08 18:04:51       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.954501521075082
[2018-06-08 18:04:52       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9614842837378227
[2018-06-08 18:04:52       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.964261324520514
[2018-06-08 18:04:53       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.964098144017789
[2018-06-08 18:04:54       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9643336517181154
[2018-06-08 18:04:55       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9608050680617629
[2018-06-08 18:04:56       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9628881939120766
[2018-06-08 18:04:56       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9617912573264212
[2018-06-08 18:04:57       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9621150970294292
[2018-06-08 18:04:58       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9594862782305067
[2018-06-08 18:04:59       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9646214125001069
[2018-06-08 18:05:00       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.967765943769681
[2018-06-08 18:05:00       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9660305618249322
[2018-06-08 18:05:01       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9661605098404482
[2018-06-08 18:05:02       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9656888037594124
[2018-06-08 18:05:03       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.966174031544937
[2018-06-08 18:05:04       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9664246689785643
[2018-06-08 18:05:04       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9668047269733109
[2018-06-08 18:05:05       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9666222321347897
[2018-06-08 18:05:06       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9664396376821212
[2018-06-08 18:05:07       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9651563120239989
[2018-06-08 18:05:08       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9672194445352109
[2018-06-08 18:05:09       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.96586517850043
[2018-06-08 18:05:09       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9652214094273599
[2018-06-08 18:05:10       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9614503958275408
[2018-06-08 18:05:11       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9615041138293686
[2018-06-08 18:05:12       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.964820075822122
[2018-06-08 18:05:12       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9642882567353891
[2018-06-08 18:05:13       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9667170946572657
[2018-06-08 18:05:14       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9664613468117301
[2018-06-08 18:05:15       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9644578950502095
[2018-06-08 18:05:15       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9654036928767641
[2018-06-08 18:05:16       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9664807249588131
[2018-06-08 18:05:17       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9635599430598633
[2018-06-08 18:05:18       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.966240379456369
[2018-06-08 18:05:18       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9633320316249382
[2018-06-08 18:05:19       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.965841055298932
[2018-06-08 18:05:20       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9665802140994306
[2018-06-08 18:05:21       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9673264958048899
[2018-06-08 18:05:21       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9675170484637141
[2018-06-08 18:05:22       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9656257356570238
[2018-06-08 18:05:23       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9670427455075451
[2018-06-08 18:05:24       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9666737072313755
[2018-06-08 18:05:24       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9649516890630365
[2018-06-08 18:05:25       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9655191309912987
[2018-06-08 18:05:26       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9676504235637285
[2018-06-08 18:05:26       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9676207916624904
[2018-06-08 18:05:27       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9663740176512777
[2018-06-08 18:05:28       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9663840922548453
[2018-06-08 18:05:29       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9679670686800341
[2018-06-08 18:05:29       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:05:29       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:05:29       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:05:29       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_2.pickle"
[2018-06-08 18:05:29  start_training.py:128 -                      main()] Fidelity obtained: 0.9671533022551979
[2018-06-08 18:05:31  start_training.py: 99 -                      main()] Starting training no.3
[2018-06-08 18:05:31  start_training.py:100 -                      main()] Initial values: random.
[2018-06-08 18:05:31    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:05:31    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:05:31    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:05:31    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:05:31           model.py:138 -       _set_initial_values()] Setting random initial parameters values.
[2018-06-08 18:05:32           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:05:32           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:05:32       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:05:32       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:05:32       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:05:32       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:05:32       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:05:32       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:05:32       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:05:32       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:05:32       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:05:32       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:05:36       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:05:36       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.40924084945142175
[2018-06-08 18:05:37       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8242428052752827
[2018-06-08 18:05:38       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8936683961548393
[2018-06-08 18:05:39       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9943375252733873
[2018-06-08 18:05:40       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999955687032
[2018-06-08 18:05:40       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999993896401048
[2018-06-08 18:05:41       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999999891692
[2018-06-08 18:05:42       Optimizer.py:490 -                      _run()]   Epoch no. 7: 1.0000000000000004
[2018-06-08 18:05:43       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999999999994
[2018-06-08 18:05:44       Optimizer.py:490 -                      _run()]   Epoch no. 9: 1.0000000000000002
[2018-06-08 18:05:44       Optimizer.py:490 -                      _run()]   Epoch no. 10: 1.0
[2018-06-08 18:05:44       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:05:44       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:05:44       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:05:44       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:05:44       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_3.pickle"
[2018-06-08 18:05:44  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 18:05:47  start_training.py: 99 -                      main()] Starting training no.4
[2018-06-08 18:05:47  start_training.py:100 -                      main()] Initial values: random.
[2018-06-08 18:05:47    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:05:47    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:05:47    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:05:47    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:05:47           model.py:138 -       _set_initial_values()] Setting random initial parameters values.
[2018-06-08 18:05:47           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:05:47           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:05:47       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:05:47       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:05:47       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:05:47       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:05:47       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:05:47       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:05:47       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:05:48       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:05:48       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:05:48       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:05:51       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:05:52       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6641299030470585
[2018-06-08 18:05:53       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.34640676747482496
[2018-06-08 18:05:54       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9646663344267077
[2018-06-08 18:05:54       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999787832189349
[2018-06-08 18:05:55       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999991893
[2018-06-08 18:05:56       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0000000000000002
[2018-06-08 18:05:57       Optimizer.py:490 -                      _run()]   Epoch no. 6: 1.0000000000000002
[2018-06-08 18:05:57       Optimizer.py:490 -                      _run()]   Epoch no. 7: 1.0
[2018-06-08 18:05:57       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:05:57       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:05:57       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:05:57       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:05:57       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_4.pickle"
[2018-06-08 18:05:57  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 18:06:00  start_training.py: 99 -                      main()] Starting training no.5
[2018-06-08 18:06:00  start_training.py:100 -                      main()] Initial values: random.
[2018-06-08 18:06:00    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:06:00    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:06:00    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:06:00    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:06:00           model.py:138 -       _set_initial_values()] Setting random initial parameters values.
[2018-06-08 18:06:00           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:06:00           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:06:00       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:06:00       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:06:00       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:06:00       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:06:00       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:06:00       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:06:00       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:06:00       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:06:00       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:06:00       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:06:04       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:06:05       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.413376617625584
[2018-06-08 18:06:05       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.4050313096596549
[2018-06-08 18:06:06       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.30380271876990506
[2018-06-08 18:06:07       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7717005700881487
[2018-06-08 18:06:08       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9157799840249217
[2018-06-08 18:06:09       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8844262142945907
[2018-06-08 18:06:09       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8418058118116677
[2018-06-08 18:06:10       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8701639076385073
[2018-06-08 18:06:11       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8974868618955274
[2018-06-08 18:06:12       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9161135672601649
[2018-06-08 18:06:12       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9048483062503802
[2018-06-08 18:06:13       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9220147980850671
[2018-06-08 18:06:14       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8588392486335057
[2018-06-08 18:06:15       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9161478923676504
[2018-06-08 18:06:16       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.907843744395413
[2018-06-08 18:06:16       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8836908026551086
[2018-06-08 18:06:17       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9130515139743848
[2018-06-08 18:06:18       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9104317966293369
[2018-06-08 18:06:19       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.926456309351639
[2018-06-08 18:06:19       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9033632201753328
[2018-06-08 18:06:20       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9295409814244041
[2018-06-08 18:06:21       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9301239324678242
[2018-06-08 18:06:22       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9143903584577571
[2018-06-08 18:06:23       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9191203192574042
[2018-06-08 18:06:23       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9277367115110725
[2018-06-08 18:06:24       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9246714807298695
[2018-06-08 18:06:25       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9127799973319456
[2018-06-08 18:06:26       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9304570112572657
[2018-06-08 18:06:26       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.934180382348937
[2018-06-08 18:06:27       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9160722109595862
[2018-06-08 18:06:28       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9297002164676721
[2018-06-08 18:06:29       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9172341499961891
[2018-06-08 18:06:29       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.928761127403
[2018-06-08 18:06:30       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9286128960963531
[2018-06-08 18:06:31       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9307907082959872
[2018-06-08 18:06:32       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9227938308162212
[2018-06-08 18:06:33       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9329469107879703
[2018-06-08 18:06:33       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9286631466910901
[2018-06-08 18:06:34       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9295443930406784
[2018-06-08 18:06:35       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9317083451090022
[2018-06-08 18:06:36       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9313895146810007
[2018-06-08 18:06:36       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9316733416040658
[2018-06-08 18:06:37       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9282818235271322
[2018-06-08 18:06:38       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9300276744792437
[2018-06-08 18:06:39       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9317387732181921
[2018-06-08 18:06:40       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9305843132535321
[2018-06-08 18:06:40       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9319408237376028
[2018-06-08 18:06:41       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9240962752075619
[2018-06-08 18:06:42       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9246277689303404
[2018-06-08 18:06:43       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.93244183822874
[2018-06-08 18:06:43       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9331086890585137
[2018-06-08 18:06:44       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9268811778467526
[2018-06-08 18:06:45       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9226718650884697
[2018-06-08 18:06:46       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9323153221634267
[2018-06-08 18:06:47       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9316062661706769
[2018-06-08 18:06:47       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9309624234393765
[2018-06-08 18:06:48       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9287897392444044
[2018-06-08 18:06:49       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9296942700837632
[2018-06-08 18:06:50       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.930692890169545
[2018-06-08 18:06:50       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9335362018675408
[2018-06-08 18:06:51       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9325189956180965
[2018-06-08 18:06:52       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9282979766813659
[2018-06-08 18:06:53       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9338944480416653
[2018-06-08 18:06:53       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9336538529949313
[2018-06-08 18:06:54       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9319129783638083
[2018-06-08 18:06:55       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9264308560634673
[2018-06-08 18:06:56       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9332872373252988
[2018-06-08 18:06:56       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9358268610454102
[2018-06-08 18:06:57       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9324424931724211
[2018-06-08 18:06:58       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.933436319585201
[2018-06-08 18:06:59       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9340668983277438
[2018-06-08 18:06:59       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.931159900663528
[2018-06-08 18:07:00       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9304356251838118
[2018-06-08 18:07:01       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9301853993997233
[2018-06-08 18:07:02       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9323206144377386
[2018-06-08 18:07:03       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9356766665872653
[2018-06-08 18:07:03       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9346039834620421
[2018-06-08 18:07:04       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9309069629809819
[2018-06-08 18:07:05       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9338617116139374
[2018-06-08 18:07:05       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9326675701514843
[2018-06-08 18:07:06       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9293053055093324
[2018-06-08 18:07:07       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9347263172078573
[2018-06-08 18:07:08       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.930706221317094
[2018-06-08 18:07:09       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9319417051592374
[2018-06-08 18:07:09       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9351964690907281
[2018-06-08 18:07:10       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9340294980977233
[2018-06-08 18:07:11       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9339327497214915
[2018-06-08 18:07:12       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9345490800380069
[2018-06-08 18:07:12       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9343489784295227
[2018-06-08 18:07:13       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9349858723218185
[2018-06-08 18:07:14       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.924440683828465
[2018-06-08 18:07:15       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9284896401092209
[2018-06-08 18:07:15       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9348840521506879
[2018-06-08 18:07:16       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9334181567394145
[2018-06-08 18:07:17       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9342214331499735
[2018-06-08 18:07:18       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9351563488911053
[2018-06-08 18:07:18       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9347034724776254
[2018-06-08 18:07:19       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.934184432402662
[2018-06-08 18:07:20       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9276217657455982
[2018-06-08 18:07:21       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9349211785587493
[2018-06-08 18:07:21       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:07:21       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:07:21       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:07:21       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_5.pickle"
[2018-06-08 18:07:21  start_training.py:128 -                      main()] Fidelity obtained: 0.9361036262076818
[2018-06-08 18:07:23  start_training.py: 99 -                      main()] Starting training no.6
[2018-06-08 18:07:23  start_training.py:100 -                      main()] Initial values: random.
[2018-06-08 18:07:23    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:07:23    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:07:23    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:07:23    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:07:23           model.py:138 -       _set_initial_values()] Setting random initial parameters values.
[2018-06-08 18:07:24           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:07:24           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:07:24       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:07:24       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:07:24       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:07:24       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:07:24       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:07:24       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:07:24       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:07:24       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:07:24       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:07:24       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:07:27       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:07:28       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7784318658824995
[2018-06-08 18:07:29       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7485130746836128
[2018-06-08 18:07:30       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7265049545789146
[2018-06-08 18:07:30       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8253626231529114
[2018-06-08 18:07:31       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8713125010011521
[2018-06-08 18:07:32       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8657612557038178
[2018-06-08 18:07:32       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8535701896932195
[2018-06-08 18:07:33       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8717829207384347
[2018-06-08 18:07:34       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8831229091396877
[2018-06-08 18:07:35       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8729332796051656
[2018-06-08 18:07:35       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8571636094591212
[2018-06-08 18:07:36       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8275384184998592
[2018-06-08 18:07:37       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8685565552939213
[2018-06-08 18:07:37       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8834491289879186
[2018-06-08 18:07:38       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8400353240750122
[2018-06-08 18:07:39       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8900411808447793
[2018-06-08 18:07:40       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8778325573150413
[2018-06-08 18:07:41       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8678115838983121
[2018-06-08 18:07:41       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8703361348581531
[2018-06-08 18:07:42       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8531711622628643
[2018-06-08 18:07:43       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8838292600793798
[2018-06-08 18:07:43       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.883963653078233
[2018-06-08 18:07:44       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8761470671589034
[2018-06-08 18:07:45       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.875019499355349
[2018-06-08 18:07:46       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8898169274827561
[2018-06-08 18:07:46       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8807560901707671
[2018-06-08 18:07:47       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8900578220295751
[2018-06-08 18:07:48       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8782447520974693
[2018-06-08 18:07:49       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8889383900554166
[2018-06-08 18:07:49       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8904384675557016
[2018-06-08 18:07:50       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8723960418593905
[2018-06-08 18:07:51       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8911092130548985
[2018-06-08 18:07:52       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8921982374827246
[2018-06-08 18:07:52       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8823419141866422
[2018-06-08 18:07:53       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8855547358975734
[2018-06-08 18:07:54       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8890658335552984
[2018-06-08 18:07:55       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.884161490543612
[2018-06-08 18:07:55       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8924939269272586
[2018-06-08 18:07:56       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8927568105657577
[2018-06-08 18:07:57       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8883771126710822
[2018-06-08 18:07:58       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8902897241153305
[2018-06-08 18:07:58       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.885639556262575
[2018-06-08 18:07:59       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8848180022172459
[2018-06-08 18:08:00       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8866811872867438
[2018-06-08 18:08:01       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8919267685267264
[2018-06-08 18:08:01       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8886794749626801
[2018-06-08 18:08:02       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8876843160987898
[2018-06-08 18:08:03       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8918982396650945
[2018-06-08 18:08:04       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8905654312530015
[2018-06-08 18:08:04       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8835877981582014
[2018-06-08 18:08:05       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8672892957574266
[2018-06-08 18:08:06       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8817937621996282
[2018-06-08 18:08:07       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8893289295248283
[2018-06-08 18:08:07       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8914419346654064
[2018-06-08 18:08:08       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8818742051941802
[2018-06-08 18:08:09       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.889024192977914
[2018-06-08 18:08:10       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8860154112244998
[2018-06-08 18:08:10       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8859522687162861
[2018-06-08 18:08:11       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8847966120691702
[2018-06-08 18:08:12       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8892273550486174
[2018-06-08 18:08:13       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8855577192781119
[2018-06-08 18:08:14       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.889597421343831
[2018-06-08 18:08:14       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8783329495537676
[2018-06-08 18:08:15       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8890731751627071
[2018-06-08 18:08:16       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8889967761202756
[2018-06-08 18:08:16       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8908210009634893
[2018-06-08 18:08:17       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.892434083080106
[2018-06-08 18:08:18       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8934052740428611
[2018-06-08 18:08:18       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8911386848984941
[2018-06-08 18:08:19       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.893294161972232
[2018-06-08 18:08:20       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8894525138757154
[2018-06-08 18:08:21       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8931281399542719
[2018-06-08 18:08:21       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8936094910319874
[2018-06-08 18:08:22       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8926916439004454
[2018-06-08 18:08:23       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8917834870023369
[2018-06-08 18:08:24       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8925743474443262
[2018-06-08 18:08:24       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8912789783710179
[2018-06-08 18:08:25       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8936830268436574
[2018-06-08 18:08:26       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8931842866557695
[2018-06-08 18:08:27       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8904676255269333
[2018-06-08 18:08:27       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8887322109604294
[2018-06-08 18:08:28       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8902924402747575
[2018-06-08 18:08:29       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.894056587481591
[2018-06-08 18:08:30       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8837067877743752
[2018-06-08 18:08:30       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8929545770121048
[2018-06-08 18:08:31       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8934784483667292
[2018-06-08 18:08:32       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.893051945641864
[2018-06-08 18:08:32       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8933549216064611
[2018-06-08 18:08:33       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8906781947073645
[2018-06-08 18:08:34       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8909643633214952
[2018-06-08 18:08:35       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8918421347149561
[2018-06-08 18:08:35       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8915496757421981
[2018-06-08 18:08:36       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8920266195673792
[2018-06-08 18:08:37       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8945364275889139
[2018-06-08 18:08:38       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8886196232285387
[2018-06-08 18:08:38       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8931622438383024
[2018-06-08 18:08:39       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8930922016372531
[2018-06-08 18:08:40       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8943600346172197
[2018-06-08 18:08:41       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8945544234457466
[2018-06-08 18:08:41       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8900416949187283
[2018-06-08 18:08:41       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:08:41       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:08:41       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:08:41       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_6.pickle"
[2018-06-08 18:08:41  start_training.py:128 -                      main()] Fidelity obtained: 0.8891878849594543
[2018-06-08 18:08:44  start_training.py: 99 -                      main()] Starting training no.7
[2018-06-08 18:08:44  start_training.py:100 -                      main()] Initial values: random.
[2018-06-08 18:08:44    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:08:44    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:08:44    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:08:44    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:08:44           model.py:138 -       _set_initial_values()] Setting random initial parameters values.
[2018-06-08 18:08:44           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:08:44           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:08:44       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:08:44       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:08:44       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:08:44       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:08:44       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:08:44       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:08:44       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:08:44       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:08:44       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:08:45       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:08:48       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:08:49       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.4966883283715302
[2018-06-08 18:08:50       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.927021660135305
[2018-06-08 18:08:50       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.5702195946420074
[2018-06-08 18:08:51       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9582014251634324
[2018-06-08 18:08:52       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8358523977489009
[2018-06-08 18:08:53       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9338790021886646
[2018-06-08 18:08:53       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9502783202251956
[2018-06-08 18:08:54       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9696560001246667
[2018-06-08 18:08:55       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9672293606817464
[2018-06-08 18:08:56       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9837151384940607
[2018-06-08 18:08:57       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9786722933495785
[2018-06-08 18:08:57       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9828928883807585
[2018-06-08 18:08:58       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9732848299738296
[2018-06-08 18:08:59       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9845811762169505
[2018-06-08 18:09:00       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9785922368796917
[2018-06-08 18:09:01       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9831322450757004
[2018-06-08 18:09:01       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9831819394357653
[2018-06-08 18:09:02       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9832156155175268
[2018-06-08 18:09:03       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9814920813048619
[2018-06-08 18:09:03       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9842303655910996
[2018-06-08 18:09:04       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9808260739787903
[2018-06-08 18:09:05       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9818947347596871
[2018-06-08 18:09:06       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9796144525173861
[2018-06-08 18:09:07       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9841233229940581
[2018-06-08 18:09:07       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9850919505478644
[2018-06-08 18:09:08       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9846650455300374
[2018-06-08 18:09:09       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9823048741082023
[2018-06-08 18:09:10       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9844813749014779
[2018-06-08 18:09:10       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.984880540768042
[2018-06-08 18:09:11       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9787612882207916
[2018-06-08 18:09:12       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9842679999221098
[2018-06-08 18:09:13       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.980727138216092
[2018-06-08 18:09:13       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9836818313530415
[2018-06-08 18:09:14       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9837218569384976
[2018-06-08 18:09:15       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.984579755211996
[2018-06-08 18:09:16       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9828642543610907
[2018-06-08 18:09:17       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9845582307514298
[2018-06-08 18:09:17       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9838185227009763
[2018-06-08 18:09:18       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9839410032166832
[2018-06-08 18:09:19       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.984988788889861
[2018-06-08 18:09:20       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9845088515568363
[2018-06-08 18:09:21       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.981280947283491
[2018-06-08 18:09:21       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.985267363898128
[2018-06-08 18:09:22       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9852710441278831
[2018-06-08 18:09:23       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9851445482349571
[2018-06-08 18:09:24       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9854735943819426
[2018-06-08 18:09:24       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9852742087289746
[2018-06-08 18:09:25       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.98497426006262
[2018-06-08 18:09:26       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9848961052452693
[2018-06-08 18:09:27       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.985649620459383
[2018-06-08 18:09:27       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9834933644081919
[2018-06-08 18:09:28       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9848725359214232
[2018-06-08 18:09:29       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.985232072461073
[2018-06-08 18:09:29       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9840359953052971
[2018-06-08 18:09:30       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9840894791161737
[2018-06-08 18:09:31       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9832523998427871
[2018-06-08 18:09:32       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9846710486872748
[2018-06-08 18:09:33       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9841481734782582
[2018-06-08 18:09:33       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9855522693241174
[2018-06-08 18:09:34       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9850462361413546
[2018-06-08 18:09:35       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9853124348244617
[2018-06-08 18:09:36       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9855045840464141
[2018-06-08 18:09:36       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9852108900820449
[2018-06-08 18:09:37       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9849229899920333
[2018-06-08 18:09:38       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9855717027976266
[2018-06-08 18:09:39       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9853600777779947
[2018-06-08 18:09:39       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9846271466210937
[2018-06-08 18:09:40       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9848303158106191
[2018-06-08 18:09:41       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9856303668607292
[2018-06-08 18:09:42       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9854582611130474
[2018-06-08 18:09:42       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9848254189402068
[2018-06-08 18:09:43       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9855620431218486
[2018-06-08 18:09:44       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9847297345809791
[2018-06-08 18:09:45       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9853212439171776
[2018-06-08 18:09:46       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9833887214095117
[2018-06-08 18:09:46       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9849675506299164
[2018-06-08 18:09:47       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9844576025697299
[2018-06-08 18:09:48       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9831995183029233
[2018-06-08 18:09:49       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9852475488891501
[2018-06-08 18:09:50       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9854779911398137
[2018-06-08 18:09:51       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9841073829945539
[2018-06-08 18:09:51       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9852155373551237
[2018-06-08 18:09:52       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9854823738386688
[2018-06-08 18:09:53       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9855001477186736
[2018-06-08 18:09:54       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9849007041670366
[2018-06-08 18:09:55       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9845472010139312
[2018-06-08 18:09:55       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9854964679027831
[2018-06-08 18:09:56       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9840736861083141
[2018-06-08 18:09:57       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.98374733356569
[2018-06-08 18:09:58       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9845951138733119
[2018-06-08 18:09:59       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9857165692071663
[2018-06-08 18:09:59       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9846660093337383
[2018-06-08 18:10:00       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9852847335340347
[2018-06-08 18:10:01       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9856841759676582
[2018-06-08 18:10:02       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9854426643658302
[2018-06-08 18:10:02       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9848346000761952
[2018-06-08 18:10:03       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9853225782978082
[2018-06-08 18:10:04       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9853983942296998
[2018-06-08 18:10:05       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9857643694912749
[2018-06-08 18:10:06       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9843005422501059
[2018-06-08 18:10:06       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:10:06       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:10:06       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:10:06       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_7.pickle"
[2018-06-08 18:10:06  start_training.py:128 -                      main()] Fidelity obtained: 0.9839374340550545
[2018-06-08 18:10:09  start_training.py: 99 -                      main()] Starting training no.8
[2018-06-08 18:10:09  start_training.py:100 -                      main()] Initial values: random.
[2018-06-08 18:10:09    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:10:09    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:10:09    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:10:09    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:10:09           model.py:138 -       _set_initial_values()] Setting random initial parameters values.
[2018-06-08 18:10:09           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:10:09           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:10:09       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:10:09       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:10:09       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:10:09       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:10:09       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:10:09       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:10:09       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:10:09       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:10:09       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:10:09       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:10:13       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:10:13       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8774779448260019
[2018-06-08 18:10:14       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.898403105598813
[2018-06-08 18:10:15       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9501657590743555
[2018-06-08 18:10:16       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9501300530220278
[2018-06-08 18:10:16       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9216025712995439
[2018-06-08 18:10:17       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8901516174693864
[2018-06-08 18:10:18       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9820752588133077
[2018-06-08 18:10:18       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9754657324067039
[2018-06-08 18:10:19       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9818864833438132
[2018-06-08 18:10:20       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9816192105540148
[2018-06-08 18:10:21       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9743233198034136
[2018-06-08 18:10:21       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9803298678698544
[2018-06-08 18:10:22       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9819769971170728
[2018-06-08 18:10:23       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9708066174101709
[2018-06-08 18:10:24       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9784090209360095
[2018-06-08 18:10:24       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9838159798763687
[2018-06-08 18:10:25       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9729150758793571
[2018-06-08 18:10:26       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9814452419200067
[2018-06-08 18:10:26       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9741929523382563
[2018-06-08 18:10:27       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9824016937461812
[2018-06-08 18:10:28       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9763507148256387
[2018-06-08 18:10:29       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9832907585195262
[2018-06-08 18:10:30       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9822811709587872
[2018-06-08 18:10:30       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9823343533833585
[2018-06-08 18:10:31       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9825076167027019
[2018-06-08 18:10:32       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.972544879950812
[2018-06-08 18:10:33       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9802174519632798
[2018-06-08 18:10:33       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9819930658303153
[2018-06-08 18:10:34       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9781215845865373
[2018-06-08 18:10:35       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9827698053059233
[2018-06-08 18:10:35       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9802704203943403
[2018-06-08 18:10:36       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9836047819426311
[2018-06-08 18:10:37       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9827035149284188
[2018-06-08 18:10:38       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9824803680030361
[2018-06-08 18:10:38       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9807281430935952
[2018-06-08 18:10:39       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9834883628718195
[2018-06-08 18:10:40       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9814644329021288
[2018-06-08 18:10:41       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9812467360763528
[2018-06-08 18:10:41       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.982433922545004
[2018-06-08 18:10:42       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.984229245812754
[2018-06-08 18:10:43       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9836996667166217
[2018-06-08 18:10:44       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9828708407443435
[2018-06-08 18:10:45       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9828999300364158
[2018-06-08 18:10:45       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9828323838465917
[2018-06-08 18:10:46       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9840036439038689
[2018-06-08 18:10:47       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9836808178864174
[2018-06-08 18:10:48       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9810324712265163
[2018-06-08 18:10:48       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9820802236744364
[2018-06-08 18:10:49       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9820600326349254
[2018-06-08 18:10:50       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9832904797494736
[2018-06-08 18:10:51       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9839712878114313
[2018-06-08 18:10:51       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9835834674325099
[2018-06-08 18:10:52       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.983548600260405
[2018-06-08 18:10:53       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9842447998607916
[2018-06-08 18:10:53       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9833383637040461
[2018-06-08 18:10:54       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9829927716607049
[2018-06-08 18:10:55       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9833988451371944
[2018-06-08 18:10:55       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9826526849557605
[2018-06-08 18:10:56       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.984182696478322
[2018-06-08 18:10:57       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9838730108611735
[2018-06-08 18:10:58       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.984186961742093
[2018-06-08 18:10:58       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9799986056990371
[2018-06-08 18:10:59       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9834552643497873
[2018-06-08 18:11:00       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.984232150692592
[2018-06-08 18:11:00       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9839589190362504
[2018-06-08 18:11:01       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9825288448997062
[2018-06-08 18:11:02       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9840898327112609
[2018-06-08 18:11:03       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9843958692354933
[2018-06-08 18:11:03       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9838683602179343
[2018-06-08 18:11:04       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9836521381389596
[2018-06-08 18:11:05       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9838785898327528
[2018-06-08 18:11:06       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9833564153657193
[2018-06-08 18:11:06       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9836315833628652
[2018-06-08 18:11:07       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9828883913444753
[2018-06-08 18:11:08       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9838036800718544
[2018-06-08 18:11:09       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9840850995857867
[2018-06-08 18:11:09       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9845832836946851
[2018-06-08 18:11:10       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9841806474882309
[2018-06-08 18:11:11       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9835894166423661
[2018-06-08 18:11:12       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9841858493977265
[2018-06-08 18:11:12       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9841868022749458
[2018-06-08 18:11:13       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9843195621740586
[2018-06-08 18:11:14       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9839315374211395
[2018-06-08 18:11:15       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.984131868336613
[2018-06-08 18:11:15       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9830038324611599
[2018-06-08 18:11:16       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9833788861166497
[2018-06-08 18:11:17       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.984341414454165
[2018-06-08 18:11:17       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9837558334090198
[2018-06-08 18:11:18       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9840951008598957
[2018-06-08 18:11:19       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9842087981818914
[2018-06-08 18:11:20       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9842322172198085
[2018-06-08 18:11:20       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9839079385804124
[2018-06-08 18:11:21       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9833080749697407
[2018-06-08 18:11:22       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.984294840111075
[2018-06-08 18:11:23       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9840126284247246
[2018-06-08 18:11:23       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.98341469759127
[2018-06-08 18:11:24       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9835876392484677
[2018-06-08 18:11:25       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9845001887648204
[2018-06-08 18:11:25       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.984185172457344
[2018-06-08 18:11:26       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9836054637591174
[2018-06-08 18:11:26       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:11:26       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:11:26       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:11:26       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_8.pickle"
[2018-06-08 18:11:26  start_training.py:128 -                      main()] Fidelity obtained: 0.9844553096503112
[2018-06-08 18:11:29  start_training.py: 99 -                      main()] Starting training no.9
[2018-06-08 18:11:29  start_training.py:100 -                      main()] Initial values: random.
[2018-06-08 18:11:29    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:11:29    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:11:29    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:11:29    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:11:29           model.py:138 -       _set_initial_values()] Setting random initial parameters values.
[2018-06-08 18:11:29           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:11:29           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:11:29       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:11:29       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:11:29       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:11:29       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:11:29       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:11:29       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:11:29       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:11:29       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:11:29       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:11:30       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:11:33       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:11:34       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.669298689756798
[2018-06-08 18:11:34       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.4258726715648845
[2018-06-08 18:11:35       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.3038064281929825
[2018-06-08 18:11:36       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9272298787936236
[2018-06-08 18:11:37       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9910719803737716
[2018-06-08 18:11:38       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999040145339709
[2018-06-08 18:11:38       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999968303465816
[2018-06-08 18:11:39       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999999802
[2018-06-08 18:11:40       Optimizer.py:490 -                      _run()]   Epoch no. 8: 1.0
[2018-06-08 18:11:40       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:11:40       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:11:40       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:11:40       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:11:40       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_9.pickle"
[2018-06-08 18:11:40  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000002
[2018-06-08 18:11:43  start_training.py: 99 -                      main()] Starting training no.10
[2018-06-08 18:11:43  start_training.py:100 -                      main()] Initial values: random.
[2018-06-08 18:11:43    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:11:43    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:11:43    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:11:43    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:11:43           model.py:138 -       _set_initial_values()] Setting random initial parameters values.
[2018-06-08 18:11:43           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:11:43           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:11:43       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:11:43       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:11:43       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:11:43       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:11:43       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:11:43       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:11:43       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:11:43       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:11:43       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:11:43       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:11:47       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:11:48       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.24181628109566225
[2018-06-08 18:11:48       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5521673412965973
[2018-06-08 18:11:49       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.40085633544886823
[2018-06-08 18:11:50       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8362381926945649
[2018-06-08 18:11:50       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7538360494448355
[2018-06-08 18:11:51       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8069365573311432
[2018-06-08 18:11:52       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8379109682672328
[2018-06-08 18:11:53       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8481657104334357
[2018-06-08 18:11:53       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.7942487969135879
[2018-06-08 18:11:54       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.761167400569643
[2018-06-08 18:11:55       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.7972742695578314
[2018-06-08 18:11:56       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8618655627913404
[2018-06-08 18:11:56       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8888354327327131
[2018-06-08 18:11:57       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8602766588370023
[2018-06-08 18:11:58       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8730896511167707
[2018-06-08 18:11:58       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.866146605420218
[2018-06-08 18:11:59       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8614961577223794
[2018-06-08 18:12:00       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.880863417418706
[2018-06-08 18:12:01       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.880491372734336
[2018-06-08 18:12:01       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8673153794789539
[2018-06-08 18:12:02       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8681553573883843
[2018-06-08 18:12:03       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8640062610801698
[2018-06-08 18:12:03       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.880416427603318
[2018-06-08 18:12:04       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8712131885801645
[2018-06-08 18:12:05       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8607943792515794
[2018-06-08 18:12:06       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8752586358537994
[2018-06-08 18:12:06       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8725592126706643
[2018-06-08 18:12:07       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8554746405359447
[2018-06-08 18:12:08       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8762249017212546
[2018-06-08 18:12:08       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8615502437001124
[2018-06-08 18:12:09       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8911454584673129
[2018-06-08 18:12:10       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8583479036486429
[2018-06-08 18:12:11       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8870475098774306
[2018-06-08 18:12:11       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8900915932098878
[2018-06-08 18:12:12       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8895797709346444
[2018-06-08 18:12:13       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8811008126089497
[2018-06-08 18:12:13       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8911391774613253
[2018-06-08 18:12:14       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8895111901994948
[2018-06-08 18:12:15       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8788551968836009
[2018-06-08 18:12:16       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8772528571338989
[2018-06-08 18:12:16       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8821544559583124
[2018-06-08 18:12:17       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.885811999296233
[2018-06-08 18:12:18       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.884733009770345
[2018-06-08 18:12:19       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8862714263463638
[2018-06-08 18:12:19       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8863309782124048
[2018-06-08 18:12:20       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8861869040382514
[2018-06-08 18:12:21       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8737977804997291
[2018-06-08 18:12:21       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8740361116728063
[2018-06-08 18:12:22       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8899018574293984
[2018-06-08 18:12:23       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8886907573649581
[2018-06-08 18:12:23       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8846922904357705
[2018-06-08 18:12:24       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8868398746098655
[2018-06-08 18:12:25       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8862190313629814
[2018-06-08 18:12:26       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8876315644368448
[2018-06-08 18:12:26       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8901483683399358
[2018-06-08 18:12:27       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.891224050735644
[2018-06-08 18:12:28       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8841677941855477
[2018-06-08 18:12:29       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8865809491845884
[2018-06-08 18:12:29       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8918157346865994
[2018-06-08 18:12:30       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8895444598374683
[2018-06-08 18:12:31       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8885675826592118
[2018-06-08 18:12:32       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8891309723145788
[2018-06-08 18:12:33       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8849085810654763
[2018-06-08 18:12:33       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8880917612773633
[2018-06-08 18:12:34       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8876430288326511
[2018-06-08 18:12:35       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8883326781129047
[2018-06-08 18:12:35       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8916799320510921
[2018-06-08 18:12:36       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8841412692919167
[2018-06-08 18:12:37       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8906787922079222
[2018-06-08 18:12:38       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8924213414127857
[2018-06-08 18:12:38       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8849997232963078
[2018-06-08 18:12:39       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.893505991690597
[2018-06-08 18:12:40       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8853803307863356
[2018-06-08 18:12:41       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8920963145779044
[2018-06-08 18:12:41       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8907532503990359
[2018-06-08 18:12:42       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8893786167354097
[2018-06-08 18:12:43       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8914232830214424
[2018-06-08 18:12:44       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.885100265680844
[2018-06-08 18:12:44       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8927808603964773
[2018-06-08 18:12:45       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8908006075296663
[2018-06-08 18:12:46       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8926049821334715
[2018-06-08 18:12:46       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8857285676056844
[2018-06-08 18:12:47       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8830471401174684
[2018-06-08 18:12:48       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8820256040417308
[2018-06-08 18:12:49       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8897838960572452
[2018-06-08 18:12:49       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8919137754979813
[2018-06-08 18:12:50       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8860358588333556
[2018-06-08 18:12:51       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8888791709653635
[2018-06-08 18:12:51       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8886584004605323
[2018-06-08 18:12:52       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8919936580116498
[2018-06-08 18:12:53       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8915967389708949
[2018-06-08 18:12:54       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8901884471740913
[2018-06-08 18:12:54       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.887641485407312
[2018-06-08 18:12:55       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8906618379212747
[2018-06-08 18:12:56       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8902730343023414
[2018-06-08 18:12:57       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8857791975068801
[2018-06-08 18:12:58       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8882780145964125
[2018-06-08 18:12:58       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8903271521761179
[2018-06-08 18:12:59       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8889907330035295
[2018-06-08 18:13:00       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8895451266248205
[2018-06-08 18:13:00       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:13:00       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:13:00       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:13:00       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_10.pickle"
[2018-06-08 18:13:00  start_training.py:128 -                      main()] Fidelity obtained: 0.8897241233812619
[2018-06-08 18:13:03  start_training.py: 99 -                      main()] Starting training no.11
[2018-06-08 18:13:03  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 18:13:03    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:13:03    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:13:03    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:13:03    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:13:03           model.py:140 -       _set_initial_values()] Initial parameters values: 0.
[2018-06-08 18:13:03           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:13:03           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:13:03       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:13:03       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:13:03       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:13:03       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:13:03       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:13:03       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:13:03       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:13:03       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:13:03       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:13:03       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:13:07       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:13:07       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5332871283392319
[2018-06-08 18:13:08       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6126451805193301
[2018-06-08 18:13:09       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.5942893153446778
[2018-06-08 18:13:10       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.6171258440844749
[2018-06-08 18:13:10       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.521331752718785
[2018-06-08 18:13:11       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.7349050805652111
[2018-06-08 18:13:12       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8700464031439727
[2018-06-08 18:13:13       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8968006698375038
[2018-06-08 18:13:13       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9782214839639264
[2018-06-08 18:13:14       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9682157015057439
[2018-06-08 18:13:15       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9782481549019387
[2018-06-08 18:13:16       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9672231451760155
[2018-06-08 18:13:16       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9655554741247836
[2018-06-08 18:13:17       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9458407977738327
[2018-06-08 18:13:18       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.983637716895407
[2018-06-08 18:13:18       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9812445816566637
[2018-06-08 18:13:19       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9758614634054473
[2018-06-08 18:13:20       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9812709112652455
[2018-06-08 18:13:21       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9678514823241738
[2018-06-08 18:13:21       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9786710887003293
[2018-06-08 18:13:22       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9812914564096087
[2018-06-08 18:13:23       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9836340874278252
[2018-06-08 18:13:23       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.982456929381806
[2018-06-08 18:13:24       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9849055717590783
[2018-06-08 18:13:25       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9845035945407961
[2018-06-08 18:13:26       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9821282950832283
[2018-06-08 18:13:26       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.983184185494116
[2018-06-08 18:13:27       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9818317402928243
[2018-06-08 18:13:28       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9835820506924087
[2018-06-08 18:13:29       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9822946349710111
[2018-06-08 18:13:29       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9837891830269427
[2018-06-08 18:13:30       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9808286855046723
[2018-06-08 18:13:31       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9809039518120118
[2018-06-08 18:13:32       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9825072984592669
[2018-06-08 18:13:32       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9847931836216768
[2018-06-08 18:13:33       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9775099482132835
[2018-06-08 18:13:34       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9841614332351764
[2018-06-08 18:13:35       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9844851017190192
[2018-06-08 18:13:35       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9838941643425128
[2018-06-08 18:13:36       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9848492471201088
[2018-06-08 18:13:37       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9842138938675441
[2018-06-08 18:13:37       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9848707446854799
[2018-06-08 18:13:38       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9845679035921593
[2018-06-08 18:13:38       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9847935283930259
[2018-06-08 18:13:39       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.98423348651892
[2018-06-08 18:13:40       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9840479302000794
[2018-06-08 18:13:41       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9838041629073935
[2018-06-08 18:13:41       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9811988929391774
[2018-06-08 18:13:42       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9840282032234436
[2018-06-08 18:13:43       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9845622336160932
[2018-06-08 18:13:43       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9846577077186883
[2018-06-08 18:13:44       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9830567200692358
[2018-06-08 18:13:45       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9847633948450775
[2018-06-08 18:13:46       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9853392858987183
[2018-06-08 18:13:46       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9841866616723436
[2018-06-08 18:13:47       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9838957032924153
[2018-06-08 18:13:48       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9850695004962755
[2018-06-08 18:13:49       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9845163627345113
[2018-06-08 18:13:49       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9845805513489952
[2018-06-08 18:13:50       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9848396967507917
[2018-06-08 18:13:50       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9840710742977155
[2018-06-08 18:13:51       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9833572717637183
[2018-06-08 18:13:52       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9854228743540788
[2018-06-08 18:13:53       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9843511866826765
[2018-06-08 18:13:53       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9831478287717418
[2018-06-08 18:13:54       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9853193851628912
[2018-06-08 18:13:55       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9853919702391599
[2018-06-08 18:13:55       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9851837829332217
[2018-06-08 18:13:56       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9848766909447393
[2018-06-08 18:13:57       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.984338050362675
[2018-06-08 18:13:57       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9849792997012773
[2018-06-08 18:13:58       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9835662319832091
[2018-06-08 18:13:59       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9851613273287311
[2018-06-08 18:14:00       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9853211213070406
[2018-06-08 18:14:00       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9842319716299113
[2018-06-08 18:14:01       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9848977737223242
[2018-06-08 18:14:02       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9852891341580292
[2018-06-08 18:14:02       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.985268994111713
[2018-06-08 18:14:03       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9844059460787363
[2018-06-08 18:14:04       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9852799165823285
[2018-06-08 18:14:05       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9837003653595977
[2018-06-08 18:14:05       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.984001544223824
[2018-06-08 18:14:06       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9844435233572151
[2018-06-08 18:14:06       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9852533552068928
[2018-06-08 18:14:07       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.983537173381905
[2018-06-08 18:14:08       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.983031866632691
[2018-06-08 18:14:08       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9850015783086775
[2018-06-08 18:14:09       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9848240855375898
[2018-06-08 18:14:10       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9852701152101847
[2018-06-08 18:14:11       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9852167616587737
[2018-06-08 18:14:11       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9849365420740775
[2018-06-08 18:14:12       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9848333235324459
[2018-06-08 18:14:13       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9844652952633681
[2018-06-08 18:14:14       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9846506968299881
[2018-06-08 18:14:14       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9848227189893315
[2018-06-08 18:14:15       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.985357557943413
[2018-06-08 18:14:16       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9851046606624465
[2018-06-08 18:14:17       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9849578201280812
[2018-06-08 18:14:18       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9850274036911655
[2018-06-08 18:14:18       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9844654741923509
[2018-06-08 18:14:18       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:14:18       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:14:18       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:14:18       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_11.pickle"
[2018-06-08 18:14:18  start_training.py:128 -                      main()] Fidelity obtained: 0.9840733457846021
[2018-06-08 18:14:21  start_training.py: 99 -                      main()] Starting training no.12
[2018-06-08 18:14:21  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 18:14:21    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:14:21    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:14:21    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:14:21    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:14:21           model.py:140 -       _set_initial_values()] Initial parameters values: 0.
[2018-06-08 18:14:22           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:14:22           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:14:22       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:14:22       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:14:22       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:14:22       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:14:22       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:14:22       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:14:22       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:14:22       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:14:22       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:14:22       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:14:25       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:14:26       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7105156683302793
[2018-06-08 18:14:26       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7206850699359784
[2018-06-08 18:14:27       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.15716714110995325
[2018-06-08 18:14:28       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.25566406249364493
[2018-06-08 18:14:29       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.6757109233584185
[2018-06-08 18:14:30       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9657761162850078
[2018-06-08 18:14:30       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999368210631853
[2018-06-08 18:14:31       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999992731719337
[2018-06-08 18:14:32       Optimizer.py:490 -                      _run()]   Epoch no. 8: 1.0000000000000007
[2018-06-08 18:14:33       Optimizer.py:490 -                      _run()]   Epoch no. 9: 1.0000000000000002
[2018-06-08 18:14:34       Optimizer.py:490 -                      _run()]   Epoch no. 10: 1.0000000000000004
[2018-06-08 18:14:35       Optimizer.py:490 -                      _run()]   Epoch no. 11: 1.0000000000000002
[2018-06-08 18:14:35       Optimizer.py:490 -                      _run()]   Epoch no. 12: 1.0000000000000007
[2018-06-08 18:14:36       Optimizer.py:490 -                      _run()]   Epoch no. 13: 1.0000000000000004
[2018-06-08 18:14:37       Optimizer.py:490 -                      _run()]   Epoch no. 14: 1.0000000000000002
[2018-06-08 18:14:38       Optimizer.py:490 -                      _run()]   Epoch no. 15: 1.0000000000000002
[2018-06-08 18:14:39       Optimizer.py:490 -                      _run()]   Epoch no. 16: 1.0000000000000002
[2018-06-08 18:14:40       Optimizer.py:490 -                      _run()]   Epoch no. 17: 1.0000000000000007
[2018-06-08 18:14:40       Optimizer.py:490 -                      _run()]   Epoch no. 18: 1.0000000000000009
[2018-06-08 18:14:41       Optimizer.py:490 -                      _run()]   Epoch no. 19: 1.0000000000000002
[2018-06-08 18:14:42       Optimizer.py:490 -                      _run()]   Epoch no. 20: 1.0000000000000007
[2018-06-08 18:14:43       Optimizer.py:490 -                      _run()]   Epoch no. 21: 1.0000000000000016
[2018-06-08 18:14:44       Optimizer.py:490 -                      _run()]   Epoch no. 22: 1.0000000000000007
[2018-06-08 18:14:45       Optimizer.py:490 -                      _run()]   Epoch no. 23: 1.0
[2018-06-08 18:14:45       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:14:45       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:14:45       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:14:45       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:14:45       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_12.pickle"
[2018-06-08 18:14:45  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000007
[2018-06-08 18:14:48  start_training.py: 99 -                      main()] Starting training no.13
[2018-06-08 18:14:48  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 18:14:48    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:14:48    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:14:48    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:14:48    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:14:48           model.py:140 -       _set_initial_values()] Initial parameters values: 0.
[2018-06-08 18:14:48           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:14:48           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:14:48       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:14:48       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:14:48       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:14:48       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:14:48       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:14:48       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:14:48       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:14:48       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:14:48       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:14:48       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:14:51       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:14:52       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.31296017433588313
[2018-06-08 18:14:53       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.45242714560736613
[2018-06-08 18:14:53       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.5241380567940899
[2018-06-08 18:14:54       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.6574189191377662
[2018-06-08 18:14:54       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7284566005419418
[2018-06-08 18:14:55       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.688105260295951
[2018-06-08 18:14:56       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8754619882314637
[2018-06-08 18:14:57       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8287016513618534
[2018-06-08 18:14:57       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8915541791028884
[2018-06-08 18:14:58       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9044559004893828
[2018-06-08 18:14:59       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9146358561099162
[2018-06-08 18:15:00       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9138710163467274
[2018-06-08 18:15:00       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9056784693016533
[2018-06-08 18:15:01       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9209641628280493
[2018-06-08 18:15:02       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8830542890553249
[2018-06-08 18:15:03       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9286114663797393
[2018-06-08 18:15:03       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9185716984966991
[2018-06-08 18:15:04       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9147202247485923
[2018-06-08 18:15:05       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.888541685192139
[2018-06-08 18:15:05       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9303258812831078
[2018-06-08 18:15:06       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9323262947006705
[2018-06-08 18:15:07       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9136374969085956
[2018-06-08 18:15:08       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9276703857464134
[2018-06-08 18:15:08       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9165390840727377
[2018-06-08 18:15:09       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.933788352829609
[2018-06-08 18:15:10       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.934993460612991
[2018-06-08 18:15:11       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9361345675907345
[2018-06-08 18:15:11       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9286458998524333
[2018-06-08 18:15:12       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9315442391653321
[2018-06-08 18:15:13       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.93453714944352
[2018-06-08 18:15:14       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9214747281053448
[2018-06-08 18:15:14       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9336526102580354
[2018-06-08 18:15:15       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9263816221317047
[2018-06-08 18:15:16       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9315296772995338
[2018-06-08 18:15:16       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9268603939145327
[2018-06-08 18:15:17       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.924876881288324
[2018-06-08 18:15:18       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9289118747651102
[2018-06-08 18:15:19       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9375873416822778
[2018-06-08 18:15:19       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9311827889552707
[2018-06-08 18:15:20       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9340233466692088
[2018-06-08 18:15:21       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.93623647207351
[2018-06-08 18:15:21       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.92932368157552
[2018-06-08 18:15:22       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9314680976230769
[2018-06-08 18:15:23       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9357271526648884
[2018-06-08 18:15:24       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9219619847167522
[2018-06-08 18:15:24       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9313247741328319
[2018-06-08 18:15:25       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9348885189917572
[2018-06-08 18:15:26       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9268486812213463
[2018-06-08 18:15:27       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9335346490520415
[2018-06-08 18:15:27       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.92958051093361
[2018-06-08 18:15:28       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9362840666420831
[2018-06-08 18:15:29       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9333685032301452
[2018-06-08 18:15:30       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9328708037960242
[2018-06-08 18:15:30       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9374429323006623
[2018-06-08 18:15:31       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9350847783335358
[2018-06-08 18:15:32       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9316882854565658
[2018-06-08 18:15:33       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9358114403753052
[2018-06-08 18:15:33       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.935676584706967
[2018-06-08 18:15:34       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9302217658369162
[2018-06-08 18:15:35       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9353491993659927
[2018-06-08 18:15:36       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.932964435914919
[2018-06-08 18:15:36       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.932831644877492
[2018-06-08 18:15:37       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9317740702404282
[2018-06-08 18:15:38       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.932407380123351
[2018-06-08 18:15:39       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9330830253127494
[2018-06-08 18:15:40       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.927695206978185
[2018-06-08 18:15:40       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9375201807488679
[2018-06-08 18:15:41       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9349975890500882
[2018-06-08 18:15:42       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9349259448938889
[2018-06-08 18:15:43       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9265347827571369
[2018-06-08 18:15:43       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9365522742398844
[2018-06-08 18:15:44       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.928060482176125
[2018-06-08 18:15:45       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9291054767077027
[2018-06-08 18:15:46       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9371531473782081
[2018-06-08 18:15:46       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9346888442582787
[2018-06-08 18:15:47       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9313725321465539
[2018-06-08 18:15:48       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.935533566195172
[2018-06-08 18:15:49       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9179572188960503
[2018-06-08 18:15:49       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9364355043707459
[2018-06-08 18:15:50       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9371163432885846
[2018-06-08 18:15:51       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9327753033450901
[2018-06-08 18:15:51       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9359361706968494
[2018-06-08 18:15:52       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9193054014709052
[2018-06-08 18:15:53       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9310096211897705
[2018-06-08 18:15:54       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9346132941988118
[2018-06-08 18:15:54       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9315558259169152
[2018-06-08 18:15:55       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9366610316214158
[2018-06-08 18:15:56       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9350535423079519
[2018-06-08 18:15:57       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9361817029585826
[2018-06-08 18:15:57       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9345552201082478
[2018-06-08 18:15:58       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9347770122196029
[2018-06-08 18:15:59       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9342694498111888
[2018-06-08 18:15:59       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9376822417362672
[2018-06-08 18:16:00       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9362439880837222
[2018-06-08 18:16:01       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9299317058644786
[2018-06-08 18:16:02       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9259281695318609
[2018-06-08 18:16:02       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9369169761078606
[2018-06-08 18:16:03       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9215841561134706
[2018-06-08 18:16:04       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9374786360355306
[2018-06-08 18:16:05       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9318495276786429
[2018-06-08 18:16:05       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:16:05       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:16:05       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:16:05       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_13.pickle"
[2018-06-08 18:16:05  start_training.py:128 -                      main()] Fidelity obtained: 0.9314530350045229
[2018-06-08 18:16:07  start_training.py: 99 -                      main()] Starting training no.14
[2018-06-08 18:16:07  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 18:16:07    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:16:07    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:16:07    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:16:07    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:16:07           model.py:140 -       _set_initial_values()] Initial parameters values: 0.
[2018-06-08 18:16:08           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:16:08           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:16:08       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:16:08       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:16:08       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:16:08       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:16:08       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:16:08       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:16:08       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:16:08       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:16:08       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:16:08       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:16:11       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:16:12       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.4097900267020817
[2018-06-08 18:16:13       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5735741652228431
[2018-06-08 18:16:14       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.583269380009062
[2018-06-08 18:16:14       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7952026680048978
[2018-06-08 18:16:15       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9857905850756454
[2018-06-08 18:16:16       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.999999384157206
[2018-06-08 18:16:17       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999415525892
[2018-06-08 18:16:17       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999831341073
[2018-06-08 18:16:18       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999924368675
[2018-06-08 18:16:19       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999952019261
[2018-06-08 18:16:20       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999977339715
[2018-06-08 18:16:21       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999999985222954
[2018-06-08 18:16:22       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999992331304
[2018-06-08 18:16:22       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999995264036
[2018-06-08 18:16:23       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999997250374
[2018-06-08 18:16:24       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999998021817
[2018-06-08 18:16:25       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999998881546
[2018-06-08 18:16:25       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999999294572
[2018-06-08 18:16:26       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999999455212
[2018-06-08 18:16:27       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999999666391
[2018-06-08 18:16:28       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999999788691
[2018-06-08 18:16:29       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999999855603
[2018-06-08 18:16:29       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999999878338
[2018-06-08 18:16:30       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999999918161
[2018-06-08 18:16:31       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999999999939904
[2018-06-08 18:16:32       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999999999959027
[2018-06-08 18:16:33       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999999962743
[2018-06-08 18:16:34       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999999978562
[2018-06-08 18:16:34       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999999984194
[2018-06-08 18:16:35       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999999999988046
[2018-06-08 18:16:36       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999999999990965
[2018-06-08 18:16:37       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999999992468
[2018-06-08 18:16:37       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999999999995026
[2018-06-08 18:16:38       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999999995839
[2018-06-08 18:16:39       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999999999996976
[2018-06-08 18:16:40       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999999997345
[2018-06-08 18:16:41       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999999998163
[2018-06-08 18:16:42       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999999999998537
[2018-06-08 18:16:42       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999999999998768
[2018-06-08 18:16:43       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999999999073
[2018-06-08 18:16:44       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999999999999251
[2018-06-08 18:16:45       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999999999999395
[2018-06-08 18:16:45       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999999999517
[2018-06-08 18:16:46       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.999999999999961
[2018-06-08 18:16:47       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999999999999687
[2018-06-08 18:16:48       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999999999736
[2018-06-08 18:16:49       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999999999777
[2018-06-08 18:16:49       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999999999999829
[2018-06-08 18:16:50       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999999999999859
[2018-06-08 18:16:51       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999999999999887
[2018-06-08 18:16:52       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999999999999907
[2018-06-08 18:16:53       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999999999999922
[2018-06-08 18:16:53       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999999999999934
[2018-06-08 18:16:54       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999999999999936
[2018-06-08 18:16:55       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999999999999964
[2018-06-08 18:16:56       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.999999999999997
[2018-06-08 18:16:57       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999999999976
[2018-06-08 18:16:57       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999999999999983
[2018-06-08 18:16:58       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.999999999999999
[2018-06-08 18:16:59       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999999999999991
[2018-06-08 18:17:00       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999999999999991
[2018-06-08 18:17:01       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999999999999994
[2018-06-08 18:17:02       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.999999999999999
[2018-06-08 18:17:03       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999999999999987
[2018-06-08 18:17:03       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999999999999996
[2018-06-08 18:17:04       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999999999999999
[2018-06-08 18:17:05       Optimizer.py:490 -                      _run()]   Epoch no. 66: 1.0
[2018-06-08 18:17:05       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:17:05       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:17:05       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:17:05       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:17:05       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_14.pickle"
[2018-06-08 18:17:05  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 18:17:08  start_training.py: 99 -                      main()] Starting training no.15
[2018-06-08 18:17:08  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 18:17:08    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:17:08    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:17:08    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:17:08    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:17:08           model.py:140 -       _set_initial_values()] Initial parameters values: 0.
[2018-06-08 18:17:08           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:17:08           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:17:08       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:17:08       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:17:08       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:17:08       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:17:08       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:17:08       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:17:08       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:17:08       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:17:08       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:17:08       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:17:12       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:17:12       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5994940877400727
[2018-06-08 18:17:13       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.42461775933217644
[2018-06-08 18:17:14       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6817440302295625
[2018-06-08 18:17:15       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9792098010846324
[2018-06-08 18:17:16       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9926373399749392
[2018-06-08 18:17:16       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999677428134
[2018-06-08 18:17:17       Optimizer.py:490 -                      _run()]   Epoch no. 6: 1.0
[2018-06-08 18:17:17       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:17:17       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:17:17       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:17:17       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:17:17       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_15.pickle"
[2018-06-08 18:17:17  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000002
[2018-06-08 18:17:20  start_training.py: 99 -                      main()] Starting training no.16
[2018-06-08 18:17:20  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 18:17:20    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:17:20    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:17:20    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:17:20    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:17:20           model.py:140 -       _set_initial_values()] Initial parameters values: 0.
[2018-06-08 18:17:20           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:17:20           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:17:20       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:17:20       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:17:20       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:17:20       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:17:20       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:17:20       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:17:20       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:17:20       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:17:20       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:17:20       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:17:24       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:17:24       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.43832614407950793
[2018-06-08 18:17:25       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.42680525243642575
[2018-06-08 18:17:26       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7870109840738853
[2018-06-08 18:17:26       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8220360331797552
[2018-06-08 18:17:27       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8748806296302202
[2018-06-08 18:17:28       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8371570242089613
[2018-06-08 18:17:28       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8646108290401686
[2018-06-08 18:17:29       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8508277405066679
[2018-06-08 18:17:30       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8621287560028342
[2018-06-08 18:17:31       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8280355822786806
[2018-06-08 18:17:31       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8416613151434297
[2018-06-08 18:17:32       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8854014140784733
[2018-06-08 18:17:33       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8405085286563466
[2018-06-08 18:17:34       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8694529640957708
[2018-06-08 18:17:34       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8661468325736162
[2018-06-08 18:17:35       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8678627818126534
[2018-06-08 18:17:36       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8603132018978592
[2018-06-08 18:17:37       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8534689290912499
[2018-06-08 18:17:37       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8582803197821665
[2018-06-08 18:17:38       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8833053838472341
[2018-06-08 18:17:39       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8400569429269599
[2018-06-08 18:17:39       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8821227767836239
[2018-06-08 18:17:40       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8676009712301779
[2018-06-08 18:17:41       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8799488973103099
[2018-06-08 18:17:42       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8858660982400702
[2018-06-08 18:17:42       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8772629885476639
[2018-06-08 18:17:43       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8828224737249342
[2018-06-08 18:17:44       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8810377622387174
[2018-06-08 18:17:45       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8825276493532691
[2018-06-08 18:17:46       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8755519724572415
[2018-06-08 18:17:46       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8850615606055848
[2018-06-08 18:17:47       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8650129026536422
[2018-06-08 18:17:48       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8707321519135295
[2018-06-08 18:17:48       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8824729155997705
[2018-06-08 18:17:49       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8799304926907386
[2018-06-08 18:17:50       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8837517394966135
[2018-06-08 18:17:50       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8549708871473267
[2018-06-08 18:17:51       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.884798719302003
[2018-06-08 18:17:52       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.885688853221087
[2018-06-08 18:17:52       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8728294057348519
[2018-06-08 18:17:53       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8809132339253136
[2018-06-08 18:17:54       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8814717366422983
[2018-06-08 18:17:55       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8881392508786066
[2018-06-08 18:17:55       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8738638637063362
[2018-06-08 18:17:56       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8766351570483535
[2018-06-08 18:17:57       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8690492002382467
[2018-06-08 18:17:58       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8769581881957029
[2018-06-08 18:17:58       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.886480031505238
[2018-06-08 18:17:59       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8887453873611717
[2018-06-08 18:18:00       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.881943202558528
[2018-06-08 18:18:01       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.88809271340357
[2018-06-08 18:18:01       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8895967351329044
[2018-06-08 18:18:02       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8880490357532816
[2018-06-08 18:18:03       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8844584727434334
[2018-06-08 18:18:04       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8874276347545456
[2018-06-08 18:18:04       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8883634477672938
[2018-06-08 18:18:05       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8855500305162934
[2018-06-08 18:18:06       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.880265674852382
[2018-06-08 18:18:07       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8877582145161063
[2018-06-08 18:18:08       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8812535618053958
[2018-06-08 18:18:08       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8885029028132208
[2018-06-08 18:18:09       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8810586217836235
[2018-06-08 18:18:10       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8875281916884092
[2018-06-08 18:18:11       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8881939705580482
[2018-06-08 18:18:11       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.890151383060679
[2018-06-08 18:18:12       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8858040323153807
[2018-06-08 18:18:13       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8908676182754253
[2018-06-08 18:18:14       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8854375017483673
[2018-06-08 18:18:14       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8887028263173131
[2018-06-08 18:18:15       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8861979797231868
[2018-06-08 18:18:16       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8886361297923817
[2018-06-08 18:18:17       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8872970231146436
[2018-06-08 18:18:17       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8885361773911024
[2018-06-08 18:18:18       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8887547533193559
[2018-06-08 18:18:19       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8896886266001194
[2018-06-08 18:18:19       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8822443635212585
[2018-06-08 18:18:20       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.884343881241542
[2018-06-08 18:18:21       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8890356840138149
[2018-06-08 18:18:22       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8876710470304718
[2018-06-08 18:18:22       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8822025712628614
[2018-06-08 18:18:23       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8895610934035605
[2018-06-08 18:18:24       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8892440102710938
[2018-06-08 18:18:25       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8896255265200876
[2018-06-08 18:18:25       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8879315445557675
[2018-06-08 18:18:26       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.883823128639395
[2018-06-08 18:18:27       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8893367883524033
[2018-06-08 18:18:27       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8882378881208579
[2018-06-08 18:18:28       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8889636364287231
[2018-06-08 18:18:29       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8870982464931838
[2018-06-08 18:18:30       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8816144819934563
[2018-06-08 18:18:30       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8876487098484364
[2018-06-08 18:18:31       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8902647832477568
[2018-06-08 18:18:32       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8881823401904981
[2018-06-08 18:18:33       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8905903677269812
[2018-06-08 18:18:33       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8890874649006204
[2018-06-08 18:18:34       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8900374704854844
[2018-06-08 18:18:35       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8885333796657483
[2018-06-08 18:18:36       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8885240075396745
[2018-06-08 18:18:36       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8898817007970634
[2018-06-08 18:18:37       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8860289744484083
[2018-06-08 18:18:37       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:18:37       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:18:37       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:18:37       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_16.pickle"
[2018-06-08 18:18:37  start_training.py:128 -                      main()] Fidelity obtained: 0.8876926863544347
[2018-06-08 18:18:40  start_training.py: 99 -                      main()] Starting training no.17
[2018-06-08 18:18:40  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 18:18:40    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:18:40    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:18:40    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:18:40    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:18:40           model.py:140 -       _set_initial_values()] Initial parameters values: 0.
[2018-06-08 18:18:40           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:18:40           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:18:40       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:18:40       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:18:40       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:18:40       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:18:40       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:18:40       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:18:40       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:18:40       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:18:40       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:18:41       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:18:44       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:18:45       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.3234270469044968
[2018-06-08 18:18:46       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5515593038953317
[2018-06-08 18:18:46       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.718947742348236
[2018-06-08 18:18:47       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.5294370616557316
[2018-06-08 18:18:48       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.646112308266087
[2018-06-08 18:18:49       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.26513436592918604
[2018-06-08 18:18:50       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.6873321908189122
[2018-06-08 18:18:50       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.6975364481779545
[2018-06-08 18:18:51       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.709350229150916
[2018-06-08 18:18:52       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.65779498181799
[2018-06-08 18:18:53       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.6823453889611814
[2018-06-08 18:18:53       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.7076915490924732
[2018-06-08 18:18:54       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.738035092021602
[2018-06-08 18:18:55       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.6769361889934667
[2018-06-08 18:18:56       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.5988769624012952
[2018-06-08 18:18:56       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.730684233205244
[2018-06-08 18:18:57       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.6607492848570575
[2018-06-08 18:18:58       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.7527716794947203
[2018-06-08 18:18:58       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.7273285184727327
[2018-06-08 18:18:59       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.7452914370281271
[2018-06-08 18:19:00       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.7185151393452155
[2018-06-08 18:19:00       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.7393735552407587
[2018-06-08 18:19:01       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.734873217677205
[2018-06-08 18:19:02       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.6909332067959748
[2018-06-08 18:19:03       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.7396479744496003
[2018-06-08 18:19:04       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.7364323679742235
[2018-06-08 18:19:04       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.7491325036989991
[2018-06-08 18:19:05       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.7340455894112345
[2018-06-08 18:19:06       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.7477061103004674
[2018-06-08 18:19:07       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.7399199007337123
[2018-06-08 18:19:07       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.7313040143290853
[2018-06-08 18:19:08       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.7470444024686725
[2018-06-08 18:19:09       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.7440684236271052
[2018-06-08 18:19:10       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.7349932545903829
[2018-06-08 18:19:10       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.7414866489621432
[2018-06-08 18:19:11       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.7513908271226458
[2018-06-08 18:19:12       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.7539303327055245
[2018-06-08 18:19:12       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.7316192520458686
[2018-06-08 18:19:13       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.7180192089689053
[2018-06-08 18:19:14       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.7354344920547213
[2018-06-08 18:19:15       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.7440897785334895
[2018-06-08 18:19:16       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.7364077607035346
[2018-06-08 18:19:16       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.7565611239524146
[2018-06-08 18:19:17       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.7386135613958852
[2018-06-08 18:19:18       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.7428665269737118
[2018-06-08 18:19:19       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.7459190093122716
[2018-06-08 18:19:20       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.7503552798651483
[2018-06-08 18:19:20       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.7291866210623499
[2018-06-08 18:19:21       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.7506911322883231
[2018-06-08 18:19:22       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.7502989928231741
[2018-06-08 18:19:22       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.735604980756828
[2018-06-08 18:19:23       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.7219342847163364
[2018-06-08 18:19:24       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.7461867665634
[2018-06-08 18:19:25       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.7455730018310237
[2018-06-08 18:19:25       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.7352578351722994
[2018-06-08 18:19:26       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.7348175753268265
[2018-06-08 18:19:27       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.7535317118155308
[2018-06-08 18:19:28       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.7553341639336887
[2018-06-08 18:19:28       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.7451454028728604
[2018-06-08 18:19:29       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.7532113437135035
[2018-06-08 18:19:30       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.7477421457906074
[2018-06-08 18:19:31       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.7380383311161937
[2018-06-08 18:19:31       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.7540279142364297
[2018-06-08 18:19:32       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.7520728858356392
[2018-06-08 18:19:33       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.7505124520859553
[2018-06-08 18:19:34       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.7365701059463383
[2018-06-08 18:19:35       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.7502768769469167
[2018-06-08 18:19:35       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.751607253106386
[2018-06-08 18:19:36       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.7133026428204292
[2018-06-08 18:19:37       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.7524259553881849
[2018-06-08 18:19:38       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.748770795624279
[2018-06-08 18:19:38       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.7142572205707135
[2018-06-08 18:19:39       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.7516439032356135
[2018-06-08 18:19:40       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.7324457515496023
[2018-06-08 18:19:41       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.7545262219474309
[2018-06-08 18:19:41       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.7398479735426513
[2018-06-08 18:19:42       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.7412831410356673
[2018-06-08 18:19:43       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.7405116122945582
[2018-06-08 18:19:44       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.7536079673504787
[2018-06-08 18:19:44       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.7490455463303131
[2018-06-08 18:19:45       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.7493582629167527
[2018-06-08 18:19:46       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.7508007685280819
[2018-06-08 18:19:47       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.7448156068659313
[2018-06-08 18:19:47       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.7479051603222864
[2018-06-08 18:19:48       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.7549357984108989
[2018-06-08 18:19:49       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.7374344843722899
[2018-06-08 18:19:50       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.6975273981522099
[2018-06-08 18:19:50       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.7500642845349508
[2018-06-08 18:19:51       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.7536366795858221
[2018-06-08 18:19:52       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.7099324926230728
[2018-06-08 18:19:53       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.7555617618169512
[2018-06-08 18:19:53       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.751117354574519
[2018-06-08 18:19:54       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.7379450230066317
[2018-06-08 18:19:55       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.7485561657476655
[2018-06-08 18:19:56       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.7488243898122604
[2018-06-08 18:19:56       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.7436536099786873
[2018-06-08 18:19:57       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.749665110137969
[2018-06-08 18:19:58       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.7541698015626536
[2018-06-08 18:19:59       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.7525037765384972
[2018-06-08 18:19:59       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.7442653280442854
[2018-06-08 18:19:59       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:19:59       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:19:59       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:19:59       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_17.pickle"
[2018-06-08 18:19:59  start_training.py:128 -                      main()] Fidelity obtained: 0.7506686851484529
[2018-06-08 18:20:02  start_training.py: 99 -                      main()] Starting training no.18
[2018-06-08 18:20:02  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 18:20:02    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:20:02    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:20:02    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:20:02    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:20:02           model.py:140 -       _set_initial_values()] Initial parameters values: 0.
[2018-06-08 18:20:02           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:20:02           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:20:02       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:20:02       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:20:02       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:20:02       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:20:02       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:20:02       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:20:02       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:20:02       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:20:02       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:20:02       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:20:06       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:20:07       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.22408629697194002
[2018-06-08 18:20:08       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6452671290802499
[2018-06-08 18:20:08       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8306961228284173
[2018-06-08 18:20:09       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9463079733127436
[2018-06-08 18:20:10       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9299151495264826
[2018-06-08 18:20:11       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9327614306453
[2018-06-08 18:20:12       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9482386959253393
[2018-06-08 18:20:12       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8990393633347851
[2018-06-08 18:20:13       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9725189547112943
[2018-06-08 18:20:14       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9725881216754064
[2018-06-08 18:20:14       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9665953216222846
[2018-06-08 18:20:15       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9749837732516171
[2018-06-08 18:20:16       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9724029742604268
[2018-06-08 18:20:17       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9782066275089033
[2018-06-08 18:20:17       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9776585685381904
[2018-06-08 18:20:18       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9810764303743941
[2018-06-08 18:20:19       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9784771760302234
[2018-06-08 18:20:20       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9778887599292574
[2018-06-08 18:20:20       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9783932614961836
[2018-06-08 18:20:21       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9729268651800977
[2018-06-08 18:20:22       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9710550315134147
[2018-06-08 18:20:23       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9738479397211972
[2018-06-08 18:20:24       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9775494851164455
[2018-06-08 18:20:24       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9716202007843476
[2018-06-08 18:20:25       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9763264723358914
[2018-06-08 18:20:26       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9784165415768769
[2018-06-08 18:20:27       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9783603064320829
[2018-06-08 18:20:28       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9816807204151019
[2018-06-08 18:20:28       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9747260668887919
[2018-06-08 18:20:29       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9794646181066109
[2018-06-08 18:20:30       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9792093701122355
[2018-06-08 18:20:31       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9822557651759319
[2018-06-08 18:20:31       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9796271528168708
[2018-06-08 18:20:32       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9807161642626049
[2018-06-08 18:20:33       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9791603369347633
[2018-06-08 18:20:34       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.978304164570088
[2018-06-08 18:20:34       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9802903723335135
[2018-06-08 18:20:35       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9816275296363253
[2018-06-08 18:20:36       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9806050454136525
[2018-06-08 18:20:37       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9794817780383418
[2018-06-08 18:20:37       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9798593570364822
[2018-06-08 18:20:38       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9800707217830934
[2018-06-08 18:20:39       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9801696971915318
[2018-06-08 18:20:40       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9819448152329369
[2018-06-08 18:20:40       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9796037441876857
[2018-06-08 18:20:41       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9826611135506894
[2018-06-08 18:20:42       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9815583811713282
[2018-06-08 18:20:42       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.980013372806683
[2018-06-08 18:20:43       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9815446754636993
[2018-06-08 18:20:44       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9819475307139327
[2018-06-08 18:20:44       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9822011341106976
[2018-06-08 18:20:45       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.981561215007281
[2018-06-08 18:20:46       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9812579772429586
[2018-06-08 18:20:47       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9810140574857213
[2018-06-08 18:20:47       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.982969542079133
[2018-06-08 18:20:48       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9820411723424699
[2018-06-08 18:20:49       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9823539547664599
[2018-06-08 18:20:50       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9829733041051457
[2018-06-08 18:20:50       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9829729532077467
[2018-06-08 18:20:51       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9823955854846854
[2018-06-08 18:20:52       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9798900579288226
[2018-06-08 18:20:53       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9821628608518522
[2018-06-08 18:20:53       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9830709464249563
[2018-06-08 18:20:54       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9816558883889209
[2018-06-08 18:20:55       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.982015623951473
[2018-06-08 18:20:56       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9824085983741084
[2018-06-08 18:20:57       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9817931334581463
[2018-06-08 18:20:57       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9821900519227692
[2018-06-08 18:20:58       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9824114584133915
[2018-06-08 18:20:59       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9809044376347454
[2018-06-08 18:21:00       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9821879021989101
[2018-06-08 18:21:00       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.982746584199769
[2018-06-08 18:21:01       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9817238954408102
[2018-06-08 18:21:02       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9817266827488226
[2018-06-08 18:21:03       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9814451153133789
[2018-06-08 18:21:04       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9820784377163357
[2018-06-08 18:21:04       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9815613355298397
[2018-06-08 18:21:05       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9823576400188307
[2018-06-08 18:21:06       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9822988911250589
[2018-06-08 18:21:07       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9827442247554299
[2018-06-08 18:21:07       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9821044871659147
[2018-06-08 18:21:08       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9829304958353409
[2018-06-08 18:21:09       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9816258785450457
[2018-06-08 18:21:09       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.982856143370995
[2018-06-08 18:21:10       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.982676393940757
[2018-06-08 18:21:11       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9822629140968765
[2018-06-08 18:21:12       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.982048244223868
[2018-06-08 18:21:12       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9810219627084276
[2018-06-08 18:21:13       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9811161299546991
[2018-06-08 18:21:14       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9827259502464583
[2018-06-08 18:21:15       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9824254158539755
[2018-06-08 18:21:15       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9814976574529025
[2018-06-08 18:21:16       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9818018288919633
[2018-06-08 18:21:17       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9828748355981872
[2018-06-08 18:21:18       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9819194093439517
[2018-06-08 18:21:18       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9829865374110998
[2018-06-08 18:21:19       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9830228323593482
[2018-06-08 18:21:20       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.982683409607317
[2018-06-08 18:21:21       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9823263910212537
[2018-06-08 18:21:21       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9800673842497726
[2018-06-08 18:21:21       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:21:21       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:21:21       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:21:21       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_18.pickle"
[2018-06-08 18:21:22  start_training.py:128 -                      main()] Fidelity obtained: 0.981215365262414
[2018-06-08 18:21:24  start_training.py: 99 -                      main()] Starting training no.19
[2018-06-08 18:21:24  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 18:21:24    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:21:24    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:21:24    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:21:24    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:21:24           model.py:140 -       _set_initial_values()] Initial parameters values: 0.
[2018-06-08 18:21:24           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:21:24           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:21:24       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:21:24       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:21:24       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:21:24       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:21:24       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:21:24       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:21:24       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:21:24       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:21:24       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:21:25       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:21:28       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:21:29       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.532454916896047
[2018-06-08 18:21:30       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.4910520501217019
[2018-06-08 18:21:30       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.5661541050566224
[2018-06-08 18:21:31       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8250433171880159
[2018-06-08 18:21:32       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.6466529625557722
[2018-06-08 18:21:32       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8206016431135166
[2018-06-08 18:21:33       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8646487014301115
[2018-06-08 18:21:34       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8207160720889115
[2018-06-08 18:21:34       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8486743113096157
[2018-06-08 18:21:35       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8438816727884297
[2018-06-08 18:21:36       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8755815238897339
[2018-06-08 18:21:37       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8481320684444988
[2018-06-08 18:21:37       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8294087475415872
[2018-06-08 18:21:38       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8854714156517354
[2018-06-08 18:21:39       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8456608117522676
[2018-06-08 18:21:40       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8776080887419354
[2018-06-08 18:21:40       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8665047420580636
[2018-06-08 18:21:41       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8358656841490836
[2018-06-08 18:21:42       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8857522953680903
[2018-06-08 18:21:42       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8851840448152646
[2018-06-08 18:21:43       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8778291455586315
[2018-06-08 18:21:44       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8840868638626523
[2018-06-08 18:21:45       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.885936046512163
[2018-06-08 18:21:45       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8677067357368458
[2018-06-08 18:21:46       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8885709024699834
[2018-06-08 18:21:47       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.880144761283265
[2018-06-08 18:21:48       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8689291560580863
[2018-06-08 18:21:48       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8842620122884682
[2018-06-08 18:21:49       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8631926802430172
[2018-06-08 18:21:50       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8777823131791221
[2018-06-08 18:21:50       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8723732454184252
[2018-06-08 18:21:51       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8872978075000825
[2018-06-08 18:21:52       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8651368387551076
[2018-06-08 18:21:53       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8806179248752468
[2018-06-08 18:21:53       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8798773277752374
[2018-06-08 18:21:54       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.876790583954643
[2018-06-08 18:21:55       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8878394455677164
[2018-06-08 18:21:56       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8863846801506949
[2018-06-08 18:21:56       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8864008505790539
[2018-06-08 18:21:57       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8807614229429
[2018-06-08 18:21:58       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8699763661290079
[2018-06-08 18:21:59       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8675186699046076
[2018-06-08 18:21:59       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8782893260575836
[2018-06-08 18:22:00       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8856621082647483
[2018-06-08 18:22:01       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8839915312940958
[2018-06-08 18:22:01       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8807576876101009
[2018-06-08 18:22:02       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8749414925529316
[2018-06-08 18:22:03       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8799298791334749
[2018-06-08 18:22:04       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8799931250021451
[2018-06-08 18:22:04       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8839130840275662
[2018-06-08 18:22:05       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8844945713929707
[2018-06-08 18:22:05       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8708211183623682
[2018-06-08 18:22:06       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8878169624242999
[2018-06-08 18:22:07       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8868930733172046
[2018-06-08 18:22:08       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8831400470795734
[2018-06-08 18:22:08       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8851087954624508
[2018-06-08 18:22:09       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8876514321589584
[2018-06-08 18:22:10       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8838060141674962
[2018-06-08 18:22:10       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8832018151074281
[2018-06-08 18:22:11       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8800405274244214
[2018-06-08 18:22:12       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8868899115355505
[2018-06-08 18:22:12       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8870107519690292
[2018-06-08 18:22:13       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8895216198771922
[2018-06-08 18:22:14       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8863559241300166
[2018-06-08 18:22:15       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8881297852556319
[2018-06-08 18:22:15       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8763284010605962
[2018-06-08 18:22:16       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.885388519557278
[2018-06-08 18:22:17       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8796307149887224
[2018-06-08 18:22:18       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8845053241183344
[2018-06-08 18:22:18       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8872604781908326
[2018-06-08 18:22:19       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.884088742067427
[2018-06-08 18:22:20       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8790654071038237
[2018-06-08 18:22:20       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8905121936097509
[2018-06-08 18:22:21       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8874947739122241
[2018-06-08 18:22:22       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8815832309519139
[2018-06-08 18:22:23       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8881386639767496
[2018-06-08 18:22:23       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8883649298884562
[2018-06-08 18:22:24       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8893245098619802
[2018-06-08 18:22:25       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8817101699028183
[2018-06-08 18:22:25       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8875453596296936
[2018-06-08 18:22:26       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8870021082884226
[2018-06-08 18:22:27       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8883250697219622
[2018-06-08 18:22:28       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8914176591898071
[2018-06-08 18:22:28       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8865991978426148
[2018-06-08 18:22:29       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8844151784472375
[2018-06-08 18:22:30       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.886036681863662
[2018-06-08 18:22:31       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8894753524451509
[2018-06-08 18:22:31       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8884337500849243
[2018-06-08 18:22:32       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8852110409341291
[2018-06-08 18:22:33       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.889041587747299
[2018-06-08 18:22:33       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8783648410311677
[2018-06-08 18:22:34       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.886065055782091
[2018-06-08 18:22:35       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8812683860361669
[2018-06-08 18:22:36       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8900051253191578
[2018-06-08 18:22:36       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8900366968921041
[2018-06-08 18:22:37       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8886989379737196
[2018-06-08 18:22:38       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8817767670942629
[2018-06-08 18:22:39       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8904251227855852
[2018-06-08 18:22:39       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8906405961594805
[2018-06-08 18:22:40       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8891372302084187
[2018-06-08 18:22:40       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:22:40       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:22:40       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:22:40       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_19.pickle"
[2018-06-08 18:22:40  start_training.py:128 -                      main()] Fidelity obtained: 0.8904751054931029
[2018-06-08 18:22:43  start_training.py: 99 -                      main()] Starting training no.20
[2018-06-08 18:22:43  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 18:22:43    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:22:43    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:22:43    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:22:43    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:22:43           model.py:140 -       _set_initial_values()] Initial parameters values: 0.
[2018-06-08 18:22:43           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:22:43           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:22:43       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:22:43       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:22:43       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:22:43       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:22:43       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:22:43       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:22:43       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:22:43       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:22:43       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:22:43       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:22:47       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:22:47       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.30724688325868305
[2018-06-08 18:22:48       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5099601215620067
[2018-06-08 18:22:49       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8619362890387028
[2018-06-08 18:22:49       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9139777508526196
[2018-06-08 18:22:50       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8933421346149596
[2018-06-08 18:22:51       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9727299662477581
[2018-06-08 18:22:52       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8487562841864775
[2018-06-08 18:22:53       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9760499970567774
[2018-06-08 18:22:53       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9778959452409793
[2018-06-08 18:22:54       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9708580014867373
[2018-06-08 18:22:55       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9815706632635482
[2018-06-08 18:22:56       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9827838163468483
[2018-06-08 18:22:56       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9685480658670725
[2018-06-08 18:22:57       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9784030278977569
[2018-06-08 18:22:58       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.969788803759408
[2018-06-08 18:22:59       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9832970581650913
[2018-06-08 18:22:59       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9777020497369882
[2018-06-08 18:23:00       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9817943720277278
[2018-06-08 18:23:01       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9816846715576308
[2018-06-08 18:23:02       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9828193456286326
[2018-06-08 18:23:03       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9812113519923983
[2018-06-08 18:23:03       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9787859730276892
[2018-06-08 18:23:04       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9786025581786898
[2018-06-08 18:23:05       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9835065609170822
[2018-06-08 18:23:06       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9799247349477294
[2018-06-08 18:23:06       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9803952873791725
[2018-06-08 18:23:07       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9845810181807395
[2018-06-08 18:23:08       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9790461987062606
[2018-06-08 18:23:09       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.982833341829366
[2018-06-08 18:23:09       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9815936872685005
[2018-06-08 18:23:10       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9818575753598603
[2018-06-08 18:23:11       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9826353453362648
[2018-06-08 18:23:12       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9815607243301827
[2018-06-08 18:23:12       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9843600381062592
[2018-06-08 18:23:13       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9846461827461154
[2018-06-08 18:23:14       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9824236722773386
[2018-06-08 18:23:15       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.98350636534371
[2018-06-08 18:23:16       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.983727117230619
[2018-06-08 18:23:16       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9829250087624698
[2018-06-08 18:23:17       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9817380186621285
[2018-06-08 18:23:18       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9841921838749877
[2018-06-08 18:23:19       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9827079111801507
[2018-06-08 18:23:19       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9839222796159497
[2018-06-08 18:23:20       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9836122426005448
[2018-06-08 18:23:21       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9846346306912059
[2018-06-08 18:23:22       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9802355600066597
[2018-06-08 18:23:22       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9847824103977955
[2018-06-08 18:23:23       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9835014005076375
[2018-06-08 18:23:24       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9832649252737157
[2018-06-08 18:23:25       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9841848302413454
[2018-06-08 18:23:25       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.984433104450781
[2018-06-08 18:23:26       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9843972427856507
[2018-06-08 18:23:27       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9822285490482521
[2018-06-08 18:23:28       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9839776950263278
[2018-06-08 18:23:28       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9839605174214943
[2018-06-08 18:23:29       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9838075667729095
[2018-06-08 18:23:30       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9845891411066445
[2018-06-08 18:23:31       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.984155193222132
[2018-06-08 18:23:32       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9836324545520937
[2018-06-08 18:23:32       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9824338030996327
[2018-06-08 18:23:33       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.983804111200361
[2018-06-08 18:23:34       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9845861484156591
[2018-06-08 18:23:34       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9836857689818777
[2018-06-08 18:23:35       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9816952960831479
[2018-06-08 18:23:36       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9847214187137651
[2018-06-08 18:23:37       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.984660008280857
[2018-06-08 18:23:38       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9847215686356036
[2018-06-08 18:23:38       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9842935542701019
[2018-06-08 18:23:39       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9843810943570103
[2018-06-08 18:23:40       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.984291196557943
[2018-06-08 18:23:41       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9834355462448986
[2018-06-08 18:23:41       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9845182326468533
[2018-06-08 18:23:42       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9844436284966898
[2018-06-08 18:23:43       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9828835637995124
[2018-06-08 18:23:44       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9841779282226248
[2018-06-08 18:23:44       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9844545864974654
[2018-06-08 18:23:45       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9841370824040204
[2018-06-08 18:23:46       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9842446869605225
[2018-06-08 18:23:47       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9843251101193945
[2018-06-08 18:23:48       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9837058758600957
[2018-06-08 18:23:48       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9845697948895631
[2018-06-08 18:23:49       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9831910438051055
[2018-06-08 18:23:50       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9844031714446438
[2018-06-08 18:23:51       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9848557682570608
[2018-06-08 18:23:52       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9839207271753716
[2018-06-08 18:23:52       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9829682707936367
[2018-06-08 18:23:53       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9834823818420239
[2018-06-08 18:23:54       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9842482359115736
[2018-06-08 18:23:55       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9849221040220923
[2018-06-08 18:23:56       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.984036215325418
[2018-06-08 18:23:56       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9845442707384356
[2018-06-08 18:23:57       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9844817576693436
[2018-06-08 18:23:58       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9842510676340239
[2018-06-08 18:23:59       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.984776768559987
[2018-06-08 18:24:00       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9841892763661572
[2018-06-08 18:24:00       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9849810457483359
[2018-06-08 18:24:01       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.984011112998918
[2018-06-08 18:24:02       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9827893905057276
[2018-06-08 18:24:02       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9842056174772135
[2018-06-08 18:24:03       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9837864262508237
[2018-06-08 18:24:03       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:24:03       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:24:03       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:24:03       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_20.pickle"
[2018-06-08 18:24:03  start_training.py:128 -                      main()] Fidelity obtained: 0.9838847809576567
[2018-06-08 18:24:06  start_training.py: 99 -                      main()] Starting training no.21
[2018-06-08 18:24:06  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 18:24:06    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:24:06    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:24:06    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:24:06    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:24:06           model.py:140 -       _set_initial_values()] Initial parameters values: 1.
[2018-06-08 18:24:06           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:24:06           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:24:06       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:24:06       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:24:06       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:24:06       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:24:06       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:24:06       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:24:06       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:24:06       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:24:06       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:24:06       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:24:10       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:24:11       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6148347517629213
[2018-06-08 18:24:11       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8303695298090737
[2018-06-08 18:24:12       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.767489788967966
[2018-06-08 18:24:13       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8364272525159326
[2018-06-08 18:24:14       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8711817905725726
[2018-06-08 18:24:14       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.7611139037856596
[2018-06-08 18:24:15       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.832084398618615
[2018-06-08 18:24:16       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8358677346482263
[2018-06-08 18:24:17       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8340243480385725
[2018-06-08 18:24:17       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.84611513384023
[2018-06-08 18:24:18       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8224674046559882
[2018-06-08 18:24:19       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8429779195268848
[2018-06-08 18:24:19       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8538082367726569
[2018-06-08 18:24:20       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8780324862616397
[2018-06-08 18:24:21       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.861915127716001
[2018-06-08 18:24:22       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8573859561314657
[2018-06-08 18:24:22       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8514671908329094
[2018-06-08 18:24:23       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8111773040490822
[2018-06-08 18:24:24       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8639057339367581
[2018-06-08 18:24:25       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8661335812847917
[2018-06-08 18:24:25       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8537629741288485
[2018-06-08 18:24:26       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8756989349253529
[2018-06-08 18:24:27       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8760622353275141
[2018-06-08 18:24:28       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8778694433673057
[2018-06-08 18:24:28       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8611138179199286
[2018-06-08 18:24:29       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8740426254947228
[2018-06-08 18:24:30       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8850343219625191
[2018-06-08 18:24:31       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.88091428048178
[2018-06-08 18:24:31       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8846146239983821
[2018-06-08 18:24:32       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8820551860024929
[2018-06-08 18:24:33       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8701954497969195
[2018-06-08 18:24:33       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8728834941752381
[2018-06-08 18:24:34       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8736746219104794
[2018-06-08 18:24:35       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8650611514592531
[2018-06-08 18:24:36       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8690182125374052
[2018-06-08 18:24:36       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8695867508724966
[2018-06-08 18:24:37       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.880930896422067
[2018-06-08 18:24:38       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8838419637461282
[2018-06-08 18:24:39       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.875086664643532
[2018-06-08 18:24:39       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8822824856451622
[2018-06-08 18:24:40       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8822088404503294
[2018-06-08 18:24:41       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.87158135912851
[2018-06-08 18:24:42       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8773606348708545
[2018-06-08 18:24:42       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8826852444767636
[2018-06-08 18:24:43       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8798639942668252
[2018-06-08 18:24:44       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.874250627218047
[2018-06-08 18:24:45       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8794309455604177
[2018-06-08 18:24:46       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8849260041567943
[2018-06-08 18:24:46       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8792722535248734
[2018-06-08 18:24:47       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8792958619688902
[2018-06-08 18:24:48       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8806310231312051
[2018-06-08 18:24:48       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8752835394226385
[2018-06-08 18:24:49       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8837284429535288
[2018-06-08 18:24:50       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8840565950060228
[2018-06-08 18:24:51       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8744322549574598
[2018-06-08 18:24:51       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8806843055394282
[2018-06-08 18:24:52       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.874102414186632
[2018-06-08 18:24:53       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8843107137788893
[2018-06-08 18:24:54       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8781243551208417
[2018-06-08 18:24:54       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8803594506371734
[2018-06-08 18:24:55       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8813410221280878
[2018-06-08 18:24:56       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8772465515477418
[2018-06-08 18:24:56       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8740443341569051
[2018-06-08 18:24:57       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8827411354604828
[2018-06-08 18:24:58       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8805595497445634
[2018-06-08 18:24:58       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8799858007464693
[2018-06-08 18:24:59       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8812218093840126
[2018-06-08 18:25:00       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8717479848718683
[2018-06-08 18:25:01       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8825698510374593
[2018-06-08 18:25:01       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8812244547038869
[2018-06-08 18:25:02       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8642587477397444
[2018-06-08 18:25:02       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8762200136812175
[2018-06-08 18:25:03       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8825539713428285
[2018-06-08 18:25:04       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8829016162994039
[2018-06-08 18:25:05       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8774633915552025
[2018-06-08 18:25:05       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8847170835447516
[2018-06-08 18:25:06       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8814287315365568
[2018-06-08 18:25:07       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.881061967542808
[2018-06-08 18:25:07       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8830338545832019
[2018-06-08 18:25:08       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8847826784563957
[2018-06-08 18:25:09       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8819074324662189
[2018-06-08 18:25:10       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.881864845348395
[2018-06-08 18:25:10       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8770309306339895
[2018-06-08 18:25:11       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8837999950832652
[2018-06-08 18:25:12       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8820564713669085
[2018-06-08 18:25:13       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8795127634637133
[2018-06-08 18:25:14       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8813756994282649
[2018-06-08 18:25:14       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8845665541083114
[2018-06-08 18:25:15       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8821197039519006
[2018-06-08 18:25:16       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8841002138681375
[2018-06-08 18:25:17       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8849975707980868
[2018-06-08 18:25:17       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8733395833131989
[2018-06-08 18:25:18       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8789185265557691
[2018-06-08 18:25:19       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8806658854765577
[2018-06-08 18:25:20       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8779908489319973
[2018-06-08 18:25:20       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8837640968347938
[2018-06-08 18:25:21       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8799344759634554
[2018-06-08 18:25:22       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8775289862086997
[2018-06-08 18:25:23       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8851907246691038
[2018-06-08 18:25:23       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8801148338911262
[2018-06-08 18:25:23       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:25:23       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:25:23       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:25:23       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_21.pickle"
[2018-06-08 18:25:23  start_training.py:128 -                      main()] Fidelity obtained: 0.8844139767728445
[2018-06-08 18:25:26  start_training.py: 99 -                      main()] Starting training no.22
[2018-06-08 18:25:26  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 18:25:26    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:25:26    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:25:26    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:25:26    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:25:26           model.py:140 -       _set_initial_values()] Initial parameters values: 1.
[2018-06-08 18:25:26           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:25:26           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:25:26       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:25:26       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:25:26       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:25:26       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:25:26       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:25:26       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:25:26       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:25:26       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:25:26       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:25:27       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:25:30       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:25:31       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8319298839515453
[2018-06-08 18:25:32       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.40032230929564055
[2018-06-08 18:25:32       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.40864178753784364
[2018-06-08 18:25:33       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.6569095453231953
[2018-06-08 18:25:34       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9534837398806146
[2018-06-08 18:25:35       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9907549553260915
[2018-06-08 18:25:35       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9909317868825209
[2018-06-08 18:25:36       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9995061463956252
[2018-06-08 18:25:37       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9987995319813782
[2018-06-08 18:25:38       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9993385857050537
[2018-06-08 18:25:39       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9997232918795445
[2018-06-08 18:25:39       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9989533165624306
[2018-06-08 18:25:40       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9982659774434143
[2018-06-08 18:25:41       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9994648070165979
[2018-06-08 18:25:42       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9996091795023228
[2018-06-08 18:25:43       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9995678683984586
[2018-06-08 18:25:43       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9997947056643919
[2018-06-08 18:25:44       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9998187480100523
[2018-06-08 18:25:45       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9997860879049437
[2018-06-08 18:25:46       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9996695031540891
[2018-06-08 18:25:47       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9998002797350659
[2018-06-08 18:25:48       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.999770440113261
[2018-06-08 18:25:48       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9998194747281004
[2018-06-08 18:25:49       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9996994406133601
[2018-06-08 18:25:50       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9997979486930447
[2018-06-08 18:25:51       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9998008840071928
[2018-06-08 18:25:52       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.999847013984109
[2018-06-08 18:25:52       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9998456162367019
[2018-06-08 18:25:53       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9998313317101154
[2018-06-08 18:25:54       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9998495347014582
[2018-06-08 18:25:55       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9998490981489644
[2018-06-08 18:25:56       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9998639788469049
[2018-06-08 18:25:56       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9998556715942278
[2018-06-08 18:25:57       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9998169309223559
[2018-06-08 18:25:58       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9998558066645163
[2018-06-08 18:25:59       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9998725926140605
[2018-06-08 18:26:00       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9998150079352545
[2018-06-08 18:26:01       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9998398297118404
[2018-06-08 18:26:02       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9998794109774812
[2018-06-08 18:26:02       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9998652809696686
[2018-06-08 18:26:03       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.999875206906796
[2018-06-08 18:26:04       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9998745846101863
[2018-06-08 18:26:05       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9998841393081038
[2018-06-08 18:26:06       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9998884468256325
[2018-06-08 18:26:06       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9998818035193673
[2018-06-08 18:26:07       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9998555108767684
[2018-06-08 18:26:08       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9998724466540442
[2018-06-08 18:26:09       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9998497074322924
[2018-06-08 18:26:10       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.999848899576351
[2018-06-08 18:26:10       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.999893053780847
[2018-06-08 18:26:11       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9998721911552962
[2018-06-08 18:26:12       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9998949731101392
[2018-06-08 18:26:13       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9998920664248138
[2018-06-08 18:26:14       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9998962250129909
[2018-06-08 18:26:14       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999009212213592
[2018-06-08 18:26:15       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9998998161484098
[2018-06-08 18:26:16       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9998978465325081
[2018-06-08 18:26:17       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999031303676408
[2018-06-08 18:26:18       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999040531563108
[2018-06-08 18:26:18       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.999891290774568
[2018-06-08 18:26:19       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999032203904129
[2018-06-08 18:26:20       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9998779781250627
[2018-06-08 18:26:21       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.999902560416779
[2018-06-08 18:26:22       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999013356501455
[2018-06-08 18:26:23       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999150023259235
[2018-06-08 18:26:24       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999057104012237
[2018-06-08 18:26:24       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999101009558377
[2018-06-08 18:26:25       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999015049069425
[2018-06-08 18:26:26       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999142608774246
[2018-06-08 18:26:27       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999160929254457
[2018-06-08 18:26:27       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999050990871912
[2018-06-08 18:26:28       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999177421073583
[2018-06-08 18:26:29       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999178766695102
[2018-06-08 18:26:30       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999188796378502
[2018-06-08 18:26:30       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999011052866744
[2018-06-08 18:26:31       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999151023438864
[2018-06-08 18:26:32       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999252502554892
[2018-06-08 18:26:33       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999214231067374
[2018-06-08 18:26:34       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999111155813565
[2018-06-08 18:26:35       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.999924487523351
[2018-06-08 18:26:35       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999261083688278
[2018-06-08 18:26:36       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.999908386916432
[2018-06-08 18:26:37       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999289944543629
[2018-06-08 18:26:38       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999250067527301
[2018-06-08 18:26:39       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999171504979836
[2018-06-08 18:26:40       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.999931561129739
[2018-06-08 18:26:40       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999320024906007
[2018-06-08 18:26:41       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999254018061771
[2018-06-08 18:26:42       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999272883720378
[2018-06-08 18:26:43       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999305756145721
[2018-06-08 18:26:44       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999322605608579
[2018-06-08 18:26:45       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999344326315649
[2018-06-08 18:26:45       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999309701549828
[2018-06-08 18:26:46       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999342675537336
[2018-06-08 18:26:47       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999318877533899
[2018-06-08 18:26:48       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.999927207710763
[2018-06-08 18:26:48       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.999939110589154
[2018-06-08 18:26:49       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999395430504869
[2018-06-08 18:26:50       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999400952700644
[2018-06-08 18:26:51       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999399008267702
[2018-06-08 18:26:51       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:26:51       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:26:51       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:26:51       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_22.pickle"
[2018-06-08 18:26:51  start_training.py:128 -                      main()] Fidelity obtained: 0.9999403528529748
[2018-06-08 18:26:53  start_training.py: 99 -                      main()] Starting training no.23
[2018-06-08 18:26:53  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 18:26:53    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:26:53    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:26:53    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:26:53    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:26:53           model.py:140 -       _set_initial_values()] Initial parameters values: 1.
[2018-06-08 18:26:53           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:26:53           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:26:53       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:26:53       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:26:53       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:26:53       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:26:53       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:26:53       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:26:53       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:26:54       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:26:54       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:26:54       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:26:57       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:26:58       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6611514828041011
[2018-06-08 18:26:59       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8814641233369381
[2018-06-08 18:27:00       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9613462705696498
[2018-06-08 18:27:01       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9333051698295067
[2018-06-08 18:27:01       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9905825388003632
[2018-06-08 18:27:02       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9950882862918892
[2018-06-08 18:27:03       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9998472063119225
[2018-06-08 18:27:04       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999964897445023
[2018-06-08 18:27:05       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999997326905968
[2018-06-08 18:27:05       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999998508131828
[2018-06-08 18:27:06       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999597622856
[2018-06-08 18:27:07       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999999981680295
[2018-06-08 18:27:08       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999993855316
[2018-06-08 18:27:08       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.999999999890952
[2018-06-08 18:27:09       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999999583113
[2018-06-08 18:27:10       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999999944305
[2018-06-08 18:27:11       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999999979895
[2018-06-08 18:27:12       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999999995398
[2018-06-08 18:27:12       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999999998858
[2018-06-08 18:27:13       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999999999736
[2018-06-08 18:27:14       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999999999918
[2018-06-08 18:27:15       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999999999979
[2018-06-08 18:27:16       Optimizer.py:490 -                      _run()]   Epoch no. 22: 1.0
[2018-06-08 18:27:16       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:27:16       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:27:16       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:27:16       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:27:16       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_23.pickle"
[2018-06-08 18:27:16  start_training.py:128 -                      main()] Fidelity obtained: 0.9999999999999998
[2018-06-08 18:27:18  start_training.py: 99 -                      main()] Starting training no.24
[2018-06-08 18:27:18  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 18:27:18    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:27:18    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:27:18    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:27:18    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:27:18           model.py:140 -       _set_initial_values()] Initial parameters values: 1.
[2018-06-08 18:27:19           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:27:19           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:27:19       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:27:19       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:27:19       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:27:19       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:27:19       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:27:19       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:27:19       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:27:19       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:27:19       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:27:19       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:27:22       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:27:23       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.707047299683657
[2018-06-08 18:27:24       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6870708176564001
[2018-06-08 18:27:25       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.5659741597307617
[2018-06-08 18:27:25       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9112735472459796
[2018-06-08 18:27:26       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8592192454670844
[2018-06-08 18:27:27       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.917353940082982
[2018-06-08 18:27:28       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9455656073750301
[2018-06-08 18:27:28       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9550276766845252
[2018-06-08 18:27:29       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8478849260830899
[2018-06-08 18:27:30       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9433240290932465
[2018-06-08 18:27:31       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9474936996254348
[2018-06-08 18:27:31       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9659445083220649
[2018-06-08 18:27:32       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9572877587537014
[2018-06-08 18:27:33       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9586492260577938
[2018-06-08 18:27:33       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9694239146553635
[2018-06-08 18:27:34       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9594305576692932
[2018-06-08 18:27:35       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9650198211522817
[2018-06-08 18:27:36       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9677134583493118
[2018-06-08 18:27:36       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9574662892302337
[2018-06-08 18:27:37       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.937555022828755
[2018-06-08 18:27:38       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9611153751186601
[2018-06-08 18:27:39       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9704631356295792
[2018-06-08 18:27:39       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9552113250516077
[2018-06-08 18:27:40       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9758108502653664
[2018-06-08 18:27:41       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9771693422398328
[2018-06-08 18:27:42       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9722799272062964
[2018-06-08 18:27:42       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9675123095013931
[2018-06-08 18:27:43       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9665888884896953
[2018-06-08 18:27:44       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9685120877786296
[2018-06-08 18:27:45       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9761441536719663
[2018-06-08 18:27:45       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9727479981617146
[2018-06-08 18:27:46       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9691648077360437
[2018-06-08 18:27:47       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9756325006886222
[2018-06-08 18:27:48       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9753125802878274
[2018-06-08 18:27:48       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9767827788233719
[2018-06-08 18:27:49       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9759597588007252
[2018-06-08 18:27:50       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9762336324822578
[2018-06-08 18:27:50       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.972422619616679
[2018-06-08 18:27:51       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9744135462366428
[2018-06-08 18:27:52       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9737124727076246
[2018-06-08 18:27:53       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9771280585221198
[2018-06-08 18:27:54       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9745110585559368
[2018-06-08 18:27:54       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9747696539425575
[2018-06-08 18:27:55       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.976312457811728
[2018-06-08 18:27:56       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9720995430716237
[2018-06-08 18:27:57       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9756010129470511
[2018-06-08 18:27:57       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.976783792696872
[2018-06-08 18:27:58       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9658592150550693
[2018-06-08 18:27:59       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9745947783019264
[2018-06-08 18:27:59       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.977178565944139
[2018-06-08 18:28:00       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9772423149477864
[2018-06-08 18:28:01       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9701319485270722
[2018-06-08 18:28:02       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9667836100827409
[2018-06-08 18:28:02       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9773697766558694
[2018-06-08 18:28:03       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9714185595477318
[2018-06-08 18:28:04       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9762743916791077
[2018-06-08 18:28:05       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9780104298905152
[2018-06-08 18:28:05       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9781552089691219
[2018-06-08 18:28:06       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.974126629307993
[2018-06-08 18:28:07       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9731812652324211
[2018-06-08 18:28:08       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9738233317294197
[2018-06-08 18:28:08       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9749787458868697
[2018-06-08 18:28:09       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9759512641432464
[2018-06-08 18:28:10       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9759271539936146
[2018-06-08 18:28:10       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.976460481647614
[2018-06-08 18:28:11       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.975694027815157
[2018-06-08 18:28:12       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9778486019733497
[2018-06-08 18:28:13       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9768464448201525
[2018-06-08 18:28:13       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.977539644397045
[2018-06-08 18:28:14       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9775757245257647
[2018-06-08 18:28:15       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9736175981871383
[2018-06-08 18:28:16       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9765853956687329
[2018-06-08 18:28:16       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9751761596347157
[2018-06-08 18:28:17       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9733442269991971
[2018-06-08 18:28:18       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9774283113630696
[2018-06-08 18:28:18       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9763584392340416
[2018-06-08 18:28:19       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9764520337171066
[2018-06-08 18:28:20       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9760733958052734
[2018-06-08 18:28:21       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9775144419195253
[2018-06-08 18:28:21       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.976942988380717
[2018-06-08 18:28:22       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9726852307362602
[2018-06-08 18:28:23       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9768234508899504
[2018-06-08 18:28:24       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9777621846366362
[2018-06-08 18:28:25       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.976843052862796
[2018-06-08 18:28:25       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9778913433266524
[2018-06-08 18:28:26       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9756020726906288
[2018-06-08 18:28:27       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9778663145897312
[2018-06-08 18:28:28       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9769969680778472
[2018-06-08 18:28:28       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9737584676819522
[2018-06-08 18:28:29       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9766712230693667
[2018-06-08 18:28:30       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9742156112249941
[2018-06-08 18:28:31       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9761805492942941
[2018-06-08 18:28:31       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.975956549160824
[2018-06-08 18:28:32       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9768476137038969
[2018-06-08 18:28:33       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9762838730005836
[2018-06-08 18:28:34       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9746552807877229
[2018-06-08 18:28:34       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9776321298055604
[2018-06-08 18:28:35       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9770437629048581
[2018-06-08 18:28:36       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9780527712013626
[2018-06-08 18:28:37       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9767302538902005
[2018-06-08 18:28:37       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:28:37       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:28:37       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:28:37       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_24.pickle"
[2018-06-08 18:28:37  start_training.py:128 -                      main()] Fidelity obtained: 0.9763405115591384
[2018-06-08 18:28:39  start_training.py: 99 -                      main()] Starting training no.25
[2018-06-08 18:28:39  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 18:28:39    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:28:39    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:28:39    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:28:39    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:28:39           model.py:140 -       _set_initial_values()] Initial parameters values: 1.
[2018-06-08 18:28:39           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:28:39           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:28:39       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:28:39       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:28:39       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:28:39       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:28:39       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:28:39       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:28:39       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:28:39       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:28:39       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:28:39       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:28:43       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:28:44       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.22970572664013555
[2018-06-08 18:28:45       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6855423012242603
[2018-06-08 18:28:45       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9368910084271619
[2018-06-08 18:28:46       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8963745622318211
[2018-06-08 18:28:47       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9252715461766653
[2018-06-08 18:28:48       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9776303641871636
[2018-06-08 18:28:48       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9720189382733325
[2018-06-08 18:28:49       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.952669575275878
[2018-06-08 18:28:50       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9308254086035932
[2018-06-08 18:28:51       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9793044265430602
[2018-06-08 18:28:51       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.981736550973392
[2018-06-08 18:28:52       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9812322916946508
[2018-06-08 18:28:53       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9494584822173374
[2018-06-08 18:28:54       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9748861459798782
[2018-06-08 18:28:54       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9794012242956605
[2018-06-08 18:28:55       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9808739794932388
[2018-06-08 18:28:56       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9791945667842686
[2018-06-08 18:28:57       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9830984381792434
[2018-06-08 18:28:57       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9685210644373243
[2018-06-08 18:28:58       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9796243163833245
[2018-06-08 18:28:59       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9806450526902845
[2018-06-08 18:29:00       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9836151540694624
[2018-06-08 18:29:00       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.979336342355626
[2018-06-08 18:29:01       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9835823531105471
[2018-06-08 18:29:02       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9808899061285398
[2018-06-08 18:29:02       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9838171462946241
[2018-06-08 18:29:03       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9825182550747991
[2018-06-08 18:29:04       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9795928699298986
[2018-06-08 18:29:04       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9830340305371528
[2018-06-08 18:29:05       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9848681928290339
[2018-06-08 18:29:06       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9828525746716852
[2018-06-08 18:29:07       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9828340760983734
[2018-06-08 18:29:07       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9835342891264263
[2018-06-08 18:29:08       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9765320244493071
[2018-06-08 18:29:09       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9844532996787843
[2018-06-08 18:29:10       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9826570915525751
[2018-06-08 18:29:10       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9823140497926963
[2018-06-08 18:29:11       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9827986824092324
[2018-06-08 18:29:12       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9846632561524374
[2018-06-08 18:29:13       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.983037112601192
[2018-06-08 18:29:13       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9844919017150029
[2018-06-08 18:29:14       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.982505998387379
[2018-06-08 18:29:15       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9816580461726532
[2018-06-08 18:29:15       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.984166896946725
[2018-06-08 18:29:16       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9834454370864417
[2018-06-08 18:29:17       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9818208221607704
[2018-06-08 18:29:17       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9831375349911834
[2018-06-08 18:29:18       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9850984932984165
[2018-06-08 18:29:19       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9848785788841772
[2018-06-08 18:29:20       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.984973956141865
[2018-06-08 18:29:20       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9839042614363926
[2018-06-08 18:29:21       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9844669020222112
[2018-06-08 18:29:22       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9828828620535479
[2018-06-08 18:29:23       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.98486477876904
[2018-06-08 18:29:23       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9849424875190587
[2018-06-08 18:29:24       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9839785328053762
[2018-06-08 18:29:25       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9840719217584061
[2018-06-08 18:29:25       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9845966419536186
[2018-06-08 18:29:26       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9837658167952696
[2018-06-08 18:29:27       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9846277553121506
[2018-06-08 18:29:28       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.984560459486077
[2018-06-08 18:29:28       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9840359347742651
[2018-06-08 18:29:29       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9836328753815761
[2018-06-08 18:29:30       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9848294038376869
[2018-06-08 18:29:31       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9834604364405756
[2018-06-08 18:29:31       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.983728902208064
[2018-06-08 18:29:32       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9842715826056383
[2018-06-08 18:29:33       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9838746237676745
[2018-06-08 18:29:33       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9837838162877661
[2018-06-08 18:29:34       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9834016237194386
[2018-06-08 18:29:35       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9840062855375957
[2018-06-08 18:29:36       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.984750457783073
[2018-06-08 18:29:36       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9823704145768896
[2018-06-08 18:29:37       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9851869761376971
[2018-06-08 18:29:38       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9846547835712433
[2018-06-08 18:29:39       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.985281797362667
[2018-06-08 18:29:39       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9846265689634116
[2018-06-08 18:29:40       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9845731872122855
[2018-06-08 18:29:41       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.984239024244172
[2018-06-08 18:29:42       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.983560818137124
[2018-06-08 18:29:42       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9841790620849622
[2018-06-08 18:29:43       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9844750121394509
[2018-06-08 18:29:44       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9851518339348874
[2018-06-08 18:29:45       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9847515411889027
[2018-06-08 18:29:45       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9845123872484094
[2018-06-08 18:29:46       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9846367085666116
[2018-06-08 18:29:47       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9842914403509951
[2018-06-08 18:29:48       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9848611017858009
[2018-06-08 18:29:48       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9848544891448645
[2018-06-08 18:29:49       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9846567166950979
[2018-06-08 18:29:50       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9847844837946832
[2018-06-08 18:29:50       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9846358858233919
[2018-06-08 18:29:51       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9847017553898658
[2018-06-08 18:29:52       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9846082693345547
[2018-06-08 18:29:53       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9847934898247181
[2018-06-08 18:29:53       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9837302081868782
[2018-06-08 18:29:54       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9843193222081932
[2018-06-08 18:29:55       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9846582274231082
[2018-06-08 18:29:56       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9848663350408212
[2018-06-08 18:29:56       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9851137216244445
[2018-06-08 18:29:56       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:29:56       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:29:56       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:29:56       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_25.pickle"
[2018-06-08 18:29:56  start_training.py:128 -                      main()] Fidelity obtained: 0.9849826543965725
[2018-06-08 18:29:59  start_training.py: 99 -                      main()] Starting training no.26
[2018-06-08 18:29:59  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 18:29:59    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:29:59    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:29:59    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:29:59    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:29:59           model.py:140 -       _set_initial_values()] Initial parameters values: 1.
[2018-06-08 18:29:59           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:29:59           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:29:59       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:29:59       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:29:59       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:29:59       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:29:59       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:29:59       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:29:59       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:30:00       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:30:00       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:30:00       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:30:04       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:30:04       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5542117707543972
[2018-06-08 18:30:05       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5848176380045012
[2018-06-08 18:30:06       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8719585390873013
[2018-06-08 18:30:07       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8501071645762004
[2018-06-08 18:30:08       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8779570087893741
[2018-06-08 18:30:08       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8838838811196816
[2018-06-08 18:30:09       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8623126478984574
[2018-06-08 18:30:10       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8851315522582329
[2018-06-08 18:30:11       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8696979740089462
[2018-06-08 18:30:12       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8667836372874891
[2018-06-08 18:30:12       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.916935816860611
[2018-06-08 18:30:13       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9022356463531871
[2018-06-08 18:30:14       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9351742170501346
[2018-06-08 18:30:15       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9099517680754474
[2018-06-08 18:30:16       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9039783095422803
[2018-06-08 18:30:16       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9300120651426245
[2018-06-08 18:30:17       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9132551624167864
[2018-06-08 18:30:18       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9330804430952726
[2018-06-08 18:30:19       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9097236458437318
[2018-06-08 18:30:20       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9343602817122678
[2018-06-08 18:30:20       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9246710568807268
[2018-06-08 18:30:21       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9221713847980808
[2018-06-08 18:30:22       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9300201709854632
[2018-06-08 18:30:22       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9346869584468986
[2018-06-08 18:30:23       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9311718931107055
[2018-06-08 18:30:24       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9319501269670277
[2018-06-08 18:30:25       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9292039598181028
[2018-06-08 18:30:25       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9094210104043725
[2018-06-08 18:30:26       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9267081512573198
[2018-06-08 18:30:27       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9338061286406344
[2018-06-08 18:30:28       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.929127712463854
[2018-06-08 18:30:29       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9288556572189371
[2018-06-08 18:30:29       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9191776053296866
[2018-06-08 18:30:30       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9361071195775554
[2018-06-08 18:30:31       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9270215970406146
[2018-06-08 18:30:32       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.924272009807408
[2018-06-08 18:30:33       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9204915052551935
[2018-06-08 18:30:33       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9269902157214998
[2018-06-08 18:30:34       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9340966571954694
[2018-06-08 18:30:35       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9267482561365695
[2018-06-08 18:30:36       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9289408900992489
[2018-06-08 18:30:36       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9348921878930225
[2018-06-08 18:30:37       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9230467028794215
[2018-06-08 18:30:38       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9297505287031302
[2018-06-08 18:30:39       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9325150004025794
[2018-06-08 18:30:40       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9364825388199042
[2018-06-08 18:30:40       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9176731297581417
[2018-06-08 18:30:41       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9358154181450052
[2018-06-08 18:30:42       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9340892988333337
[2018-06-08 18:30:43       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9329059267727311
[2018-06-08 18:30:44       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9311010656718427
[2018-06-08 18:30:44       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9271077463054082
[2018-06-08 18:30:45       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9341744881827309
[2018-06-08 18:30:46       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9287118862457129
[2018-06-08 18:30:47       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9321139121570777
[2018-06-08 18:30:48       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9367026541200018
[2018-06-08 18:30:48       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9358575296601677
[2018-06-08 18:30:49       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9321729957418654
[2018-06-08 18:30:50       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9369254786625706
[2018-06-08 18:30:51       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9300006900369301
[2018-06-08 18:30:52       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9361809383703158
[2018-06-08 18:30:52       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9263874818808823
[2018-06-08 18:30:53       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9353891330435985
[2018-06-08 18:30:54       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9295869193105268
[2018-06-08 18:30:54       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.935002523241325
[2018-06-08 18:30:55       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9363885638682713
[2018-06-08 18:30:56       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9360294004865962
[2018-06-08 18:30:57       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9336213931604803
[2018-06-08 18:30:58       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9362009971173125
[2018-06-08 18:30:58       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9301776448476318
[2018-06-08 18:30:59       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9359874092351204
[2018-06-08 18:31:00       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9365911975373205
[2018-06-08 18:31:01       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9365960837154594
[2018-06-08 18:31:02       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9373954218009934
[2018-06-08 18:31:02       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9360811224267516
[2018-06-08 18:31:03       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9214328908119093
[2018-06-08 18:31:04       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9364431211742165
[2018-06-08 18:31:04       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9334605595722771
[2018-06-08 18:31:05       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9362094075880925
[2018-06-08 18:31:06       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9339863752056706
[2018-06-08 18:31:07       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9343720565991813
[2018-06-08 18:31:08       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9335693113754485
[2018-06-08 18:31:08       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9378412538886797
[2018-06-08 18:31:09       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9346824317993611
[2018-06-08 18:31:10       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.937470617613103
[2018-06-08 18:31:11       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9351756201388751
[2018-06-08 18:31:12       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9330774785934579
[2018-06-08 18:31:12       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9356914053962849
[2018-06-08 18:31:13       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9362683206249328
[2018-06-08 18:31:14       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9209868645527611
[2018-06-08 18:31:15       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9370400932668461
[2018-06-08 18:31:15       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9346397913056701
[2018-06-08 18:31:16       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9326853856302822
[2018-06-08 18:31:17       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9368957212991201
[2018-06-08 18:31:18       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9373661091122769
[2018-06-08 18:31:19       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9378368430039825
[2018-06-08 18:31:19       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9333703781367187
[2018-06-08 18:31:20       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9373933610235367
[2018-06-08 18:31:21       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9341898010611048
[2018-06-08 18:31:22       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9378610211149254
[2018-06-08 18:31:22       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:31:22       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:31:22       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:31:22       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_26.pickle"
[2018-06-08 18:31:22  start_training.py:128 -                      main()] Fidelity obtained: 0.9383754975148344
[2018-06-08 18:31:25  start_training.py: 99 -                      main()] Starting training no.27
[2018-06-08 18:31:25  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 18:31:25    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:31:25    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:31:25    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:31:25    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:31:25           model.py:140 -       _set_initial_values()] Initial parameters values: 1.
[2018-06-08 18:31:25           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:31:25           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:31:25       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:31:25       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:31:25       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:31:25       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:31:25       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:31:25       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:31:25       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:31:25       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:31:25       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:31:25       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:31:29       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:31:29       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.49962075008090145
[2018-06-08 18:31:30       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8117800819457323
[2018-06-08 18:31:31       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9846229047385271
[2018-06-08 18:31:32       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9954662261892031
[2018-06-08 18:31:33       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9989159109981284
[2018-06-08 18:31:33       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9998456023974538
[2018-06-08 18:31:34       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9998945947355942
[2018-06-08 18:31:35       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.999826597726322
[2018-06-08 18:31:36       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9998694525865716
[2018-06-08 18:31:36       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9997827007748622
[2018-06-08 18:31:37       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9996225860109976
[2018-06-08 18:31:38       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9998996591689918
[2018-06-08 18:31:39       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9998563420311432
[2018-06-08 18:31:40       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9998824903704869
[2018-06-08 18:31:41       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9998856156410766
[2018-06-08 18:31:41       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9998917947160034
[2018-06-08 18:31:42       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999087502560289
[2018-06-08 18:31:43       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9998819292883302
[2018-06-08 18:31:43       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.999872837206984
[2018-06-08 18:31:44       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999095076198218
[2018-06-08 18:31:45       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.999907340318927
[2018-06-08 18:31:46       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9998760136595533
[2018-06-08 18:31:47       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9998935117304019
[2018-06-08 18:31:48       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9998985300571194
[2018-06-08 18:31:48       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9998990766020098
[2018-06-08 18:31:49       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999030253617023
[2018-06-08 18:31:50       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9998832253476586
[2018-06-08 18:31:51       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9998979008739132
[2018-06-08 18:31:52       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999015213517799
[2018-06-08 18:31:52       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9998989869037598
[2018-06-08 18:31:53       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9998986639362843
[2018-06-08 18:31:54       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999040262868948
[2018-06-08 18:31:54       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999089328942351
[2018-06-08 18:31:55       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9998572250729006
[2018-06-08 18:31:56       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999081734282735
[2018-06-08 18:31:57       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.999895744654863
[2018-06-08 18:31:57       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9998621963200245
[2018-06-08 18:31:58       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9998907029679839
[2018-06-08 18:31:59       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999042295389644
[2018-06-08 18:32:00       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9998685858545636
[2018-06-08 18:32:01       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999053232107389
[2018-06-08 18:32:02       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.999902651725051
[2018-06-08 18:32:02       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9998958142194562
[2018-06-08 18:32:03       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999023830063684
[2018-06-08 18:32:04       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999005890600664
[2018-06-08 18:32:05       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999045353775563
[2018-06-08 18:32:06       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999077494418631
[2018-06-08 18:32:06       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9998998243242925
[2018-06-08 18:32:07       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999025292167678
[2018-06-08 18:32:08       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.999908497968407
[2018-06-08 18:32:09       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.999910516212083
[2018-06-08 18:32:10       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999083859493002
[2018-06-08 18:32:10       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9998968329200928
[2018-06-08 18:32:11       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999060027789147
[2018-06-08 18:32:12       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9998916312605541
[2018-06-08 18:32:13       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9998987912892143
[2018-06-08 18:32:14       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999084642199888
[2018-06-08 18:32:15       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9998979744742535
[2018-06-08 18:32:15       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.999876398704123
[2018-06-08 18:32:16       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999027827715942
[2018-06-08 18:32:17       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999111940205998
[2018-06-08 18:32:18       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999086142935785
[2018-06-08 18:32:19       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999007047826132
[2018-06-08 18:32:19       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999030627149268
[2018-06-08 18:32:20       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999023514077037
[2018-06-08 18:32:21       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.999907194681801
[2018-06-08 18:32:22       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.999904403786893
[2018-06-08 18:32:23       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999059224579099
[2018-06-08 18:32:24       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999031689945894
[2018-06-08 18:32:24       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999103011655893
[2018-06-08 18:32:25       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.999908517076307
[2018-06-08 18:32:26       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9998973976867922
[2018-06-08 18:32:27       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.999908675815631
[2018-06-08 18:32:28       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999090737252776
[2018-06-08 18:32:29       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999011256834001
[2018-06-08 18:32:29       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999049421820065
[2018-06-08 18:32:30       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999082141752319
[2018-06-08 18:32:31       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999018385867121
[2018-06-08 18:32:32       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999073764626529
[2018-06-08 18:32:33       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999068716798131
[2018-06-08 18:32:34       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999060847007618
[2018-06-08 18:32:34       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999001383699196
[2018-06-08 18:32:35       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999102895162327
[2018-06-08 18:32:36       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.99988857190724
[2018-06-08 18:32:37       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.999907830009412
[2018-06-08 18:32:37       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999086198058277
[2018-06-08 18:32:38       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999074686771892
[2018-06-08 18:32:39       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999100352418466
[2018-06-08 18:32:40       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999116618866292
[2018-06-08 18:32:41       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999084978724937
[2018-06-08 18:32:41       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.999900957637809
[2018-06-08 18:32:42       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999071116878636
[2018-06-08 18:32:43       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999087836519507
[2018-06-08 18:32:44       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999002656314676
[2018-06-08 18:32:45       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999107108492169
[2018-06-08 18:32:45       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999089855986593
[2018-06-08 18:32:46       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999028680096508
[2018-06-08 18:32:47       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.99990645514714
[2018-06-08 18:32:48       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999004304472457
[2018-06-08 18:32:49       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999110395426158
[2018-06-08 18:32:49       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:32:49       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:32:49       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:32:49       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_27.pickle"
[2018-06-08 18:32:49  start_training.py:128 -                      main()] Fidelity obtained: 0.9999118015076038
[2018-06-08 18:32:52  start_training.py: 99 -                      main()] Starting training no.28
[2018-06-08 18:32:52  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 18:32:52    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:32:52    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:32:52    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:32:52    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:32:52           model.py:140 -       _set_initial_values()] Initial parameters values: 1.
[2018-06-08 18:32:52           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:32:52           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:32:52       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:32:52       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:32:52       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:32:52       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:32:52       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:32:52       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:32:52       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:32:52       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:32:52       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:32:52       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:32:56       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:32:56       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7924385584788207
[2018-06-08 18:32:57       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.3966802327459205
[2018-06-08 18:32:58       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8954754171618441
[2018-06-08 18:32:58       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9519094144746783
[2018-06-08 18:32:59       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9808909355952035
[2018-06-08 18:33:00       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9627077734122147
[2018-06-08 18:33:01       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9659907205690651
[2018-06-08 18:33:01       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9770846171959991
[2018-06-08 18:33:02       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9776252057033363
[2018-06-08 18:33:03       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9707732309845446
[2018-06-08 18:33:04       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9607719958490958
[2018-06-08 18:33:04       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9792435982538886
[2018-06-08 18:33:05       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9749785155598726
[2018-06-08 18:33:06       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9802602511192489
[2018-06-08 18:33:06       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9809825614853723
[2018-06-08 18:33:07       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9825836134741531
[2018-06-08 18:33:08       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9846588181053284
[2018-06-08 18:33:09       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9822704804032282
[2018-06-08 18:33:09       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9815990649306988
[2018-06-08 18:33:10       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.982781902713308
[2018-06-08 18:33:11       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9845468714207967
[2018-06-08 18:33:12       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9842988623839924
[2018-06-08 18:33:12       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9840687248176587
[2018-06-08 18:33:13       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.983034446874075
[2018-06-08 18:33:14       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9828233630054892
[2018-06-08 18:33:15       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9847223053976392
[2018-06-08 18:33:15       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9824611658478026
[2018-06-08 18:33:16       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9844292169424006
[2018-06-08 18:33:17       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9821592391513864
[2018-06-08 18:33:17       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9820360747112639
[2018-06-08 18:33:18       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9836457233566034
[2018-06-08 18:33:19       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9827667920984793
[2018-06-08 18:33:20       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9822375699749327
[2018-06-08 18:33:20       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9838461879126086
[2018-06-08 18:33:21       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9823559581015394
[2018-06-08 18:33:22       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9834087467641676
[2018-06-08 18:33:23       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9817104730444011
[2018-06-08 18:33:24       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9844670226542194
[2018-06-08 18:33:24       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9838223252889747
[2018-06-08 18:33:25       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9835390634332047
[2018-06-08 18:33:26       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9843270815216839
[2018-06-08 18:33:27       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9833060886374088
[2018-06-08 18:33:27       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9846351957284588
[2018-06-08 18:33:28       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9834729504780596
[2018-06-08 18:33:29       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9826024946619688
[2018-06-08 18:33:30       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9812238857756543
[2018-06-08 18:33:30       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9844426517179573
[2018-06-08 18:33:31       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.982709753723515
[2018-06-08 18:33:32       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.98538364923806
[2018-06-08 18:33:33       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9851947332662023
[2018-06-08 18:33:33       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9831158768989587
[2018-06-08 18:33:34       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9846910944737763
[2018-06-08 18:33:35       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9851082061088569
[2018-06-08 18:33:36       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9840674809470876
[2018-06-08 18:33:36       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9837865374286142
[2018-06-08 18:33:37       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9854831217428044
[2018-06-08 18:33:38       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9832531696066407
[2018-06-08 18:33:39       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9843443261763134
[2018-06-08 18:33:39       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9837797768256806
[2018-06-08 18:33:40       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.985086351533606
[2018-06-08 18:33:41       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9843615053473711
[2018-06-08 18:33:41       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9841764989548882
[2018-06-08 18:33:42       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9851100548393552
[2018-06-08 18:33:43       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9838367182115373
[2018-06-08 18:33:44       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9851140847094991
[2018-06-08 18:33:44       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.985085866393345
[2018-06-08 18:33:45       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9833081682266207
[2018-06-08 18:33:46       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9842965943947378
[2018-06-08 18:33:47       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9817896321744825
[2018-06-08 18:33:47       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.985261550886819
[2018-06-08 18:33:48       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9834992957278871
[2018-06-08 18:33:49       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.984993907715021
[2018-06-08 18:33:50       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.983274963674324
[2018-06-08 18:33:50       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.984268248001939
[2018-06-08 18:33:51       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9844402270143335
[2018-06-08 18:33:52       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9843730282245601
[2018-06-08 18:33:53       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9817279571680483
[2018-06-08 18:33:53       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9841973844149361
[2018-06-08 18:33:54       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9843340921446978
[2018-06-08 18:33:55       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9838604047391628
[2018-06-08 18:33:56       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9850329730836432
[2018-06-08 18:33:56       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9840306284846241
[2018-06-08 18:33:57       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9846509709306236
[2018-06-08 18:33:58       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9831981588844364
[2018-06-08 18:33:58       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9851637950784772
[2018-06-08 18:33:59       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9851943714761049
[2018-06-08 18:34:00       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.984474033250244
[2018-06-08 18:34:00       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9853645132146509
[2018-06-08 18:34:01       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9851028386925532
[2018-06-08 18:34:02       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9848685153696225
[2018-06-08 18:34:03       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9844642623335953
[2018-06-08 18:34:03       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9851647853428256
[2018-06-08 18:34:04       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9845597212011397
[2018-06-08 18:34:05       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9852489185071556
[2018-06-08 18:34:06       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9844365895621177
[2018-06-08 18:34:06       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9854605409996371
[2018-06-08 18:34:07       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9839027438674287
[2018-06-08 18:34:08       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9847446234983505
[2018-06-08 18:34:09       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9847702413142676
[2018-06-08 18:34:09       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9850818113296657
[2018-06-08 18:34:09       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:34:09       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:34:09       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:34:09       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_28.pickle"
[2018-06-08 18:34:09  start_training.py:128 -                      main()] Fidelity obtained: 0.984508310799442
[2018-06-08 18:34:12  start_training.py: 99 -                      main()] Starting training no.29
[2018-06-08 18:34:12  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 18:34:12    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:34:12    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:34:12    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:34:12    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:34:12           model.py:140 -       _set_initial_values()] Initial parameters values: 1.
[2018-06-08 18:34:12           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:34:12           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:34:12       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:34:12       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:34:12       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:34:12       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:34:12       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:34:12       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:34:12       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:34:12       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:34:12       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:34:12       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:34:16       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:34:17       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.11713055710120543
[2018-06-08 18:34:17       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.27994967510031693
[2018-06-08 18:34:18       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.5408908271546777
[2018-06-08 18:34:19       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.4246956513418351
[2018-06-08 18:34:20       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.914824098695976
[2018-06-08 18:34:20       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9365282352974569
[2018-06-08 18:34:21       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9775834165289897
[2018-06-08 18:34:22       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9104581959869046
[2018-06-08 18:34:23       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9255138853633551
[2018-06-08 18:34:24       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9755851262438732
[2018-06-08 18:34:24       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9569161229351721
[2018-06-08 18:34:25       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9640748662751939
[2018-06-08 18:34:26       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9722192195364469
[2018-06-08 18:34:27       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9530479287232794
[2018-06-08 18:34:27       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9832608488438397
[2018-06-08 18:34:28       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9620895302508459
[2018-06-08 18:34:29       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9797142772016398
[2018-06-08 18:34:30       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9786182553037736
[2018-06-08 18:34:30       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.979748483849258
[2018-06-08 18:34:31       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9787825552283596
[2018-06-08 18:34:32       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9845392694656023
[2018-06-08 18:34:33       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9836150170643438
[2018-06-08 18:34:33       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9842389390016925
[2018-06-08 18:34:34       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9780243935519733
[2018-06-08 18:34:35       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9776020985289685
[2018-06-08 18:34:36       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9732942358632488
[2018-06-08 18:34:36       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9822599453688098
[2018-06-08 18:34:37       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9826785789423189
[2018-06-08 18:34:38       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.984686116984159
[2018-06-08 18:34:39       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9716131577191984
[2018-06-08 18:34:39       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9837260834004659
[2018-06-08 18:34:40       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9837353960351872
[2018-06-08 18:34:41       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9806609221652114
[2018-06-08 18:34:42       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9792693123916193
[2018-06-08 18:34:42       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9850483678356861
[2018-06-08 18:34:43       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9810517275892425
[2018-06-08 18:34:44       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.98402883057201
[2018-06-08 18:34:45       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9844541196875036
[2018-06-08 18:34:45       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9791431235992871
[2018-06-08 18:34:46       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9832578336181033
[2018-06-08 18:34:47       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9841721833548607
[2018-06-08 18:34:48       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9772502802873635
[2018-06-08 18:34:49       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9837181353135938
[2018-06-08 18:34:49       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9800387801354414
[2018-06-08 18:34:50       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9839781151628822
[2018-06-08 18:34:51       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9821483689768403
[2018-06-08 18:34:52       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.983115871237056
[2018-06-08 18:34:52       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9824838045913026
[2018-06-08 18:34:53       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.984881096549276
[2018-06-08 18:34:54       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9841777589533414
[2018-06-08 18:34:55       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9849043158108024
[2018-06-08 18:34:56       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9852073532787867
[2018-06-08 18:34:56       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9802505369742728
[2018-06-08 18:34:57       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9854843225494114
[2018-06-08 18:34:58       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9843050040266337
[2018-06-08 18:34:59       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.985237710581685
[2018-06-08 18:34:59       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9823746789861901
[2018-06-08 18:35:00       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.984093886467959
[2018-06-08 18:35:01       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9819815812830971
[2018-06-08 18:35:02       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9832711560290228
[2018-06-08 18:35:03       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9841612093632206
[2018-06-08 18:35:03       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9832830790560759
[2018-06-08 18:35:04       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9800162543641526
[2018-06-08 18:35:05       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9852235343235397
[2018-06-08 18:35:06       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9820635213456731
[2018-06-08 18:35:07       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9853636715457883
[2018-06-08 18:35:07       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9847501945886239
[2018-06-08 18:35:08       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9841374849203061
[2018-06-08 18:35:09       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9842776099306573
[2018-06-08 18:35:10       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9839627613828644
[2018-06-08 18:35:11       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9846696739983771
[2018-06-08 18:35:12       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9847600714827905
[2018-06-08 18:35:12       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9842893552320053
[2018-06-08 18:35:13       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9849535368712768
[2018-06-08 18:35:14       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9844341244706333
[2018-06-08 18:35:15       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9847325374980211
[2018-06-08 18:35:16       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9839513067844301
[2018-06-08 18:35:16       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9852463098081854
[2018-06-08 18:35:17       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9854058610898332
[2018-06-08 18:35:18       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9848477027975787
[2018-06-08 18:35:19       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.983825771351379
[2018-06-08 18:35:20       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.983751597994685
[2018-06-08 18:35:20       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9827436851355145
[2018-06-08 18:35:21       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.984415712191803
[2018-06-08 18:35:22       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9848855622672571
[2018-06-08 18:35:23       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9840541215139206
[2018-06-08 18:35:24       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9831313105935249
[2018-06-08 18:35:24       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9851851808298396
[2018-06-08 18:35:25       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9847808294751832
[2018-06-08 18:35:26       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9844334219570932
[2018-06-08 18:35:27       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9853484430115784
[2018-06-08 18:35:27       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9851464774795566
[2018-06-08 18:35:28       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9855335135054331
[2018-06-08 18:35:29       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9843592094643931
[2018-06-08 18:35:30       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9841661242376263
[2018-06-08 18:35:31       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9856557265551409
[2018-06-08 18:35:31       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9852683899680524
[2018-06-08 18:35:32       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9850859118718474
[2018-06-08 18:35:33       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.984279819558676
[2018-06-08 18:35:34       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9826700069809357
[2018-06-08 18:35:34       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:35:34       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:35:34       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:35:34       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_29.pickle"
[2018-06-08 18:35:34  start_training.py:128 -                      main()] Fidelity obtained: 0.9829420652676862
[2018-06-08 18:35:36  start_training.py: 99 -                      main()] Starting training no.30
[2018-06-08 18:35:36  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 18:35:36    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:35:36    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:35:36    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:35:36    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:35:36           model.py:140 -       _set_initial_values()] Initial parameters values: 1.
[2018-06-08 18:35:37           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:35:37           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:35:37       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:35:37       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:35:37       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:35:37       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:35:37       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:35:37       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:35:37       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:35:37       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:35:37       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:35:37       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:35:40       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:35:41       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.29283707829511074
[2018-06-08 18:35:42       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5088257002216733
[2018-06-08 18:35:43       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8450671861089961
[2018-06-08 18:35:43       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.734047604151406
[2018-06-08 18:35:44       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7951632154122159
[2018-06-08 18:35:45       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.978670734427292
[2018-06-08 18:35:46       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9944316646348399
[2018-06-08 18:35:46       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9994033228230369
[2018-06-08 18:35:47       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999379782667132
[2018-06-08 18:35:48       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999959057126346
[2018-06-08 18:35:49       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999984006485816
[2018-06-08 18:35:49       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999997545736311
[2018-06-08 18:35:50       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999876304225
[2018-06-08 18:35:51       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999977838518
[2018-06-08 18:35:51       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999997127389
[2018-06-08 18:35:52       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999999507675
[2018-06-08 18:35:53       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999999805935
[2018-06-08 18:35:54       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999999976109
[2018-06-08 18:35:54       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999999995136
[2018-06-08 18:35:55       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999999998879
[2018-06-08 18:35:56       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999999999531
[2018-06-08 18:35:57       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999999999908
[2018-06-08 18:35:57       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999999999989
[2018-06-08 18:35:58       Optimizer.py:490 -                      _run()]   Epoch no. 23: 1.0
[2018-06-08 18:35:58       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:35:58       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:35:58       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:35:58       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:35:58       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_30.pickle"
[2018-06-08 18:35:58  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 18:36:01  start_training.py: 99 -                      main()] Starting training no.31
[2018-06-08 18:36:01  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 18:36:01    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:36:01    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:36:01    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:36:01    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:36:01           model.py:140 -       _set_initial_values()] Initial parameters values: 2.
[2018-06-08 18:36:01           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:36:01           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:36:01       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:36:01       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:36:01       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:36:01       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:36:01       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:36:01       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:36:01       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:36:01       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:36:01       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:36:01       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:36:05       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:36:05       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.4350300128017824
[2018-06-08 18:36:06       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.43104952275127956
[2018-06-08 18:36:07       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6804298826683238
[2018-06-08 18:36:07       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.14958804169090625
[2018-06-08 18:36:08       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8864198920935367
[2018-06-08 18:36:09       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9240711221066829
[2018-06-08 18:36:10       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8538870963857884
[2018-06-08 18:36:10       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.982719703678333
[2018-06-08 18:36:11       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9289825254325781
[2018-06-08 18:36:12       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8798913073237072
[2018-06-08 18:36:13       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9845229384095441
[2018-06-08 18:36:13       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9391305672950054
[2018-06-08 18:36:14       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9997518215990163
[2018-06-08 18:36:15       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999446489424355
[2018-06-08 18:36:16       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999677452121033
[2018-06-08 18:36:16       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999618118721915
[2018-06-08 18:36:17       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999919753973123
[2018-06-08 18:36:18       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999937202282722
[2018-06-08 18:36:19       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999919833778265
[2018-06-08 18:36:19       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999979209285792
[2018-06-08 18:36:20       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999986363849953
[2018-06-08 18:36:21       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999972169815338
[2018-06-08 18:36:21       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999994066498844
[2018-06-08 18:36:22       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.999999373510839
[2018-06-08 18:36:23       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999995797065864
[2018-06-08 18:36:24       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999997523894106
[2018-06-08 18:36:24       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999998028876091
[2018-06-08 18:36:25       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999998525127074
[2018-06-08 18:36:26       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999187409442
[2018-06-08 18:36:27       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999998927149325
[2018-06-08 18:36:27       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999999458578016
[2018-06-08 18:36:28       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999567495621
[2018-06-08 18:36:28       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999999717472309
[2018-06-08 18:36:29       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999755516693
[2018-06-08 18:36:30       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999999801137861
[2018-06-08 18:36:31       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999866255227
[2018-06-08 18:36:31       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999897049123
[2018-06-08 18:36:32       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999999925527938
[2018-06-08 18:36:33       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999999934973228
[2018-06-08 18:36:33       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999943704548
[2018-06-08 18:36:34       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999999947167443
[2018-06-08 18:36:35       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999999959340115
[2018-06-08 18:36:35       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999968788299
[2018-06-08 18:36:36       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.99999999776597
[2018-06-08 18:36:37       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.99999999840578
[2018-06-08 18:36:38       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999984062543
[2018-06-08 18:36:38       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999988020792
[2018-06-08 18:36:39       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999999990415699
[2018-06-08 18:36:40       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999999992296879
[2018-06-08 18:36:41       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999999993568732
[2018-06-08 18:36:41       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999999994509094
[2018-06-08 18:36:42       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999999995570072
[2018-06-08 18:36:43       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999999995334439
[2018-06-08 18:36:44       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999999996248752
[2018-06-08 18:36:44       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999999997052115
[2018-06-08 18:36:45       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.999999999725643
[2018-06-08 18:36:46       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999998211375
[2018-06-08 18:36:46       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999999998433318
[2018-06-08 18:36:47       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999999998562084
[2018-06-08 18:36:48       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999999998854419
[2018-06-08 18:36:48       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999999999051319
[2018-06-08 18:36:49       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999999999079576
[2018-06-08 18:36:50       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.999999999925435
[2018-06-08 18:36:51       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999999999373818
[2018-06-08 18:36:51       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999999999402754
[2018-06-08 18:36:52       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999999999530221
[2018-06-08 18:36:53       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999999999554063
[2018-06-08 18:36:53       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999999999596472
[2018-06-08 18:36:54       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.999999999970041
[2018-06-08 18:36:55       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999999999717901
[2018-06-08 18:36:55       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999999999742468
[2018-06-08 18:36:56       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999999999802328
[2018-06-08 18:36:57       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999999999827703
[2018-06-08 18:36:58       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999999999825371
[2018-06-08 18:36:58       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999999999855212
[2018-06-08 18:36:59       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999999999879686
[2018-06-08 18:37:00       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999999999883827
[2018-06-08 18:37:00       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999999999876173
[2018-06-08 18:37:01       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999999999920659
[2018-06-08 18:37:02       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999999999929304
[2018-06-08 18:37:02       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999999999938332
[2018-06-08 18:37:03       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999999999943873
[2018-06-08 18:37:04       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999999999939952
[2018-06-08 18:37:05       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999999999947707
[2018-06-08 18:37:05       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999999999960509
[2018-06-08 18:37:06       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999999999965449
[2018-06-08 18:37:06       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999999999965331
[2018-06-08 18:37:07       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999999999969134
[2018-06-08 18:37:08       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999999999974016
[2018-06-08 18:37:09       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999999999976659
[2018-06-08 18:37:09       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999999999979527
[2018-06-08 18:37:10       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999999999981057
[2018-06-08 18:37:11       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999999999984288
[2018-06-08 18:37:11       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999999999982869
[2018-06-08 18:37:12       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999999999984409
[2018-06-08 18:37:13       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999999999987099
[2018-06-08 18:37:14       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999999999989186
[2018-06-08 18:37:14       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.999999999998998
[2018-06-08 18:37:15       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999999999991311
[2018-06-08 18:37:16       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999999999992071
[2018-06-08 18:37:16       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:37:16       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:37:16       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:37:16       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_31.pickle"
[2018-06-08 18:37:16  start_training.py:128 -                      main()] Fidelity obtained: 0.9999999999991844
[2018-06-08 18:37:18  start_training.py: 99 -                      main()] Starting training no.32
[2018-06-08 18:37:18  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 18:37:18    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:37:18    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:37:18    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:37:18    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:37:18           model.py:140 -       _set_initial_values()] Initial parameters values: 2.
[2018-06-08 18:37:19           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:37:19           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:37:19       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:37:19       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:37:19       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:37:19       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:37:19       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:37:19       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:37:19       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:37:19       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:37:19       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:37:19       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:37:22       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:37:23       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5483778554105865
[2018-06-08 18:37:23       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5145745227779345
[2018-06-08 18:37:24       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.4338529814887899
[2018-06-08 18:37:25       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.86788783786003
[2018-06-08 18:37:26       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8789090100457713
[2018-06-08 18:37:26       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8893835515456432
[2018-06-08 18:37:27       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9116415783442346
[2018-06-08 18:37:28       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8931847954742558
[2018-06-08 18:37:29       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.7498485237395256
[2018-06-08 18:37:29       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8800368708386225
[2018-06-08 18:37:30       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9007056295261772
[2018-06-08 18:37:31       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.888742603904539
[2018-06-08 18:37:31       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9137726320657698
[2018-06-08 18:37:32       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9140768795724381
[2018-06-08 18:37:33       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9035008447017481
[2018-06-08 18:37:33       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8869290209867554
[2018-06-08 18:37:34       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9191859910191813
[2018-06-08 18:37:35       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9232881299258322
[2018-06-08 18:37:36       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9267700248221834
[2018-06-08 18:37:36       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.906029979200172
[2018-06-08 18:37:37       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9148967124970357
[2018-06-08 18:37:38       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.906281526486717
[2018-06-08 18:37:38       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9260227586864148
[2018-06-08 18:37:39       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9204549048276356
[2018-06-08 18:37:40       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9230316611756758
[2018-06-08 18:37:40       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9287404251622442
[2018-06-08 18:37:41       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9134486853631795
[2018-06-08 18:37:42       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9183018891452366
[2018-06-08 18:37:43       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9256323844608021
[2018-06-08 18:37:43       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9217966100465819
[2018-06-08 18:37:44       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9249959121504172
[2018-06-08 18:37:45       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9265389620684119
[2018-06-08 18:37:46       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.926823894128545
[2018-06-08 18:37:46       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9184234143176776
[2018-06-08 18:37:47       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9177026781898762
[2018-06-08 18:37:48       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9288104912585503
[2018-06-08 18:37:49       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9211393727421598
[2018-06-08 18:37:49       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9233672907112671
[2018-06-08 18:37:50       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9280052050792402
[2018-06-08 18:37:51       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9209155119746982
[2018-06-08 18:37:52       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9252795065268355
[2018-06-08 18:37:52       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9297460840901054
[2018-06-08 18:37:53       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9281656454853975
[2018-06-08 18:37:54       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9259698421189847
[2018-06-08 18:37:54       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9286348191378156
[2018-06-08 18:37:55       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9268345842526814
[2018-06-08 18:37:56       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.930388131840179
[2018-06-08 18:37:57       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9264065487230322
[2018-06-08 18:37:58       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9183996474600913
[2018-06-08 18:37:58       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9256935123166272
[2018-06-08 18:37:59       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9294981222134883
[2018-06-08 18:38:00       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9310556425764854
[2018-06-08 18:38:01       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9269466028043218
[2018-06-08 18:38:01       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9259779369468649
[2018-06-08 18:38:02       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9303498103703037
[2018-06-08 18:38:03       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9298841651393501
[2018-06-08 18:38:03       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9295100469276032
[2018-06-08 18:38:04       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9312877930112812
[2018-06-08 18:38:05       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9294420568301304
[2018-06-08 18:38:05       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9206544575695836
[2018-06-08 18:38:06       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9317210323073875
[2018-06-08 18:38:06       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9227241869986006
[2018-06-08 18:38:07       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9293881475560042
[2018-06-08 18:38:08       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9287743022199052
[2018-06-08 18:38:09       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9305256590266802
[2018-06-08 18:38:09       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9273119250854208
[2018-06-08 18:38:10       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9302828183247388
[2018-06-08 18:38:11       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9299106908889375
[2018-06-08 18:38:11       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9256330170467847
[2018-06-08 18:38:12       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9306313961014291
[2018-06-08 18:38:13       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.927385217957823
[2018-06-08 18:38:13       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9236358824014197
[2018-06-08 18:38:14       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9307158119929246
[2018-06-08 18:38:15       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9303591297574555
[2018-06-08 18:38:16       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9292961239806723
[2018-06-08 18:38:16       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9316331289052147
[2018-06-08 18:38:17       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9282810950342948
[2018-06-08 18:38:18       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9267389037773079
[2018-06-08 18:38:19       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9314266618631905
[2018-06-08 18:38:19       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9262545561622604
[2018-06-08 18:38:20       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9301729781790778
[2018-06-08 18:38:21       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9297729235634792
[2018-06-08 18:38:22       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9292836091058072
[2018-06-08 18:38:22       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9270333308326327
[2018-06-08 18:38:23       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9324875654086064
[2018-06-08 18:38:24       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9218376271689394
[2018-06-08 18:38:25       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9299681949957092
[2018-06-08 18:38:25       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9304976299111709
[2018-06-08 18:38:26       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9295540510063947
[2018-06-08 18:38:27       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9256751129146933
[2018-06-08 18:38:27       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9296205074410596
[2018-06-08 18:38:28       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9320439020502651
[2018-06-08 18:38:29       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9319683333064477
[2018-06-08 18:38:30       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9257649613125432
[2018-06-08 18:38:30       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.93001271163951
[2018-06-08 18:38:31       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9322775926398132
[2018-06-08 18:38:32       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9292200090100351
[2018-06-08 18:38:33       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9301138933533808
[2018-06-08 18:38:33       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9317860368954101
[2018-06-08 18:38:34       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9331216733277569
[2018-06-08 18:38:34       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:38:34       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:38:34       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:38:34       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_32.pickle"
[2018-06-08 18:38:34  start_training.py:128 -                      main()] Fidelity obtained: 0.93557777578685
[2018-06-08 18:38:37  start_training.py: 99 -                      main()] Starting training no.33
[2018-06-08 18:38:37  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 18:38:37    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:38:37    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:38:37    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:38:37    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:38:37           model.py:140 -       _set_initial_values()] Initial parameters values: 2.
[2018-06-08 18:38:37           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:38:37           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:38:37       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:38:37       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:38:37       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:38:37       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:38:37       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:38:37       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:38:37       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:38:37       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:38:37       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:38:37       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:38:41       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:38:41       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8571354768921101
[2018-06-08 18:38:42       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9372700367954654
[2018-06-08 18:38:43       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6611021771389504
[2018-06-08 18:38:44       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8496160713703942
[2018-06-08 18:38:45       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9605387148243549
[2018-06-08 18:38:46       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9498409016320305
[2018-06-08 18:38:46       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.920953379906194
[2018-06-08 18:38:47       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9605560382574366
[2018-06-08 18:38:48       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.965662208369485
[2018-06-08 18:38:49       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9666054777214214
[2018-06-08 18:38:50       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9641762992294679
[2018-06-08 18:38:51       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9682683567128992
[2018-06-08 18:38:51       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.968196049168219
[2018-06-08 18:38:52       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9509796850886117
[2018-06-08 18:38:53       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9608375770980113
[2018-06-08 18:38:54       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9625621897638369
[2018-06-08 18:38:55       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9637344034484605
[2018-06-08 18:38:56       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9580615511422619
[2018-06-08 18:38:56       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9606666648526196
[2018-06-08 18:38:57       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.956061886694349
[2018-06-08 18:38:58       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9552705474576422
[2018-06-08 18:38:59       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9683998705964527
[2018-06-08 18:39:00       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9637642606801675
[2018-06-08 18:39:01       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9643760185951957
[2018-06-08 18:39:01       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9625259547535715
[2018-06-08 18:39:02       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9579862749325601
[2018-06-08 18:39:03       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.967746441303302
[2018-06-08 18:39:04       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9674293788213078
[2018-06-08 18:39:05       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9692021330597055
[2018-06-08 18:39:06       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9695608016481433
[2018-06-08 18:39:06       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9686490051274406
[2018-06-08 18:39:07       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9699735877955835
[2018-06-08 18:39:08       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9648311375685821
[2018-06-08 18:39:09       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9695939645101765
[2018-06-08 18:39:10       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9636737478451342
[2018-06-08 18:39:11       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9630519784715169
[2018-06-08 18:39:11       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9696584911349203
[2018-06-08 18:39:12       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9659472503163782
[2018-06-08 18:39:13       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9692468796081651
[2018-06-08 18:39:14       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9683017591143996
[2018-06-08 18:39:15       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9698107666696312
[2018-06-08 18:39:16       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9682757084313678
[2018-06-08 18:39:16       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9662116181016607
[2018-06-08 18:39:17       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9695813200719189
[2018-06-08 18:39:18       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.970610421070612
[2018-06-08 18:39:19       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9702757045095994
[2018-06-08 18:39:20       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9703206873305483
[2018-06-08 18:39:20       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9681693953799847
[2018-06-08 18:39:21       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9697275880823917
[2018-06-08 18:39:22       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9704372357181766
[2018-06-08 18:39:23       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9711108625752548
[2018-06-08 18:39:24       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9666781263144293
[2018-06-08 18:39:25       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9697677118778103
[2018-06-08 18:39:26       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9690786497192664
[2018-06-08 18:39:26       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9698023371966069
[2018-06-08 18:39:27       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9685210334420509
[2018-06-08 18:39:28       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9709390636360301
[2018-06-08 18:39:29       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9686235851941889
[2018-06-08 18:39:29       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9711526269412007
[2018-06-08 18:39:30       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9707124604313497
[2018-06-08 18:39:31       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9635025857988885
[2018-06-08 18:39:32       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9697217080145744
[2018-06-08 18:39:33       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9663362093368683
[2018-06-08 18:39:33       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9669688796256868
[2018-06-08 18:39:34       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9700925416668674
[2018-06-08 18:39:35       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9705775579502577
[2018-06-08 18:39:36       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9668191321336888
[2018-06-08 18:39:36       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9707905895500943
[2018-06-08 18:39:37       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9671633026802197
[2018-06-08 18:39:38       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.967518993356251
[2018-06-08 18:39:39       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9689797859496775
[2018-06-08 18:39:40       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9697219701805821
[2018-06-08 18:39:40       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9691980826435571
[2018-06-08 18:39:41       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9681115306472017
[2018-06-08 18:39:42       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9702500272458265
[2018-06-08 18:39:43       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9697228077240004
[2018-06-08 18:39:44       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9701404013401778
[2018-06-08 18:39:44       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9686935066018892
[2018-06-08 18:39:45       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9693277750319343
[2018-06-08 18:39:46       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9699536707994066
[2018-06-08 18:39:47       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9706710119117112
[2018-06-08 18:39:48       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9700956929592934
[2018-06-08 18:39:49       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9672148753566452
[2018-06-08 18:39:49       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9707510403815189
[2018-06-08 18:39:50       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.968727570073879
[2018-06-08 18:39:51       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9711938095085023
[2018-06-08 18:39:52       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9648199143301691
[2018-06-08 18:39:53       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9694022100074972
[2018-06-08 18:39:53       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9691300931828601
[2018-06-08 18:39:54       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9698082791026116
[2018-06-08 18:39:55       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9703130406464077
[2018-06-08 18:39:56       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9704726125602151
[2018-06-08 18:39:57       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.970762504292765
[2018-06-08 18:39:58       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9709416921842537
[2018-06-08 18:39:58       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9705182131951666
[2018-06-08 18:39:59       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9704782912347938
[2018-06-08 18:40:00       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9679007573199025
[2018-06-08 18:40:01       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.971122227557473
[2018-06-08 18:40:02       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.97003060935502
[2018-06-08 18:40:02       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9702711531257567
[2018-06-08 18:40:02       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:40:02       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:40:02       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:40:02       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_33.pickle"
[2018-06-08 18:40:02  start_training.py:128 -                      main()] Fidelity obtained: 0.968550823050577
[2018-06-08 18:40:05  start_training.py: 99 -                      main()] Starting training no.34
[2018-06-08 18:40:05  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 18:40:05    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:40:05    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:40:05    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:40:05    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:40:05           model.py:140 -       _set_initial_values()] Initial parameters values: 2.
[2018-06-08 18:40:05           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:40:05           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:40:05       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:40:05       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:40:05       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:40:05       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:40:05       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:40:05       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:40:05       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:40:06       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:40:06       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:40:06       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:40:09       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:40:10       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.11053607298572209
[2018-06-08 18:40:11       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7384644562357942
[2018-06-08 18:40:12       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6579088309862106
[2018-06-08 18:40:12       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7476337285178387
[2018-06-08 18:40:13       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.6229326034815678
[2018-06-08 18:40:14       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8731650404900555
[2018-06-08 18:40:15       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9559621384972907
[2018-06-08 18:40:16       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9865445754766026
[2018-06-08 18:40:16       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9631191555484881
[2018-06-08 18:40:17       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.999746503796607
[2018-06-08 18:40:18       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.999745652322565
[2018-06-08 18:40:19       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9993785921047365
[2018-06-08 18:40:19       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999204252144648
[2018-06-08 18:40:20       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999219898769626
[2018-06-08 18:40:21       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.999874827376725
[2018-06-08 18:40:22       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9998877817685208
[2018-06-08 18:40:22       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999132596297258
[2018-06-08 18:40:23       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999489277098609
[2018-06-08 18:40:24       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.999942299236224
[2018-06-08 18:40:25       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999423269043233
[2018-06-08 18:40:26       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999497646645727
[2018-06-08 18:40:26       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.999946455222895
[2018-06-08 18:40:27       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999486097451871
[2018-06-08 18:40:28       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999575429282805
[2018-06-08 18:40:29       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999631382277029
[2018-06-08 18:40:30       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999644654906561
[2018-06-08 18:40:30       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999726786340811
[2018-06-08 18:40:31       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999614802734413
[2018-06-08 18:40:32       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999744529651631
[2018-06-08 18:40:33       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999741518695251
[2018-06-08 18:40:34       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999587154825683
[2018-06-08 18:40:34       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999778350140474
[2018-06-08 18:40:35       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999793551523577
[2018-06-08 18:40:36       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999800787089146
[2018-06-08 18:40:37       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.999977800134863
[2018-06-08 18:40:38       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999677566833728
[2018-06-08 18:40:38       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999801812430062
[2018-06-08 18:40:39       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999803720371022
[2018-06-08 18:40:40       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999807887322699
[2018-06-08 18:40:41       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999773480654871
[2018-06-08 18:40:42       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999768214222334
[2018-06-08 18:40:42       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999798098513013
[2018-06-08 18:40:43       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999827239736225
[2018-06-08 18:40:44       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999833837973137
[2018-06-08 18:40:45       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.999982080192207
[2018-06-08 18:40:46       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999813915482225
[2018-06-08 18:40:46       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999835894766435
[2018-06-08 18:40:47       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999795488940417
[2018-06-08 18:40:48       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999827823482353
[2018-06-08 18:40:49       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999839861657763
[2018-06-08 18:40:49       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999803554718603
[2018-06-08 18:40:50       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999843382839899
[2018-06-08 18:40:51       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999760713774009
[2018-06-08 18:40:52       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999832295650699
[2018-06-08 18:40:53       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999847090121163
[2018-06-08 18:40:53       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999843194949908
[2018-06-08 18:40:54       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999847884247685
[2018-06-08 18:40:55       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999825049109513
[2018-06-08 18:40:56       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.999983612278292
[2018-06-08 18:40:56       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999847048326758
[2018-06-08 18:40:57       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999857635383096
[2018-06-08 18:40:58       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999819281826205
[2018-06-08 18:40:58       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999844725112885
[2018-06-08 18:40:59       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.999982071406693
[2018-06-08 18:41:00       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999854932349203
[2018-06-08 18:41:00       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999792261247962
[2018-06-08 18:41:01       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999845495935404
[2018-06-08 18:41:02       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999852967031281
[2018-06-08 18:41:03       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999845615381843
[2018-06-08 18:41:04       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999855319659134
[2018-06-08 18:41:04       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999863411402995
[2018-06-08 18:41:05       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999857757835151
[2018-06-08 18:41:06       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999828140841625
[2018-06-08 18:41:07       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999858286376291
[2018-06-08 18:41:07       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999858810180445
[2018-06-08 18:41:08       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999853091121652
[2018-06-08 18:41:09       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.999986271007485
[2018-06-08 18:41:09       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999840866745743
[2018-06-08 18:41:10       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999861068363743
[2018-06-08 18:41:11       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999821602915585
[2018-06-08 18:41:12       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999866749933719
[2018-06-08 18:41:13       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999864009263082
[2018-06-08 18:41:13       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999861883240694
[2018-06-08 18:41:14       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999863340663956
[2018-06-08 18:41:15       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999867110152164
[2018-06-08 18:41:16       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999860150009959
[2018-06-08 18:41:16       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999863215200671
[2018-06-08 18:41:17       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.999987023380219
[2018-06-08 18:41:18       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999849324740516
[2018-06-08 18:41:19       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999863309465156
[2018-06-08 18:41:20       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999830607646615
[2018-06-08 18:41:20       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999864469769237
[2018-06-08 18:41:21       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999860851296792
[2018-06-08 18:41:22       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999868558824031
[2018-06-08 18:41:23       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999834217833358
[2018-06-08 18:41:23       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999868809792771
[2018-06-08 18:41:24       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999866636855289
[2018-06-08 18:41:25       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.999987083688207
[2018-06-08 18:41:26       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999866621698326
[2018-06-08 18:41:26       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999855344928563
[2018-06-08 18:41:26       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:41:26       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:41:26       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:41:26       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_34.pickle"
[2018-06-08 18:41:26  start_training.py:128 -                      main()] Fidelity obtained: 0.9999854850576189
[2018-06-08 18:41:29  start_training.py: 99 -                      main()] Starting training no.35
[2018-06-08 18:41:29  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 18:41:29    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:41:29    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:41:29    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:41:29    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:41:29           model.py:140 -       _set_initial_values()] Initial parameters values: 2.
[2018-06-08 18:41:29           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:41:29           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:41:29       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:41:29       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:41:29       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:41:29       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:41:29       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:41:29       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:41:29       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:41:30       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:41:30       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:41:30       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:41:33       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:41:34       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8064891248878385
[2018-06-08 18:41:35       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8820494374442537
[2018-06-08 18:41:36       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9555289728334
[2018-06-08 18:41:37       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.938620395813623
[2018-06-08 18:41:37       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.937634924564882
[2018-06-08 18:41:38       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9475178484896667
[2018-06-08 18:41:39       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9453252364005331
[2018-06-08 18:41:40       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9442675587976287
[2018-06-08 18:41:40       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9433114597660314
[2018-06-08 18:41:41       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9549275749263468
[2018-06-08 18:41:42       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9582962344763392
[2018-06-08 18:41:43       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9433475795942455
[2018-06-08 18:41:44       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9597916601430377
[2018-06-08 18:41:44       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9665999377584948
[2018-06-08 18:41:45       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9520578514216342
[2018-06-08 18:41:46       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9636297278393529
[2018-06-08 18:41:47       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9677961444542776
[2018-06-08 18:41:48       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9656736491993686
[2018-06-08 18:41:48       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9667010379626615
[2018-06-08 18:41:49       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9642591044229003
[2018-06-08 18:41:50       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9519351383635256
[2018-06-08 18:41:51       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9625115874836625
[2018-06-08 18:41:52       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9595545051799768
[2018-06-08 18:41:52       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9635259453656336
[2018-06-08 18:41:53       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9565523794535444
[2018-06-08 18:41:54       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9642741980019655
[2018-06-08 18:41:55       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9657121858493438
[2018-06-08 18:41:56       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9657109200702407
[2018-06-08 18:41:57       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9615257319435878
[2018-06-08 18:41:57       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9652824514404421
[2018-06-08 18:41:58       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9648960573672342
[2018-06-08 18:41:59       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9674109568737879
[2018-06-08 18:42:00       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.962834645436901
[2018-06-08 18:42:01       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9674924826745959
[2018-06-08 18:42:02       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9646138640610857
[2018-06-08 18:42:02       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9643025152398728
[2018-06-08 18:42:03       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9628736978582988
[2018-06-08 18:42:04       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.961696595104916
[2018-06-08 18:42:05       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.966455911096807
[2018-06-08 18:42:06       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9659613397793485
[2018-06-08 18:42:07       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9629967329082316
[2018-06-08 18:42:07       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9653929287393472
[2018-06-08 18:42:08       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9648893938425226
[2018-06-08 18:42:09       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9673346419783557
[2018-06-08 18:42:10       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9680301090133664
[2018-06-08 18:42:11       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9668636768047422
[2018-06-08 18:42:12       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9659268298970909
[2018-06-08 18:42:13       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9682511633716799
[2018-06-08 18:42:13       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9669297961302311
[2018-06-08 18:42:14       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.967482027878637
[2018-06-08 18:42:15       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9679474129942822
[2018-06-08 18:42:16       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9670762794645708
[2018-06-08 18:42:17       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9672488430791233
[2018-06-08 18:42:18       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9679579794655191
[2018-06-08 18:42:18       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9684930938730519
[2018-06-08 18:42:19       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9664397772598263
[2018-06-08 18:42:20       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9659239087705127
[2018-06-08 18:42:21       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9676904321744706
[2018-06-08 18:42:22       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9682944145752691
[2018-06-08 18:42:22       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9651851714120845
[2018-06-08 18:42:23       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9647664433983627
[2018-06-08 18:42:24       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.967275099255479
[2018-06-08 18:42:25       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.967115054832603
[2018-06-08 18:42:25       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9679117545150349
[2018-06-08 18:42:26       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9667252577647596
[2018-06-08 18:42:27       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9675832430007192
[2018-06-08 18:42:28       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9671138020729377
[2018-06-08 18:42:29       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9672973064431258
[2018-06-08 18:42:29       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9677353636257361
[2018-06-08 18:42:30       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9668587200320792
[2018-06-08 18:42:31       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9678135158808692
[2018-06-08 18:42:32       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9660918124652733
[2018-06-08 18:42:33       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9660117917293153
[2018-06-08 18:42:34       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9672693382809547
[2018-06-08 18:42:34       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.967522458695657
[2018-06-08 18:42:35       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9677300941535816
[2018-06-08 18:42:36       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9659978235763758
[2018-06-08 18:42:37       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9662625991909216
[2018-06-08 18:42:38       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.968046605205323
[2018-06-08 18:42:38       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9670743196404183
[2018-06-08 18:42:39       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9671490669866546
[2018-06-08 18:42:40       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9669143739512681
[2018-06-08 18:42:41       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9670711374371034
[2018-06-08 18:42:42       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9665824195895207
[2018-06-08 18:42:43       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9661895756882177
[2018-06-08 18:42:43       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9669973088644995
[2018-06-08 18:42:44       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9658955649089811
[2018-06-08 18:42:45       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9681876991038736
[2018-06-08 18:42:46       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9649818287912282
[2018-06-08 18:42:47       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9668057279367539
[2018-06-08 18:42:47       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9671036278405425
[2018-06-08 18:42:48       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9684016989010746
[2018-06-08 18:42:49       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.967642922000188
[2018-06-08 18:42:50       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9670316916555741
[2018-06-08 18:42:51       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9659366799077458
[2018-06-08 18:42:51       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9683060099955605
[2018-06-08 18:42:52       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9677691520787418
[2018-06-08 18:42:53       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9668510399770956
[2018-06-08 18:42:54       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9674921437057158
[2018-06-08 18:42:55       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9684958775788022
[2018-06-08 18:42:55       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:42:55       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:42:55       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:42:55       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_35.pickle"
[2018-06-08 18:42:55  start_training.py:128 -                      main()] Fidelity obtained: 0.9689079414062354
[2018-06-08 18:42:58  start_training.py: 99 -                      main()] Starting training no.36
[2018-06-08 18:42:58  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 18:42:58    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:42:58    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:42:58    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:42:58    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:42:58           model.py:140 -       _set_initial_values()] Initial parameters values: 2.
[2018-06-08 18:42:58           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:42:58           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:42:58       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:42:58       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:42:58       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:42:58       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:42:58       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:42:58       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:42:58       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:42:58       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:42:58       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:42:58       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:43:01       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:43:02       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7601906423154365
[2018-06-08 18:43:03       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8509260789374964
[2018-06-08 18:43:04       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8586616224972876
[2018-06-08 18:43:04       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7964744014930466
[2018-06-08 18:43:05       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.6560019620648824
[2018-06-08 18:43:06       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9597646004628316
[2018-06-08 18:43:07       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8839066665710255
[2018-06-08 18:43:07       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.683584842052989
[2018-06-08 18:43:08       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.975427790734533
[2018-06-08 18:43:09       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8926347826318723
[2018-06-08 18:43:10       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9618739766274813
[2018-06-08 18:43:11       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9720283765378868
[2018-06-08 18:43:11       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9639351193991943
[2018-06-08 18:43:12       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9768106932301782
[2018-06-08 18:43:13       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9627753165000328
[2018-06-08 18:43:13       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9616159320389981
[2018-06-08 18:43:14       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9571331702613993
[2018-06-08 18:43:15       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9712706101275776
[2018-06-08 18:43:16       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9646337651094212
[2018-06-08 18:43:16       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9637997070467073
[2018-06-08 18:43:17       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9695102316588552
[2018-06-08 18:43:18       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.975680521292961
[2018-06-08 18:43:18       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9737526807157403
[2018-06-08 18:43:19       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9741045625636849
[2018-06-08 18:43:20       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9673280547725205
[2018-06-08 18:43:21       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.973100124598474
[2018-06-08 18:43:21       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9619507559318262
[2018-06-08 18:43:22       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9768306427175745
[2018-06-08 18:43:23       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9726130779063824
[2018-06-08 18:43:23       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9747844197298319
[2018-06-08 18:43:24       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9741072606631208
[2018-06-08 18:43:25       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9718848521504122
[2018-06-08 18:43:25       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.974862184623349
[2018-06-08 18:43:26       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9701184344130382
[2018-06-08 18:43:27       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9775325507541656
[2018-06-08 18:43:28       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.971890575760526
[2018-06-08 18:43:28       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9754282704554168
[2018-06-08 18:43:29       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9767590289266442
[2018-06-08 18:43:30       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9721806453754566
[2018-06-08 18:43:31       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9741924196972743
[2018-06-08 18:43:32       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9744191966068039
[2018-06-08 18:43:32       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9736376760817406
[2018-06-08 18:43:33       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9753295538500908
[2018-06-08 18:43:34       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9771884455866708
[2018-06-08 18:43:35       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9759906763557943
[2018-06-08 18:43:35       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9760573088647284
[2018-06-08 18:43:36       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9745815406979372
[2018-06-08 18:43:37       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9768012530969069
[2018-06-08 18:43:37       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9645137494209639
[2018-06-08 18:43:38       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9763180583815084
[2018-06-08 18:43:39       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9774147950886622
[2018-06-08 18:43:40       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9767243482171237
[2018-06-08 18:43:40       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9770123264484413
[2018-06-08 18:43:41       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9770143512859006
[2018-06-08 18:43:42       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.975866722376016
[2018-06-08 18:43:43       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9737092876578738
[2018-06-08 18:43:43       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9756370896843098
[2018-06-08 18:43:44       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.976921775183182
[2018-06-08 18:43:45       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9765567361035791
[2018-06-08 18:43:46       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9768468323237495
[2018-06-08 18:43:46       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9767767360754622
[2018-06-08 18:43:47       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9722637511140619
[2018-06-08 18:43:48       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9753731657778411
[2018-06-08 18:43:49       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9774984149759198
[2018-06-08 18:43:49       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9742793239194749
[2018-06-08 18:43:50       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9762779016789552
[2018-06-08 18:43:51       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9735531714608531
[2018-06-08 18:43:52       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9760295953390333
[2018-06-08 18:43:52       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.975194189157882
[2018-06-08 18:43:53       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9767641004990729
[2018-06-08 18:43:54       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9736232655032832
[2018-06-08 18:43:55       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9775766372971727
[2018-06-08 18:43:55       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9759375497650913
[2018-06-08 18:43:56       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9750194397778829
[2018-06-08 18:43:57       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9737200728857534
[2018-06-08 18:43:57       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9746153096310414
[2018-06-08 18:43:58       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9760390248629911
[2018-06-08 18:43:59       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9759437319529074
[2018-06-08 18:44:00       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9775438162227507
[2018-06-08 18:44:00       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9760189690972766
[2018-06-08 18:44:01       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9771456455368822
[2018-06-08 18:44:02       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9765973934256124
[2018-06-08 18:44:03       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9766700074212671
[2018-06-08 18:44:03       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.97755035250486
[2018-06-08 18:44:04       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9767361830310592
[2018-06-08 18:44:05       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9760366818843674
[2018-06-08 18:44:05       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9775362512828387
[2018-06-08 18:44:06       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9758743623361101
[2018-06-08 18:44:07       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9775566692505923
[2018-06-08 18:44:08       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9775048913936408
[2018-06-08 18:44:08       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9760670750841045
[2018-06-08 18:44:09       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9761195500538671
[2018-06-08 18:44:10       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.975736415867846
[2018-06-08 18:44:10       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9754673681055386
[2018-06-08 18:44:11       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9765102500421938
[2018-06-08 18:44:12       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.97340596025191
[2018-06-08 18:44:13       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9770517116062691
[2018-06-08 18:44:13       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9758147803234575
[2018-06-08 18:44:14       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9767224021926013
[2018-06-08 18:44:15       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9769436483799683
[2018-06-08 18:44:15       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:44:15       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:44:15       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:44:15       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_36.pickle"
[2018-06-08 18:44:15  start_training.py:128 -                      main()] Fidelity obtained: 0.9767723504551267
[2018-06-08 18:44:18  start_training.py: 99 -                      main()] Starting training no.37
[2018-06-08 18:44:18  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 18:44:18    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:44:18    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:44:18    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:44:18    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:44:18           model.py:140 -       _set_initial_values()] Initial parameters values: 2.
[2018-06-08 18:44:18           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:44:18           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:44:18       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:44:18       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:44:18       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:44:18       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:44:18       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:44:18       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:44:18       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:44:18       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:44:18       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:44:18       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:44:22       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:44:23       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9325261823083997
[2018-06-08 18:44:23       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9609526875400997
[2018-06-08 18:44:24       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9995712326479778
[2018-06-08 18:44:25       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999985782389724
[2018-06-08 18:44:26       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999998668124
[2018-06-08 18:44:27       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0000000000000002
[2018-06-08 18:44:27       Optimizer.py:490 -                      _run()]   Epoch no. 6: 1.0
[2018-06-08 18:44:27       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:44:27       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:44:27       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:44:27       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:44:27       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_37.pickle"
[2018-06-08 18:44:28  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000002
[2018-06-08 18:44:31  start_training.py: 99 -                      main()] Starting training no.38
[2018-06-08 18:44:31  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 18:44:31    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:44:31    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:44:31    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:44:31    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:44:31           model.py:140 -       _set_initial_values()] Initial parameters values: 2.
[2018-06-08 18:44:31           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:44:31           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:44:31       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:44:31       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:44:31       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:44:31       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:44:31       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:44:31       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:44:31       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:44:31       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:44:31       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:44:31       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:44:35       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:44:35       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.28923110640587135
[2018-06-08 18:44:36       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.43225556802286436
[2018-06-08 18:44:36       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9365333675718435
[2018-06-08 18:44:37       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8377476836339729
[2018-06-08 18:44:38       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.877210794377904
[2018-06-08 18:44:39       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.6797450756098985
[2018-06-08 18:44:40       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9643098888587777
[2018-06-08 18:44:40       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9358317428490378
[2018-06-08 18:44:41       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9619819861376174
[2018-06-08 18:44:42       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9538576009988763
[2018-06-08 18:44:43       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9708760714275754
[2018-06-08 18:44:44       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9717713944950656
[2018-06-08 18:44:44       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9689971127282672
[2018-06-08 18:44:45       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9672870573091167
[2018-06-08 18:44:46       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9752517684337352
[2018-06-08 18:44:47       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9694811788145671
[2018-06-08 18:44:48       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9772921880195861
[2018-06-08 18:44:48       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.973889800118735
[2018-06-08 18:44:49       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9759018477957646
[2018-06-08 18:44:50       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9690627746055527
[2018-06-08 18:44:51       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9773807127385377
[2018-06-08 18:44:51       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9777689479514862
[2018-06-08 18:44:52       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9741549309156283
[2018-06-08 18:44:53       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.974735229331177
[2018-06-08 18:44:54       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9775353963241316
[2018-06-08 18:44:54       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9793153480038501
[2018-06-08 18:44:55       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9756111643929103
[2018-06-08 18:44:56       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9781992988660825
[2018-06-08 18:44:57       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9777238345431389
[2018-06-08 18:44:58       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9738486835061394
[2018-06-08 18:44:59       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9760000046473378
[2018-06-08 18:44:59       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9782559474421184
[2018-06-08 18:45:00       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9778660527698844
[2018-06-08 18:45:01       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9789428148737227
[2018-06-08 18:45:02       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9782631372957993
[2018-06-08 18:45:03       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.970879520025891
[2018-06-08 18:45:03       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9727844162585061
[2018-06-08 18:45:04       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9770419775556947
[2018-06-08 18:45:05       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9803550925787091
[2018-06-08 18:45:06       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9786770476677269
[2018-06-08 18:45:07       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9801123335313394
[2018-06-08 18:45:07       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9795319403676294
[2018-06-08 18:45:08       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9788111573310464
[2018-06-08 18:45:09       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9769449126616299
[2018-06-08 18:45:10       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9801781899446139
[2018-06-08 18:45:11       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9796372062200415
[2018-06-08 18:45:11       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9792006249861376
[2018-06-08 18:45:12       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.979508134038373
[2018-06-08 18:45:13       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9799108285846646
[2018-06-08 18:45:14       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9761364334978718
[2018-06-08 18:45:15       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9753392529338052
[2018-06-08 18:45:16       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9793783345054267
[2018-06-08 18:45:16       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.97921760812548
[2018-06-08 18:45:17       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9790019311980206
[2018-06-08 18:45:18       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9774739897171333
[2018-06-08 18:45:19       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9785882131863748
[2018-06-08 18:45:19       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9794291213459949
[2018-06-08 18:45:20       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9751792029340158
[2018-06-08 18:45:21       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9785591441018121
[2018-06-08 18:45:22       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9798573033069949
[2018-06-08 18:45:22       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9792981718584582
[2018-06-08 18:45:23       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9793865326308846
[2018-06-08 18:45:24       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9786564610074651
[2018-06-08 18:45:25       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9793947866920609
[2018-06-08 18:45:26       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9802255341402787
[2018-06-08 18:45:27       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9797669751684144
[2018-06-08 18:45:27       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9796893965899878
[2018-06-08 18:45:28       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9797506199885807
[2018-06-08 18:45:29       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9782148203206655
[2018-06-08 18:45:30       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9777345662626081
[2018-06-08 18:45:31       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9798701575454409
[2018-06-08 18:45:32       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9804436912958774
[2018-06-08 18:45:32       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9797702286172035
[2018-06-08 18:45:33       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9788335648610343
[2018-06-08 18:45:34       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.979926219311592
[2018-06-08 18:45:34       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9800700706783264
[2018-06-08 18:45:35       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9804027121719383
[2018-06-08 18:45:36       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9803463392208341
[2018-06-08 18:45:37       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.979107241571606
[2018-06-08 18:45:38       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9794904742364064
[2018-06-08 18:45:38       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9801540787067115
[2018-06-08 18:45:39       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9797006920646005
[2018-06-08 18:45:40       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9797752800837278
[2018-06-08 18:45:41       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9800908294350859
[2018-06-08 18:45:41       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9801949206945497
[2018-06-08 18:45:42       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.980366228026919
[2018-06-08 18:45:43       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9797564741065571
[2018-06-08 18:45:44       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9797535454550199
[2018-06-08 18:45:44       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.979714173410606
[2018-06-08 18:45:45       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9797224557308799
[2018-06-08 18:45:46       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9797391462957379
[2018-06-08 18:45:47       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9792543140997942
[2018-06-08 18:45:48       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9796985225470175
[2018-06-08 18:45:48       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9791880395261132
[2018-06-08 18:45:49       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9802381575709821
[2018-06-08 18:45:50       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.980317166917125
[2018-06-08 18:45:51       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9797051582837214
[2018-06-08 18:45:51       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9794530340931381
[2018-06-08 18:45:52       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9765561435787837
[2018-06-08 18:45:53       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9801017813987822
[2018-06-08 18:45:53       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:45:53       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:45:53       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:45:53       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_38.pickle"
[2018-06-08 18:45:53  start_training.py:128 -                      main()] Fidelity obtained: 0.980642388464511
[2018-06-08 18:45:55  start_training.py: 99 -                      main()] Starting training no.39
[2018-06-08 18:45:55  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 18:45:55    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:45:55    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:45:55    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:45:55    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:45:55           model.py:140 -       _set_initial_values()] Initial parameters values: 2.
[2018-06-08 18:45:56           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:45:56           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:45:56       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:45:56       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:45:56       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:45:56       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:45:56       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:45:56       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:45:56       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:45:56       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:45:56       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:45:56       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:45:59       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:46:00       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6480465566161095
[2018-06-08 18:46:01       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7178823652933753
[2018-06-08 18:46:02       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7721302097981022
[2018-06-08 18:46:02       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9647772723682196
[2018-06-08 18:46:03       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9499144872492657
[2018-06-08 18:46:04       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9682308737691696
[2018-06-08 18:46:05       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9767095635156953
[2018-06-08 18:46:06       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9688485301741585
[2018-06-08 18:46:07       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9829184008578328
[2018-06-08 18:46:08       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9819150994960314
[2018-06-08 18:46:08       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.984717037978625
[2018-06-08 18:46:09       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9868462616507773
[2018-06-08 18:46:10       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9866290269898919
[2018-06-08 18:46:11       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.987026272414504
[2018-06-08 18:46:12       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9874922321198588
[2018-06-08 18:46:13       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.984221507582546
[2018-06-08 18:46:13       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9873225671392811
[2018-06-08 18:46:14       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9859007417014571
[2018-06-08 18:46:15       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9863569830749372
[2018-06-08 18:46:16       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9853341044876411
[2018-06-08 18:46:17       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9877199688860333
[2018-06-08 18:46:18       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9852487566327573
[2018-06-08 18:46:18       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.987735253318005
[2018-06-08 18:46:19       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9860068124739896
[2018-06-08 18:46:20       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9875495106599618
[2018-06-08 18:46:21       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.984480490055591
[2018-06-08 18:46:22       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9874276498968867
[2018-06-08 18:46:22       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9873815104651352
[2018-06-08 18:46:23       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9886650347251339
[2018-06-08 18:46:24       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9862215950983106
[2018-06-08 18:46:25       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9867128559374789
[2018-06-08 18:46:25       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9883829857396809
[2018-06-08 18:46:26       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9890415072635912
[2018-06-08 18:46:27       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9875793185308
[2018-06-08 18:46:28       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9885997198876653
[2018-06-08 18:46:29       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9875543891340444
[2018-06-08 18:46:29       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9883007036397664
[2018-06-08 18:46:30       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9852096403349053
[2018-06-08 18:46:31       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.987779180268641
[2018-06-08 18:46:32       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.988508531904346
[2018-06-08 18:46:33       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9880071384381769
[2018-06-08 18:46:33       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.988085081594829
[2018-06-08 18:46:34       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9863184248803313
[2018-06-08 18:46:35       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9885007367062528
[2018-06-08 18:46:36       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9881660983696537
[2018-06-08 18:46:36       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9875720117735532
[2018-06-08 18:46:37       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9861806110399636
[2018-06-08 18:46:38       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9887345126452085
[2018-06-08 18:46:39       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.988310629784923
[2018-06-08 18:46:39       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.988297146056475
[2018-06-08 18:46:40       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9882605231637211
[2018-06-08 18:46:41       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.989111965693786
[2018-06-08 18:46:42       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9880007427966511
[2018-06-08 18:46:43       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9891978820296546
[2018-06-08 18:46:43       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9878796509292995
[2018-06-08 18:46:44       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9884178153911414
[2018-06-08 18:46:45       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9883407022623888
[2018-06-08 18:46:46       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9892687312452915
[2018-06-08 18:46:47       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.988969541852676
[2018-06-08 18:46:47       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9883532714403778
[2018-06-08 18:46:48       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9888954586995059
[2018-06-08 18:46:49       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9887565412075806
[2018-06-08 18:46:50       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9888506931481708
[2018-06-08 18:46:51       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9875166661117194
[2018-06-08 18:46:51       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9876749105607787
[2018-06-08 18:46:52       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9882852618497446
[2018-06-08 18:46:53       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9887275798697346
[2018-06-08 18:46:54       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9889590386278375
[2018-06-08 18:46:55       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9883990758583739
[2018-06-08 18:46:55       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9885655796947007
[2018-06-08 18:46:56       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9884539917036893
[2018-06-08 18:46:57       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9888294925268805
[2018-06-08 18:46:58       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9890508098649775
[2018-06-08 18:46:59       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9876184985326116
[2018-06-08 18:46:59       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9889873542581359
[2018-06-08 18:47:00       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9887647745503805
[2018-06-08 18:47:01       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9888137519922648
[2018-06-08 18:47:02       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9869164119316602
[2018-06-08 18:47:03       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9885999044905058
[2018-06-08 18:47:03       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9888460871720107
[2018-06-08 18:47:04       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9883391953280038
[2018-06-08 18:47:05       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9876281126430702
[2018-06-08 18:47:06       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9884957975015033
[2018-06-08 18:47:06       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9889828799657857
[2018-06-08 18:47:07       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9880877122166959
[2018-06-08 18:47:08       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9889556978234073
[2018-06-08 18:47:08       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.988857222011217
[2018-06-08 18:47:09       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9890380645816335
[2018-06-08 18:47:10       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9882252752561008
[2018-06-08 18:47:11       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9890703921257418
[2018-06-08 18:47:12       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9889176550795702
[2018-06-08 18:47:12       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9889720548014198
[2018-06-08 18:47:13       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9890293467364154
[2018-06-08 18:47:14       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9891789189402607
[2018-06-08 18:47:15       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.988819075236659
[2018-06-08 18:47:15       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9886400158890745
[2018-06-08 18:47:16       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9891164174236918
[2018-06-08 18:47:17       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9886003053672332
[2018-06-08 18:47:18       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9886524229093225
[2018-06-08 18:47:19       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9882612634718692
[2018-06-08 18:47:19       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:47:19       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:47:19       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:47:19       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_39.pickle"
[2018-06-08 18:47:19  start_training.py:128 -                      main()] Fidelity obtained: 0.9882916906953625
[2018-06-08 18:47:21  start_training.py: 99 -                      main()] Starting training no.40
[2018-06-08 18:47:21  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 18:47:21    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:47:21    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:47:21    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:47:21    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:47:21           model.py:140 -       _set_initial_values()] Initial parameters values: 2.
[2018-06-08 18:47:22           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:47:22           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:47:22       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:47:22       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:47:22       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:47:22       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:47:22       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:47:22       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:47:22       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:47:22       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:47:22       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:47:22       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:47:25       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:47:26       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5362313323651583
[2018-06-08 18:47:27       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.16160666805182963
[2018-06-08 18:47:28       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7600324857305323
[2018-06-08 18:47:28       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.5497125880099603
[2018-06-08 18:47:29       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.4821939669566558
[2018-06-08 18:47:30       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.5326987497501952
[2018-06-08 18:47:31       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.666593311875939
[2018-06-08 18:47:32       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.5418333562895107
[2018-06-08 18:47:32       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.609400075844578
[2018-06-08 18:47:33       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.7214534219895471
[2018-06-08 18:47:34       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.6137088410921663
[2018-06-08 18:47:35       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.6690136682253582
[2018-06-08 18:47:36       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.6650069072146119
[2018-06-08 18:47:36       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.7168335371225345
[2018-06-08 18:47:37       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.680324256726894
[2018-06-08 18:47:38       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.7226585462003047
[2018-06-08 18:47:39       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.7195435074202812
[2018-06-08 18:47:39       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.7121597099217998
[2018-06-08 18:47:40       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.6510438387804481
[2018-06-08 18:47:41       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.6859633819681519
[2018-06-08 18:47:42       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.7321439114600287
[2018-06-08 18:47:42       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.7081761878313537
[2018-06-08 18:47:43       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.7230971860962542
[2018-06-08 18:47:44       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.7182501645976264
[2018-06-08 18:47:45       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.7434736700934805
[2018-06-08 18:47:45       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.7262688036047683
[2018-06-08 18:47:46       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.6631553419547204
[2018-06-08 18:47:47       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.6873867873035283
[2018-06-08 18:47:48       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.6813859906537995
[2018-06-08 18:47:49       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.7249236537756554
[2018-06-08 18:47:49       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.7298698520835326
[2018-06-08 18:47:50       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.7476101313087008
[2018-06-08 18:47:51       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.7057155558000799
[2018-06-08 18:47:52       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.7306121435577759
[2018-06-08 18:47:52       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.7190960454673904
[2018-06-08 18:47:53       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.7306340648549589
[2018-06-08 18:47:54       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.7270266800111201
[2018-06-08 18:47:55       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.7018601233052386
[2018-06-08 18:47:56       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.7391371662258096
[2018-06-08 18:47:56       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.7197229653355431
[2018-06-08 18:47:57       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.7258801321563275
[2018-06-08 18:47:58       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.7421379803699958
[2018-06-08 18:47:59       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.7424379356566188
[2018-06-08 18:48:00       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.7167572161816643
[2018-06-08 18:48:00       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.7380839831749993
[2018-06-08 18:48:01       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.7318974048891213
[2018-06-08 18:48:02       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.7082728435787129
[2018-06-08 18:48:03       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.7355924913424821
[2018-06-08 18:48:03       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.7245623961903347
[2018-06-08 18:48:04       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.7318202690865279
[2018-06-08 18:48:05       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.7378844444872975
[2018-06-08 18:48:06       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.7406470813670742
[2018-06-08 18:48:06       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.730153069996974
[2018-06-08 18:48:07       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.7372361860263478
[2018-06-08 18:48:08       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.7274859244859525
[2018-06-08 18:48:09       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.7394758236607427
[2018-06-08 18:48:10       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.7401509478446698
[2018-06-08 18:48:11       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.7337670322012529
[2018-06-08 18:48:11       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.7401975587399476
[2018-06-08 18:48:12       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.7420023604218354
[2018-06-08 18:48:13       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.7262857214818527
[2018-06-08 18:48:14       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.7460473002177832
[2018-06-08 18:48:14       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.740294002262188
[2018-06-08 18:48:15       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.7422869795968252
[2018-06-08 18:48:16       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.7480588110062868
[2018-06-08 18:48:17       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.7348511323042878
[2018-06-08 18:48:18       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.7456299446351704
[2018-06-08 18:48:19       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.7391122379105829
[2018-06-08 18:48:19       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.7326755280135967
[2018-06-08 18:48:20       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.746218993692881
[2018-06-08 18:48:21       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.7475007638678396
[2018-06-08 18:48:22       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.7327747093710815
[2018-06-08 18:48:23       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.7408613619007707
[2018-06-08 18:48:23       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.7418330103198781
[2018-06-08 18:48:24       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.7456104439923233
[2018-06-08 18:48:25       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.7416721310120978
[2018-06-08 18:48:26       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.7296245968943451
[2018-06-08 18:48:26       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.738930162429609
[2018-06-08 18:48:27       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.7462644914868523
[2018-06-08 18:48:28       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.7285390466771395
[2018-06-08 18:48:29       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.7453861624464215
[2018-06-08 18:48:30       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.7313321350179336
[2018-06-08 18:48:30       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.7453106006038215
[2018-06-08 18:48:31       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.737251936180106
[2018-06-08 18:48:32       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.7330450052050014
[2018-06-08 18:48:33       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.7483608273686333
[2018-06-08 18:48:34       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.7471763227948186
[2018-06-08 18:48:34       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.7320061854693385
[2018-06-08 18:48:35       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.7431529149233094
[2018-06-08 18:48:36       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.7307858798979943
[2018-06-08 18:48:37       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.745167860208728
[2018-06-08 18:48:38       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.7291449936607381
[2018-06-08 18:48:38       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.7475618483249515
[2018-06-08 18:48:39       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.7439963944835332
[2018-06-08 18:48:40       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.7450310602982428
[2018-06-08 18:48:41       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.7400356022095275
[2018-06-08 18:48:42       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.7359093199958419
[2018-06-08 18:48:42       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.7435208538149495
[2018-06-08 18:48:43       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.7364853662572038
[2018-06-08 18:48:44       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.7435297490496307
[2018-06-08 18:48:44       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:48:44       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:48:44       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:48:44       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_40.pickle"
[2018-06-08 18:48:44  start_training.py:128 -                      main()] Fidelity obtained: 0.7532474551685618
[2018-06-08 18:48:47  start_training.py: 99 -                      main()] Starting training no.41
[2018-06-08 18:48:47  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 18:48:47    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:48:47    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:48:47    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:48:47    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:48:47           model.py:140 -       _set_initial_values()] Initial parameters values: 3.
[2018-06-08 18:48:47           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:48:47           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:48:47       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:48:47       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:48:47       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:48:47       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:48:47       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:48:47       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:48:47       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:48:47       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:48:47       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:48:47       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:48:51       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:48:51       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6905349917396434
[2018-06-08 18:48:52       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6218788611873214
[2018-06-08 18:48:53       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7513848251690658
[2018-06-08 18:48:54       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8896710297105579
[2018-06-08 18:48:54       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8883867447031812
[2018-06-08 18:48:55       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9081094225150569
[2018-06-08 18:48:56       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9734619966561513
[2018-06-08 18:48:57       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9957340158186908
[2018-06-08 18:48:57       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999111606206786
[2018-06-08 18:48:58       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9994570476216792
[2018-06-08 18:48:59       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9998963171407934
[2018-06-08 18:48:59       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9998393359875135
[2018-06-08 18:49:00       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9998041087856887
[2018-06-08 18:49:01       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9997566075001523
[2018-06-08 18:49:02       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9998830580487084
[2018-06-08 18:49:03       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999206741330318
[2018-06-08 18:49:03       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9998948431033089
[2018-06-08 18:49:04       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999291435950526
[2018-06-08 18:49:05       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9998144902369382
[2018-06-08 18:49:06       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999082450732233
[2018-06-08 18:49:06       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999302172575785
[2018-06-08 18:49:07       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999241701971039
[2018-06-08 18:49:08       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999312045199593
[2018-06-08 18:49:09       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999360825201622
[2018-06-08 18:49:10       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999181863147263
[2018-06-08 18:49:11       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9998868056588475
[2018-06-08 18:49:11       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999336403504802
[2018-06-08 18:49:12       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999260472059587
[2018-06-08 18:49:13       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999319886613652
[2018-06-08 18:49:14       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999372127770522
[2018-06-08 18:49:15       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.999936363982171
[2018-06-08 18:49:15       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999370643749649
[2018-06-08 18:49:16       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999282252448198
[2018-06-08 18:49:17       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999339679901837
[2018-06-08 18:49:18       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999389739922241
[2018-06-08 18:49:18       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999342613856237
[2018-06-08 18:49:19       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999277769727216
[2018-06-08 18:49:20       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999350799419195
[2018-06-08 18:49:21       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999405203725088
[2018-06-08 18:49:21       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.99993097165604
[2018-06-08 18:49:22       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999374007263185
[2018-06-08 18:49:23       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999401671755888
[2018-06-08 18:49:23       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999374739094319
[2018-06-08 18:49:24       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999318445802321
[2018-06-08 18:49:25       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999387102367002
[2018-06-08 18:49:26       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999392612976992
[2018-06-08 18:49:26       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999378735968056
[2018-06-08 18:49:27       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999420880285181
[2018-06-08 18:49:28       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999420446755153
[2018-06-08 18:49:29       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999429755570364
[2018-06-08 18:49:29       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999423941123564
[2018-06-08 18:49:30       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999419800546464
[2018-06-08 18:49:31       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999412509922543
[2018-06-08 18:49:32       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999422993019426
[2018-06-08 18:49:33       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999431102859576
[2018-06-08 18:49:33       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999372154154166
[2018-06-08 18:49:34       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999422998099478
[2018-06-08 18:49:35       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.999943219112715
[2018-06-08 18:49:36       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999365988773948
[2018-06-08 18:49:37       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999445067625357
[2018-06-08 18:49:37       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999421094400589
[2018-06-08 18:49:38       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999413444499032
[2018-06-08 18:49:39       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999437028194371
[2018-06-08 18:49:40       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999410825756883
[2018-06-08 18:49:40       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999426725647395
[2018-06-08 18:49:41       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999448297941962
[2018-06-08 18:49:42       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999435169715238
[2018-06-08 18:49:43       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999417174783974
[2018-06-08 18:49:43       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999442557272314
[2018-06-08 18:49:44       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999456803739695
[2018-06-08 18:49:45       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.999946486132517
[2018-06-08 18:49:46       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.999945619613254
[2018-06-08 18:49:46       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999447228819524
[2018-06-08 18:49:47       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999418024397833
[2018-06-08 18:49:48       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999443010501997
[2018-06-08 18:49:49       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999454704459282
[2018-06-08 18:49:49       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999462355181822
[2018-06-08 18:49:50       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999468175477508
[2018-06-08 18:49:51       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999457621322503
[2018-06-08 18:49:52       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999445045952435
[2018-06-08 18:49:53       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.999944114682514
[2018-06-08 18:49:53       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999470089692193
[2018-06-08 18:49:54       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999466177976243
[2018-06-08 18:49:55       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999476350307807
[2018-06-08 18:49:56       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999449366656831
[2018-06-08 18:49:56       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999473771271026
[2018-06-08 18:49:57       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999475719832616
[2018-06-08 18:49:58       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999468004573255
[2018-06-08 18:49:59       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999413319012992
[2018-06-08 18:50:00       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.999946763936249
[2018-06-08 18:50:01       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999479045237516
[2018-06-08 18:50:02       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999438000804066
[2018-06-08 18:50:02       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999470069751101
[2018-06-08 18:50:03       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999467079921499
[2018-06-08 18:50:04       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999482456742355
[2018-06-08 18:50:05       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999475436825038
[2018-06-08 18:50:05       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999395404843895
[2018-06-08 18:50:06       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999470810484354
[2018-06-08 18:50:07       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999476960695578
[2018-06-08 18:50:08       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999465503287912
[2018-06-08 18:50:08       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:50:08       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:50:08       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:50:08       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_41.pickle"
[2018-06-08 18:50:08  start_training.py:128 -                      main()] Fidelity obtained: 0.9999425993954464
[2018-06-08 18:50:11  start_training.py: 99 -                      main()] Starting training no.42
[2018-06-08 18:50:11  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 18:50:11    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:50:11    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:50:11    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:50:11    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:50:11           model.py:140 -       _set_initial_values()] Initial parameters values: 3.
[2018-06-08 18:50:11           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:50:11           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:50:11       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:50:11       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:50:11       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:50:11       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:50:11       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:50:11       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:50:11       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:50:11       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:50:11       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:50:11       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:50:15       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:50:15       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8681065710964063
[2018-06-08 18:50:16       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8418024330436726
[2018-06-08 18:50:17       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7854786412629113
[2018-06-08 18:50:18       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9168161546498887
[2018-06-08 18:50:19       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999989991476328
[2018-06-08 18:50:19       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0
[2018-06-08 18:50:19       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:50:19       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:50:19       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:50:19       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:50:19       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_42.pickle"
[2018-06-08 18:50:19  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 18:50:22  start_training.py: 99 -                      main()] Starting training no.43
[2018-06-08 18:50:22  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 18:50:22    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:50:22    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:50:22    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:50:22    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:50:22           model.py:140 -       _set_initial_values()] Initial parameters values: 3.
[2018-06-08 18:50:22           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:50:22           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:50:22       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:50:22       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:50:22       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:50:22       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:50:22       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:50:22       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:50:22       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:50:22       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:50:22       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:50:22       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:50:26       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:50:26       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7303902275057313
[2018-06-08 18:50:27       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.4191833346103598
[2018-06-08 18:50:28       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.38498226083410936
[2018-06-08 18:50:29       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8230593814344569
[2018-06-08 18:50:29       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8967760629748379
[2018-06-08 18:50:30       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8892780060614309
[2018-06-08 18:50:31       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8361759433614195
[2018-06-08 18:50:31       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9353152953008697
[2018-06-08 18:50:32       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9703419422492818
[2018-06-08 18:50:33       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999962997448663
[2018-06-08 18:50:33       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999999999
[2018-06-08 18:50:34       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999999999999997
[2018-06-08 18:50:35       Optimizer.py:490 -                      _run()]   Epoch no. 12: 1.0000000000000018
[2018-06-08 18:50:36       Optimizer.py:490 -                      _run()]   Epoch no. 13: 1.000000000000003
[2018-06-08 18:50:37       Optimizer.py:490 -                      _run()]   Epoch no. 14: 1.0000000000000007
[2018-06-08 18:50:37       Optimizer.py:490 -                      _run()]   Epoch no. 15: 1.0000000000000027
[2018-06-08 18:50:38       Optimizer.py:490 -                      _run()]   Epoch no. 16: 1.0000000000000033
[2018-06-08 18:50:39       Optimizer.py:490 -                      _run()]   Epoch no. 17: 1.000000000000002
[2018-06-08 18:50:40       Optimizer.py:490 -                      _run()]   Epoch no. 18: 1.0
[2018-06-08 18:50:40       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:50:40       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:50:40       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:50:40       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:50:40       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_43.pickle"
[2018-06-08 18:50:40  start_training.py:128 -                      main()] Fidelity obtained: 0.999999999999999
[2018-06-08 18:50:42  start_training.py: 99 -                      main()] Starting training no.44
[2018-06-08 18:50:42  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 18:50:42    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:50:42    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:50:42    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:50:42    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:50:42           model.py:140 -       _set_initial_values()] Initial parameters values: 3.
[2018-06-08 18:50:43           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:50:43           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:50:43       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:50:43       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:50:43       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:50:43       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:50:43       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:50:43       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:50:43       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:50:43       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:50:43       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:50:43       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:50:46       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:50:47       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5543556910317718
[2018-06-08 18:50:48       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.585077119095684
[2018-06-08 18:50:48       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9781755951136604
[2018-06-08 18:50:49       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.99940849687155
[2018-06-08 18:50:50       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.999999999960262
[2018-06-08 18:50:51       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999999684
[2018-06-08 18:50:51       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999999999999
[2018-06-08 18:50:52       Optimizer.py:490 -                      _run()]   Epoch no. 7: 1.0
[2018-06-08 18:50:52       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:50:52       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:50:52       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:50:52       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:50:52       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_44.pickle"
[2018-06-08 18:50:52  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 18:50:55  start_training.py: 99 -                      main()] Starting training no.45
[2018-06-08 18:50:55  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 18:50:55    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:50:55    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:50:55    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:50:55    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:50:55           model.py:140 -       _set_initial_values()] Initial parameters values: 3.
[2018-06-08 18:50:55           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:50:55           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:50:55       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:50:55       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:50:55       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:50:55       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:50:55       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:50:55       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:50:55       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:50:55       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:50:55       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:50:56       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:50:59       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:51:00       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.840693022870355
[2018-06-08 18:51:01       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5634726096680527
[2018-06-08 18:51:01       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9628122967531187
[2018-06-08 18:51:02       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9635142060669337
[2018-06-08 18:51:03       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9988486314825515
[2018-06-08 18:51:04       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999894100475479
[2018-06-08 18:51:05       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999966773306
[2018-06-08 18:51:05       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999370717
[2018-06-08 18:51:06       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999999989921
[2018-06-08 18:51:07       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999999349
[2018-06-08 18:51:08       Optimizer.py:490 -                      _run()]   Epoch no. 10: 1.0
[2018-06-08 18:51:08       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:51:08       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:51:08       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:51:08       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:51:08       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_45.pickle"
[2018-06-08 18:51:08  start_training.py:128 -                      main()] Fidelity obtained: 0.9999999999999996
[2018-06-08 18:51:10  start_training.py: 99 -                      main()] Starting training no.46
[2018-06-08 18:51:10  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 18:51:10    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:51:10    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:51:10    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:51:10    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:51:10           model.py:140 -       _set_initial_values()] Initial parameters values: 3.
[2018-06-08 18:51:10           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:51:10           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:51:10       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:51:10       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:51:10       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:51:10       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:51:10       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:51:10       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:51:10       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:51:11       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:51:11       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:51:11       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:51:14       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:51:15       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9825730700612926
[2018-06-08 18:51:16       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.383481698924304
[2018-06-08 18:51:17       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8442307685340786
[2018-06-08 18:51:18       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7671986524569239
[2018-06-08 18:51:18       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.999991179441931
[2018-06-08 18:51:19       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999963397695305
[2018-06-08 18:51:20       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999985613759418
[2018-06-08 18:51:21       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999990711552366
[2018-06-08 18:51:22       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.999999177791778
[2018-06-08 18:51:22       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999990442011195
[2018-06-08 18:51:23       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.999999438496137
[2018-06-08 18:51:24       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999995762348598
[2018-06-08 18:51:24       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999996465451204
[2018-06-08 18:51:25       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.999999694012084
[2018-06-08 18:51:26       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999996864627114
[2018-06-08 18:51:27       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999997466910472
[2018-06-08 18:51:27       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999997723498173
[2018-06-08 18:51:28       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999997827608741
[2018-06-08 18:51:29       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999998012997355
[2018-06-08 18:51:30       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999998115396589
[2018-06-08 18:51:30       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999998282295954
[2018-06-08 18:51:31       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999998206206488
[2018-06-08 18:51:32       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999998407081624
[2018-06-08 18:51:33       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999998563692594
[2018-06-08 18:51:34       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999998565312782
[2018-06-08 18:51:34       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.99999987258305
[2018-06-08 18:51:35       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999998739786377
[2018-06-08 18:51:36       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999998840363652
[2018-06-08 18:51:37       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999998875159786
[2018-06-08 18:51:37       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999998958065919
[2018-06-08 18:51:38       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999998983464065
[2018-06-08 18:51:39       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999038035438
[2018-06-08 18:51:40       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999998995394966
[2018-06-08 18:51:40       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999094362356
[2018-06-08 18:51:41       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999999089985132
[2018-06-08 18:51:42       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999160944567
[2018-06-08 18:51:43       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999152672703
[2018-06-08 18:51:43       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999999183608979
[2018-06-08 18:51:44       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999999225234205
[2018-06-08 18:51:45       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999173051393
[2018-06-08 18:51:46       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999999271072844
[2018-06-08 18:51:46       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999999282120632
[2018-06-08 18:51:47       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999299161348
[2018-06-08 18:51:48       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999999319645291
[2018-06-08 18:51:49       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999999329367475
[2018-06-08 18:51:49       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999338001713
[2018-06-08 18:51:50       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999348996511
[2018-06-08 18:51:51       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999999358825886
[2018-06-08 18:51:52       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999999380232422
[2018-06-08 18:51:52       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999999394858489
[2018-06-08 18:51:53       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999999361832789
[2018-06-08 18:51:54       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999999423901432
[2018-06-08 18:51:55       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999999425354952
[2018-06-08 18:51:56       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999999433327232
[2018-06-08 18:51:56       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999999449765662
[2018-06-08 18:51:57       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999999464869745
[2018-06-08 18:51:58       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999458598434
[2018-06-08 18:51:59       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999999487126167
[2018-06-08 18:52:00       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999999477497089
[2018-06-08 18:52:00       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999999498538443
[2018-06-08 18:52:01       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.999999950784995
[2018-06-08 18:52:02       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999999512002682
[2018-06-08 18:52:03       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999999523740155
[2018-06-08 18:52:04       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999999523126698
[2018-06-08 18:52:04       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.999999950780225
[2018-06-08 18:52:05       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999999544225883
[2018-06-08 18:52:06       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999999519424156
[2018-06-08 18:52:07       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999999549019669
[2018-06-08 18:52:08       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999999549891821
[2018-06-08 18:52:09       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999999567076108
[2018-06-08 18:52:09       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999999563982287
[2018-06-08 18:52:10       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999999572744369
[2018-06-08 18:52:11       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999999584014274
[2018-06-08 18:52:12       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999999569994372
[2018-06-08 18:52:13       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999999591838648
[2018-06-08 18:52:13       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999999595474712
[2018-06-08 18:52:14       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999999601107402
[2018-06-08 18:52:15       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999999606302192
[2018-06-08 18:52:16       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999999610787289
[2018-06-08 18:52:16       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999999605471469
[2018-06-08 18:52:17       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999999603039446
[2018-06-08 18:52:18       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999999620787952
[2018-06-08 18:52:19       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.999999961996259
[2018-06-08 18:52:19       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999999630407324
[2018-06-08 18:52:20       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999999634172971
[2018-06-08 18:52:21       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999999604662702
[2018-06-08 18:52:22       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999999639262306
[2018-06-08 18:52:23       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999999643561456
[2018-06-08 18:52:23       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.999999964610407
[2018-06-08 18:52:24       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.999999965212417
[2018-06-08 18:52:25       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999999649477063
[2018-06-08 18:52:25       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999999656251759
[2018-06-08 18:52:26       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999999659616123
[2018-06-08 18:52:27       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999999660686616
[2018-06-08 18:52:28       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999999666348842
[2018-06-08 18:52:29       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999999662752542
[2018-06-08 18:52:30       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999999669131716
[2018-06-08 18:52:30       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999999668195464
[2018-06-08 18:52:31       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.999999967727625
[2018-06-08 18:52:32       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999999678681237
[2018-06-08 18:52:32       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:52:32       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:52:32       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:52:32       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_46.pickle"
[2018-06-08 18:52:32  start_training.py:128 -                      main()] Fidelity obtained: 0.999999966212569
[2018-06-08 18:52:34  start_training.py: 99 -                      main()] Starting training no.47
[2018-06-08 18:52:34  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 18:52:34    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:52:34    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:52:34    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:52:34    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:52:34           model.py:140 -       _set_initial_values()] Initial parameters values: 3.
[2018-06-08 18:52:35           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:52:35           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:52:35       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:52:35       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:52:35       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:52:35       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:52:35       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:52:35       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:52:35       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:52:35       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:52:35       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:52:35       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:52:38       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:52:39       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.49030377270880043
[2018-06-08 18:52:40       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.23819406360802933
[2018-06-08 18:52:41       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9941238353536603
[2018-06-08 18:52:42       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999999999977313
[2018-06-08 18:52:42       Optimizer.py:490 -                      _run()]   Epoch no. 4: 1.0
[2018-06-08 18:52:42       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:52:42       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:52:42       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:52:42       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:52:42       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_47.pickle"
[2018-06-08 18:52:42  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 18:52:45  start_training.py: 99 -                      main()] Starting training no.48
[2018-06-08 18:52:45  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 18:52:45    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:52:45    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:52:45    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:52:45    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:52:45           model.py:140 -       _set_initial_values()] Initial parameters values: 3.
[2018-06-08 18:52:45           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:52:45           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:52:45       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:52:45       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:52:45       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:52:45       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:52:45       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:52:45       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:52:45       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:52:45       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:52:45       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:52:45       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:52:49       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:52:49       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8989360988831536
[2018-06-08 18:52:50       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9170803750388451
[2018-06-08 18:52:51       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.956620833717477
[2018-06-08 18:52:52       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9219207795592448
[2018-06-08 18:52:52       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9917613368214395
[2018-06-08 18:52:53       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9757318771186205
[2018-06-08 18:52:54       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.99851190280628
[2018-06-08 18:52:55       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9976176418400692
[2018-06-08 18:52:55       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9984037823458652
[2018-06-08 18:52:56       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9951850663995329
[2018-06-08 18:52:57       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9973770752416979
[2018-06-08 18:52:58       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.998340667236296
[2018-06-08 18:52:58       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9984220898885907
[2018-06-08 18:52:59       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9979307572730433
[2018-06-08 18:53:00       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9976651681715406
[2018-06-08 18:53:00       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9987182429834026
[2018-06-08 18:53:01       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9985164518250097
[2018-06-08 18:53:02       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9980096779306089
[2018-06-08 18:53:03       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9986583350640644
[2018-06-08 18:53:04       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9982576790244226
[2018-06-08 18:53:04       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9984208331326697
[2018-06-08 18:53:05       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9987755999154959
[2018-06-08 18:53:06       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9990263264469186
[2018-06-08 18:53:07       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9989586488159609
[2018-06-08 18:53:08       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9985540542081357
[2018-06-08 18:53:08       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.998987456061098
[2018-06-08 18:53:09       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9990243933694017
[2018-06-08 18:53:10       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9990616721515047
[2018-06-08 18:53:11       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9987085281791706
[2018-06-08 18:53:11       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9988969534859027
[2018-06-08 18:53:12       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9991437008149646
[2018-06-08 18:53:13       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.999286565162661
[2018-06-08 18:53:14       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9992762848229856
[2018-06-08 18:53:15       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9993367604109197
[2018-06-08 18:53:15       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.999279991617545
[2018-06-08 18:53:16       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9992347886882169
[2018-06-08 18:53:17       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9993495587050916
[2018-06-08 18:53:18       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9993772809918439
[2018-06-08 18:53:18       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9993776206766835
[2018-06-08 18:53:19       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9994619955210418
[2018-06-08 18:53:20       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9995411525536981
[2018-06-08 18:53:21       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9995478209321971
[2018-06-08 18:53:21       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.999585940532901
[2018-06-08 18:53:22       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9996186805087746
[2018-06-08 18:53:23       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9996283847497779
[2018-06-08 18:53:24       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9996228656698843
[2018-06-08 18:53:25       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9996646834300847
[2018-06-08 18:53:25       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9996467916500079
[2018-06-08 18:53:26       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9996758987408982
[2018-06-08 18:53:27       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9996966047281736
[2018-06-08 18:53:28       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9997194870068165
[2018-06-08 18:53:28       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.99973781763561
[2018-06-08 18:53:29       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9997522215635456
[2018-06-08 18:53:30       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.999764606057998
[2018-06-08 18:53:31       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9997836452166208
[2018-06-08 18:53:31       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9997821507906537
[2018-06-08 18:53:32       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9998010296983343
[2018-06-08 18:53:33       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.999797319970355
[2018-06-08 18:53:34       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.999812793136696
[2018-06-08 18:53:34       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9997776079761583
[2018-06-08 18:53:35       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9998162053725068
[2018-06-08 18:53:36       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.999828277974454
[2018-06-08 18:53:37       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9998464078924559
[2018-06-08 18:53:37       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.999846453408589
[2018-06-08 18:53:38       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9998530695926701
[2018-06-08 18:53:39       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9998607347664686
[2018-06-08 18:53:40       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9998688028795254
[2018-06-08 18:53:40       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9998767337488131
[2018-06-08 18:53:41       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.999873319788143
[2018-06-08 18:53:42       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9998838491569733
[2018-06-08 18:53:43       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9998781940508341
[2018-06-08 18:53:43       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9998898747270946
[2018-06-08 18:53:44       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9998921167202007
[2018-06-08 18:53:45       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9998991266700789
[2018-06-08 18:53:46       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.999895232169168
[2018-06-08 18:53:46       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999059861503696
[2018-06-08 18:53:47       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999075017057715
[2018-06-08 18:53:48       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999089421986703
[2018-06-08 18:53:48       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.999909458484533
[2018-06-08 18:53:49       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.999917153337034
[2018-06-08 18:53:50       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.999914920312283
[2018-06-08 18:53:51       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999192655529886
[2018-06-08 18:53:51       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999242461361397
[2018-06-08 18:53:52       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999261863295884
[2018-06-08 18:53:53       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999307393907557
[2018-06-08 18:53:54       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999280530022985
[2018-06-08 18:53:55       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999322433843628
[2018-06-08 18:53:55       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999292558626207
[2018-06-08 18:53:56       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.99993501224467
[2018-06-08 18:53:57       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999365043247311
[2018-06-08 18:53:58       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999391758307098
[2018-06-08 18:53:58       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999434096165516
[2018-06-08 18:53:59       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999448431617495
[2018-06-08 18:54:00       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999414149607361
[2018-06-08 18:54:01       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999423345706991
[2018-06-08 18:54:01       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999449164953501
[2018-06-08 18:54:02       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999496250863288
[2018-06-08 18:54:03       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999511516178116
[2018-06-08 18:54:03       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999486636371823
[2018-06-08 18:54:04       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999516706387079
[2018-06-08 18:54:04       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:54:04       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:54:04       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:54:04       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_48.pickle"
[2018-06-08 18:54:04  start_training.py:128 -                      main()] Fidelity obtained: 0.9999527557822622
[2018-06-08 18:54:07  start_training.py: 99 -                      main()] Starting training no.49
[2018-06-08 18:54:07  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 18:54:07    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:54:07    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:54:07    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:54:07    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:54:07           model.py:140 -       _set_initial_values()] Initial parameters values: 3.
[2018-06-08 18:54:07           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:54:07           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:54:07       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:54:07       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:54:07       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:54:07       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:54:07       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:54:07       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:54:07       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:54:07       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:54:07       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:54:07       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:54:11       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:54:12       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8429395323923861
[2018-06-08 18:54:13       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.45646245232433375
[2018-06-08 18:54:13       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7737729845155523
[2018-06-08 18:54:14       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9074139377879286
[2018-06-08 18:54:15       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.1302036584925722
[2018-06-08 18:54:16       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9012127707791225
[2018-06-08 18:54:16       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8542162180398879
[2018-06-08 18:54:17       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9394421240613094
[2018-06-08 18:54:18       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9998074653352443
[2018-06-08 18:54:19       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999388875754
[2018-06-08 18:54:19       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999997755
[2018-06-08 18:54:20       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999999999999997
[2018-06-08 18:54:21       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999999999999
[2018-06-08 18:54:21       Optimizer.py:490 -                      _run()]   Epoch no. 13: 1.0000000000000002
[2018-06-08 18:54:22       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999999999999
[2018-06-08 18:54:23       Optimizer.py:490 -                      _run()]   Epoch no. 15: 1.0000000000000002
[2018-06-08 18:54:23       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999999999996
[2018-06-08 18:54:24       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999999999997
[2018-06-08 18:54:25       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999999999994
[2018-06-08 18:54:26       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999999999999
[2018-06-08 18:54:26       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999999999999
[2018-06-08 18:54:27       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999999999999
[2018-06-08 18:54:28       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999999999996
[2018-06-08 18:54:29       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999999999994
[2018-06-08 18:54:29       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999999999999997
[2018-06-08 18:54:30       Optimizer.py:490 -                      _run()]   Epoch no. 25: 1.0
[2018-06-08 18:54:30       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:54:30       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:54:30       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:54:30       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:54:30       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_49.pickle"
[2018-06-08 18:54:30  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000009
[2018-06-08 18:54:33  start_training.py: 99 -                      main()] Starting training no.50
[2018-06-08 18:54:33  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 18:54:33    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:54:33    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:54:33    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:54:33    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:54:33           model.py:140 -       _set_initial_values()] Initial parameters values: 3.
[2018-06-08 18:54:33           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:54:33           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:54:33       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:54:33       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:54:33       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:54:33       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:54:33       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:54:33       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:54:33       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:54:33       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:54:33       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:54:33       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:54:37       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:54:38       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.4993157686138197
[2018-06-08 18:54:38       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8621426065719331
[2018-06-08 18:54:39       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9995775499987631
[2018-06-08 18:54:40       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9996101572763183
[2018-06-08 18:54:41       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9998548400114273
[2018-06-08 18:54:42       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.999938866493583
[2018-06-08 18:54:42       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999327939617895
[2018-06-08 18:54:43       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999772870148813
[2018-06-08 18:54:44       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999835275608986
[2018-06-08 18:54:45       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999819480578748
[2018-06-08 18:54:45       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999881821616823
[2018-06-08 18:54:46       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999860996909128
[2018-06-08 18:54:47       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999837831679307
[2018-06-08 18:54:48       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999922283725537
[2018-06-08 18:54:49       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.999992897348978
[2018-06-08 18:54:49       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999934143307805
[2018-06-08 18:54:50       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999942818983816
[2018-06-08 18:54:51       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999946000144985
[2018-06-08 18:54:52       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999947747340032
[2018-06-08 18:54:52       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.999994438268896
[2018-06-08 18:54:53       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999955229643182
[2018-06-08 18:54:54       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999957238541328
[2018-06-08 18:54:55       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999958739238458
[2018-06-08 18:54:56       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.999996164727513
[2018-06-08 18:54:57       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999962430508657
[2018-06-08 18:54:57       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999963939486343
[2018-06-08 18:54:58       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999967051037609
[2018-06-08 18:54:59       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999967337951915
[2018-06-08 18:55:00       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999966542822436
[2018-06-08 18:55:00       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999968625427157
[2018-06-08 18:55:01       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999963767162404
[2018-06-08 18:55:02       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999967549152654
[2018-06-08 18:55:03       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999972204598488
[2018-06-08 18:55:04       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999973028057145
[2018-06-08 18:55:04       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999973648719106
[2018-06-08 18:55:05       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999973190295312
[2018-06-08 18:55:06       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999974550922859
[2018-06-08 18:55:07       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999975586467903
[2018-06-08 18:55:07       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999974661340224
[2018-06-08 18:55:08       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.999997582580697
[2018-06-08 18:55:09       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999977421550114
[2018-06-08 18:55:10       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999977533899447
[2018-06-08 18:55:10       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999978472931071
[2018-06-08 18:55:11       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999979140469886
[2018-06-08 18:55:12       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.999997942033248
[2018-06-08 18:55:13       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999977624843635
[2018-06-08 18:55:14       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999980294859082
[2018-06-08 18:55:14       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999980003418001
[2018-06-08 18:55:15       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999980932199797
[2018-06-08 18:55:16       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999980320064542
[2018-06-08 18:55:17       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999981074383242
[2018-06-08 18:55:18       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999981072823572
[2018-06-08 18:55:19       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999981156177905
[2018-06-08 18:55:19       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999980495960523
[2018-06-08 18:55:20       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999981143056857
[2018-06-08 18:55:21       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999979293718039
[2018-06-08 18:55:22       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.999998278900338
[2018-06-08 18:55:22       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999982949855136
[2018-06-08 18:55:23       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999983606354458
[2018-06-08 18:55:24       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999983786729669
[2018-06-08 18:55:25       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999983970738983
[2018-06-08 18:55:25       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999982193256655
[2018-06-08 18:55:26       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999983689627666
[2018-06-08 18:55:27       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999984281527337
[2018-06-08 18:55:28       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999983914977386
[2018-06-08 18:55:29       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.999998478716091
[2018-06-08 18:55:29       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999985132946084
[2018-06-08 18:55:30       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999985060960477
[2018-06-08 18:55:31       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999984861189037
[2018-06-08 18:55:32       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999984625480497
[2018-06-08 18:55:32       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999985418779683
[2018-06-08 18:55:33       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999984979698466
[2018-06-08 18:55:34       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.99999861864185
[2018-06-08 18:55:35       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.999998605770564
[2018-06-08 18:55:35       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999985110948566
[2018-06-08 18:55:36       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999986441940649
[2018-06-08 18:55:37       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.999998562898439
[2018-06-08 18:55:38       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999986701805668
[2018-06-08 18:55:38       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999986848881813
[2018-06-08 18:55:39       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999987011967134
[2018-06-08 18:55:40       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.999998704738776
[2018-06-08 18:55:41       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999987014474846
[2018-06-08 18:55:41       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999987185839836
[2018-06-08 18:55:42       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999986977119575
[2018-06-08 18:55:43       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999986678794786
[2018-06-08 18:55:44       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999987604009348
[2018-06-08 18:55:44       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999987054100358
[2018-06-08 18:55:45       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999987794473458
[2018-06-08 18:55:46       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999987702289601
[2018-06-08 18:55:47       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999988038478044
[2018-06-08 18:55:48       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999987355188503
[2018-06-08 18:55:48       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999988265226598
[2018-06-08 18:55:49       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999987779660688
[2018-06-08 18:55:50       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999988294359855
[2018-06-08 18:55:51       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999987889858504
[2018-06-08 18:55:51       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999988627325577
[2018-06-08 18:55:52       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.999998844392733
[2018-06-08 18:55:53       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999988749446032
[2018-06-08 18:55:54       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999987676993076
[2018-06-08 18:55:55       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999988214563126
[2018-06-08 18:55:55       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:55:55       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:55:55       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:55:55       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_50.pickle"
[2018-06-08 18:55:55  start_training.py:128 -                      main()] Fidelity obtained: 0.9999988801415378
[2018-06-08 18:55:58  start_training.py: 99 -                      main()] Starting training no.51
[2018-06-08 18:55:58  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 18:55:58    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:55:58    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:55:58    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:55:58    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:55:58           model.py:140 -       _set_initial_values()] Initial parameters values: 4.
[2018-06-08 18:55:58           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:55:58           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:55:58       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:55:58       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:55:58       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:55:58       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:55:58       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:55:58       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:55:58       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:55:58       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:55:58       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:55:58       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:56:02       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:56:03       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.44908630858389864
[2018-06-08 18:56:03       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.701456766736571
[2018-06-08 18:56:04       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9442883655537126
[2018-06-08 18:56:05       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9577047905249431
[2018-06-08 18:56:06       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9995780400429979
[2018-06-08 18:56:07       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9996453567057515
[2018-06-08 18:56:07       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9998535031967138
[2018-06-08 18:56:08       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999808387233325
[2018-06-08 18:56:09       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999858581046813
[2018-06-08 18:56:10       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999855942249684
[2018-06-08 18:56:10       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999965972055093
[2018-06-08 18:56:11       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999972736276105
[2018-06-08 18:56:12       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999983150648916
[2018-06-08 18:56:13       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999987525596846
[2018-06-08 18:56:14       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999989148357877
[2018-06-08 18:56:15       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999992867411674
[2018-06-08 18:56:15       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999994940279834
[2018-06-08 18:56:16       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999995362525839
[2018-06-08 18:56:17       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999996987913604
[2018-06-08 18:56:18       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999996410646029
[2018-06-08 18:56:19       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999996928364225
[2018-06-08 18:56:20       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999997387042143
[2018-06-08 18:56:20       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999998678674602
[2018-06-08 18:56:21       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999997443010717
[2018-06-08 18:56:22       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999998483287346
[2018-06-08 18:56:23       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999998846444949
[2018-06-08 18:56:24       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999034823669
[2018-06-08 18:56:24       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999414216058
[2018-06-08 18:56:25       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999144703006
[2018-06-08 18:56:26       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999999562756778
[2018-06-08 18:56:27       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.999999956336548
[2018-06-08 18:56:28       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999646757061
[2018-06-08 18:56:29       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999999686397242
[2018-06-08 18:56:29       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999730171462
[2018-06-08 18:56:30       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.999999974607991
[2018-06-08 18:56:31       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999789194333
[2018-06-08 18:56:32       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999789198217
[2018-06-08 18:56:33       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999999837968869
[2018-06-08 18:56:34       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999999834142972
[2018-06-08 18:56:34       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999868539925
[2018-06-08 18:56:35       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999999882782954
[2018-06-08 18:56:36       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999999897106844
[2018-06-08 18:56:37       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999898890539
[2018-06-08 18:56:38       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999999917253448
[2018-06-08 18:56:38       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999999924267132
[2018-06-08 18:56:39       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999930150812
[2018-06-08 18:56:40       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999930738955
[2018-06-08 18:56:41       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999999937831885
[2018-06-08 18:56:42       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999999946823682
[2018-06-08 18:56:43       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999999948747764
[2018-06-08 18:56:43       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.999999995476077
[2018-06-08 18:56:44       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999999957444998
[2018-06-08 18:56:45       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999999954528869
[2018-06-08 18:56:46       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999999965270129
[2018-06-08 18:56:47       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999999965598774
[2018-06-08 18:56:47       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999999971486497
[2018-06-08 18:56:48       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999971479083
[2018-06-08 18:56:49       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999999973707213
[2018-06-08 18:56:50       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999999971950814
[2018-06-08 18:56:51       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999999979209931
[2018-06-08 18:56:52       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999999980575818
[2018-06-08 18:56:52       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999999980703761
[2018-06-08 18:56:53       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999999981436999
[2018-06-08 18:56:54       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999999982155381
[2018-06-08 18:56:55       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999999984964668
[2018-06-08 18:56:56       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999999984587399
[2018-06-08 18:56:56       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999999987038011
[2018-06-08 18:56:57       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999999988069068
[2018-06-08 18:56:58       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999999988246918
[2018-06-08 18:56:59       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999999989504273
[2018-06-08 18:57:00       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999999989098501
[2018-06-08 18:57:01       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999999989543188
[2018-06-08 18:57:02       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999999990541113
[2018-06-08 18:57:02       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999999992037206
[2018-06-08 18:57:03       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.999999999081566
[2018-06-08 18:57:04       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999999992930239
[2018-06-08 18:57:05       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999999993380915
[2018-06-08 18:57:06       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999999993287468
[2018-06-08 18:57:06       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999999994251635
[2018-06-08 18:57:07       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999999993981207
[2018-06-08 18:57:08       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999999993956511
[2018-06-08 18:57:09       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.999999999515656
[2018-06-08 18:57:09       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999999994752378
[2018-06-08 18:57:10       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.999999999522271
[2018-06-08 18:57:11       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999999995734098
[2018-06-08 18:57:12       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999999995909298
[2018-06-08 18:57:13       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999999996280166
[2018-06-08 18:57:14       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999999996376683
[2018-06-08 18:57:14       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999999996085076
[2018-06-08 18:57:15       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999999996703007
[2018-06-08 18:57:16       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999999997024954
[2018-06-08 18:57:17       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999999997137888
[2018-06-08 18:57:18       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999999997258537
[2018-06-08 18:57:18       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999999997421629
[2018-06-08 18:57:19       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.999999999749531
[2018-06-08 18:57:20       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999999997386873
[2018-06-08 18:57:21       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999999997726721
[2018-06-08 18:57:22       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.999999999775704
[2018-06-08 18:57:22       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999999997905243
[2018-06-08 18:57:23       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999999998046082
[2018-06-08 18:57:23       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:57:23       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:57:23       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:57:23       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_51.pickle"
[2018-06-08 18:57:23  start_training.py:128 -                      main()] Fidelity obtained: 0.9999999998025235
[2018-06-08 18:57:26  start_training.py: 99 -                      main()] Starting training no.52
[2018-06-08 18:57:26  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 18:57:26    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:57:26    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:57:26    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:57:26    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:57:26           model.py:140 -       _set_initial_values()] Initial parameters values: 4.
[2018-06-08 18:57:26           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:57:26           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:57:26       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:57:26       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:57:26       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:57:26       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:57:26       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:57:26       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:57:26       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:57:26       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:57:26       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:57:27       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:57:30       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:57:31       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5215613029657437
[2018-06-08 18:57:32       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8313600991828521
[2018-06-08 18:57:33       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9887707112696014
[2018-06-08 18:57:33       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999999997574811
[2018-06-08 18:57:34       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999999997
[2018-06-08 18:57:35       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999999999
[2018-06-08 18:57:36       Optimizer.py:490 -                      _run()]   Epoch no. 6: 1.0
[2018-06-08 18:57:36       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:57:36       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:57:36       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:57:36       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:57:36       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_52.pickle"
[2018-06-08 18:57:36  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 18:57:39  start_training.py: 99 -                      main()] Starting training no.53
[2018-06-08 18:57:39  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 18:57:39    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:57:39    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:57:39    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:57:39    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:57:39           model.py:140 -       _set_initial_values()] Initial parameters values: 4.
[2018-06-08 18:57:39           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:57:39           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:57:39       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:57:39       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:57:39       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:57:39       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:57:39       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:57:39       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:57:39       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:57:39       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:57:39       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:57:39       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:57:43       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:57:43       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.978403548087573
[2018-06-08 18:57:44       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8283836149770823
[2018-06-08 18:57:45       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9974451394799003
[2018-06-08 18:57:46       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9782734826026198
[2018-06-08 18:57:46       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999976512841
[2018-06-08 18:57:47       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999979992
[2018-06-08 18:57:48       Optimizer.py:490 -                      _run()]   Epoch no. 6: 1.0
[2018-06-08 18:57:48       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:57:48       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:57:48       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:57:48       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:57:48       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_53.pickle"
[2018-06-08 18:57:48  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000002
[2018-06-08 18:57:50  start_training.py: 99 -                      main()] Starting training no.54
[2018-06-08 18:57:50  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 18:57:50    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:57:50    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:57:50    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:57:50    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:57:50           model.py:140 -       _set_initial_values()] Initial parameters values: 4.
[2018-06-08 18:57:51           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:57:51           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:57:51       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:57:51       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:57:51       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:57:51       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:57:51       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:57:51       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:57:51       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:57:51       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:57:51       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:57:51       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:57:54       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:57:55       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.333118079691477
[2018-06-08 18:57:56       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5123347065692964
[2018-06-08 18:57:57       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7661643163572341
[2018-06-08 18:57:58       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9924854733860955
[2018-06-08 18:57:58       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999330541216
[2018-06-08 18:57:59       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999999809
[2018-06-08 18:58:00       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999999999999
[2018-06-08 18:58:01       Optimizer.py:490 -                      _run()]   Epoch no. 7: 1.0000000000000002
[2018-06-08 18:58:02       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999999999999
[2018-06-08 18:58:03       Optimizer.py:490 -                      _run()]   Epoch no. 9: 1.0
[2018-06-08 18:58:03       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:58:03       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:58:03       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:58:03       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:58:03       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_54.pickle"
[2018-06-08 18:58:03  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 18:58:06  start_training.py: 99 -                      main()] Starting training no.55
[2018-06-08 18:58:06  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 18:58:06    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:58:06    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:58:06    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:58:06    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:58:06           model.py:140 -       _set_initial_values()] Initial parameters values: 4.
[2018-06-08 18:58:06           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:58:06           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:58:06       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:58:06       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:58:06       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:58:06       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:58:06       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:58:06       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:58:06       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:58:06       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:58:06       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:58:06       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:58:10       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:58:10       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.4272307851830142
[2018-06-08 18:58:11       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.39423174893493174
[2018-06-08 18:58:12       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9640428556149447
[2018-06-08 18:58:13       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.18033347111661915
[2018-06-08 18:58:14       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999999969
[2018-06-08 18:58:14       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999999999
[2018-06-08 18:58:15       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999999999997
[2018-06-08 18:58:16       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999999999
[2018-06-08 18:58:17       Optimizer.py:490 -                      _run()]   Epoch no. 8: 1.0
[2018-06-08 18:58:17       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 18:58:17       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:58:17       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:58:17       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:58:17       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_55.pickle"
[2018-06-08 18:58:17  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 18:58:19  start_training.py: 99 -                      main()] Starting training no.56
[2018-06-08 18:58:19  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 18:58:19    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:58:19    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:58:19    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:58:19    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:58:19           model.py:140 -       _set_initial_values()] Initial parameters values: 4.
[2018-06-08 18:58:19           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:58:19           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:58:19       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:58:19       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:58:19       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:58:19       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:58:19       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:58:19       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:58:19       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:58:20       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:58:20       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:58:20       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:58:23       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:58:24       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8988464861550056
[2018-06-08 18:58:24       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.33904587669301967
[2018-06-08 18:58:25       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9783297072946527
[2018-06-08 18:58:26       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8883097489618581
[2018-06-08 18:58:27       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9598244574147927
[2018-06-08 18:58:27       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9695496306878539
[2018-06-08 18:58:28       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9940322167331921
[2018-06-08 18:58:29       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9953031732282761
[2018-06-08 18:58:30       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9942079389188092
[2018-06-08 18:58:30       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.992230692580233
[2018-06-08 18:58:31       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9934703625156134
[2018-06-08 18:58:32       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9948059417341176
[2018-06-08 18:58:33       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9952465243922789
[2018-06-08 18:58:33       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.993634893204086
[2018-06-08 18:58:34       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9949618580726574
[2018-06-08 18:58:35       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.995014907198687
[2018-06-08 18:58:35       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9948872536395763
[2018-06-08 18:58:36       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9952664439120943
[2018-06-08 18:58:37       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9947310764646586
[2018-06-08 18:58:38       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9953634862725851
[2018-06-08 18:58:38       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.995619067259766
[2018-06-08 18:58:39       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9951773952643418
[2018-06-08 18:58:40       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9953675588726805
[2018-06-08 18:58:41       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9954013925484255
[2018-06-08 18:58:42       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9953949611620054
[2018-06-08 18:58:42       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9952741928578352
[2018-06-08 18:58:43       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9955283225698176
[2018-06-08 18:58:44       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9954986391983905
[2018-06-08 18:58:45       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9955986244345775
[2018-06-08 18:58:45       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9953501961799582
[2018-06-08 18:58:46       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9952645057932946
[2018-06-08 18:58:47       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9948475775037449
[2018-06-08 18:58:47       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9953541441085203
[2018-06-08 18:58:48       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9955950480779048
[2018-06-08 18:58:49       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9952461802682333
[2018-06-08 18:58:50       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9954560625173715
[2018-06-08 18:58:51       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9945629295576975
[2018-06-08 18:58:51       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9954654657006065
[2018-06-08 18:58:52       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9954275259300954
[2018-06-08 18:58:53       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9954685116015359
[2018-06-08 18:58:54       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9955487855974086
[2018-06-08 18:58:54       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9951547469049379
[2018-06-08 18:58:55       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9952952512841736
[2018-06-08 18:58:56       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9954495143210642
[2018-06-08 18:58:57       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9953975304401331
[2018-06-08 18:58:57       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9955186308758545
[2018-06-08 18:58:58       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9955674696778191
[2018-06-08 18:58:59       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.995369286050424
[2018-06-08 18:59:00       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9953654087428037
[2018-06-08 18:59:01       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9952308286760482
[2018-06-08 18:59:01       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9956807221886386
[2018-06-08 18:59:02       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9953599252563643
[2018-06-08 18:59:03       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9956913367372837
[2018-06-08 18:59:03       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.995551214875882
[2018-06-08 18:59:04       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9951804588871722
[2018-06-08 18:59:05       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9956234130717483
[2018-06-08 18:59:06       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9956492054013484
[2018-06-08 18:59:06       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9954392603097582
[2018-06-08 18:59:07       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9957080269865274
[2018-06-08 18:59:08       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.995616113915947
[2018-06-08 18:59:09       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9955524487724788
[2018-06-08 18:59:09       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.995531078709771
[2018-06-08 18:59:10       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9956425913048704
[2018-06-08 18:59:11       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9952799549302113
[2018-06-08 18:59:11       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9951992939780476
[2018-06-08 18:59:12       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9956375840244571
[2018-06-08 18:59:13       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9955793005953866
[2018-06-08 18:59:14       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9955524412264279
[2018-06-08 18:59:14       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9955701173314104
[2018-06-08 18:59:15       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9953802405063757
[2018-06-08 18:59:16       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9955929537441492
[2018-06-08 18:59:17       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.995534985261505
[2018-06-08 18:59:17       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9956226816100164
[2018-06-08 18:59:18       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9955684694754027
[2018-06-08 18:59:19       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.995343084253369
[2018-06-08 18:59:20       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9956738185457432
[2018-06-08 18:59:21       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9951437702125796
[2018-06-08 18:59:21       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9955671994448062
[2018-06-08 18:59:22       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9955170919448858
[2018-06-08 18:59:23       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9956186535688673
[2018-06-08 18:59:24       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9954772120995421
[2018-06-08 18:59:24       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9956651607771021
[2018-06-08 18:59:25       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9956788594003858
[2018-06-08 18:59:26       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9953594600862978
[2018-06-08 18:59:27       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9955408699103458
[2018-06-08 18:59:28       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9955552881192912
[2018-06-08 18:59:28       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9955775150591083
[2018-06-08 18:59:29       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9956032409124225
[2018-06-08 18:59:30       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9956616690534013
[2018-06-08 18:59:31       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9956704359851031
[2018-06-08 18:59:31       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9955395050454974
[2018-06-08 18:59:32       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9956278566913117
[2018-06-08 18:59:33       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.995469264289295
[2018-06-08 18:59:34       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9955230362890992
[2018-06-08 18:59:34       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.995459346501941
[2018-06-08 18:59:35       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9955815006805893
[2018-06-08 18:59:36       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9955569503645646
[2018-06-08 18:59:36       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.99568460273706
[2018-06-08 18:59:37       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9955651792256599
[2018-06-08 18:59:38       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9954029536236624
[2018-06-08 18:59:38       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 18:59:38       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 18:59:38       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 18:59:38       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_56.pickle"
[2018-06-08 18:59:38  start_training.py:128 -                      main()] Fidelity obtained: 0.9952292626561758
[2018-06-08 18:59:41  start_training.py: 99 -                      main()] Starting training no.57
[2018-06-08 18:59:41  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 18:59:41    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 18:59:41    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 18:59:41    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 18:59:41    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 18:59:41           model.py:140 -       _set_initial_values()] Initial parameters values: 4.
[2018-06-08 18:59:41           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 18:59:41           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 18:59:41       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 18:59:41       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 18:59:41       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 18:59:41       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 18:59:41       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 18:59:41       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 18:59:41       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 18:59:41       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 18:59:41       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 18:59:41       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 18:59:44       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 18:59:45       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7574420001655294
[2018-06-08 18:59:46       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9481936521108594
[2018-06-08 18:59:47       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.74357450223593
[2018-06-08 18:59:48       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.983176102908727
[2018-06-08 18:59:49       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9992145247774712
[2018-06-08 18:59:49       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999995331725404
[2018-06-08 18:59:50       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999999995127
[2018-06-08 18:59:51       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999999997
[2018-06-08 18:59:52       Optimizer.py:490 -                      _run()]   Epoch no. 8: 1.0000000000000004
[2018-06-08 18:59:53       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999999997
[2018-06-08 18:59:53       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999999997
[2018-06-08 18:59:54       Optimizer.py:490 -                      _run()]   Epoch no. 11: 1.000000000000001
[2018-06-08 18:59:55       Optimizer.py:490 -                      _run()]   Epoch no. 12: 1.0000000000000002
[2018-06-08 18:59:56       Optimizer.py:490 -                      _run()]   Epoch no. 13: 1.0000000000000004
[2018-06-08 18:59:57       Optimizer.py:490 -                      _run()]   Epoch no. 14: 1.0000000000000007
[2018-06-08 18:59:57       Optimizer.py:490 -                      _run()]   Epoch no. 15: 1.0000000000000004
[2018-06-08 18:59:58       Optimizer.py:490 -                      _run()]   Epoch no. 16: 1.0000000000000007
[2018-06-08 18:59:59       Optimizer.py:490 -                      _run()]   Epoch no. 17: 1.0000000000000007
[2018-06-08 18:59:59       Optimizer.py:490 -                      _run()]   Epoch no. 18: 1.000000000000001
[2018-06-08 19:00:00       Optimizer.py:490 -                      _run()]   Epoch no. 19: 1.0000000000000013
[2018-06-08 19:00:01       Optimizer.py:490 -                      _run()]   Epoch no. 20: 1.0000000000000002
[2018-06-08 19:00:02       Optimizer.py:490 -                      _run()]   Epoch no. 21: 1.0000000000000007
[2018-06-08 19:00:02       Optimizer.py:490 -                      _run()]   Epoch no. 22: 1.0000000000000002
[2018-06-08 19:00:03       Optimizer.py:490 -                      _run()]   Epoch no. 23: 1.0000000000000002
[2018-06-08 19:00:04       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999999999999999
[2018-06-08 19:00:05       Optimizer.py:490 -                      _run()]   Epoch no. 25: 1.0000000000000007
[2018-06-08 19:00:06       Optimizer.py:490 -                      _run()]   Epoch no. 26: 1.0000000000000002
[2018-06-08 19:00:06       Optimizer.py:490 -                      _run()]   Epoch no. 27: 1.0000000000000007
[2018-06-08 19:00:07       Optimizer.py:490 -                      _run()]   Epoch no. 28: 1.0000000000000007
[2018-06-08 19:00:08       Optimizer.py:490 -                      _run()]   Epoch no. 29: 1.0
[2018-06-08 19:00:08       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 19:00:08       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 19:00:08       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 19:00:08       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 19:00:08       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_57.pickle"
[2018-06-08 19:00:08  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 19:00:11  start_training.py: 99 -                      main()] Starting training no.58
[2018-06-08 19:00:11  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 19:00:11    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 19:00:11    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 19:00:11    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 19:00:11    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 19:00:11           model.py:140 -       _set_initial_values()] Initial parameters values: 4.
[2018-06-08 19:00:11           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 19:00:11           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 19:00:11       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 19:00:11       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 19:00:11       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 19:00:11       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 19:00:11       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 19:00:11       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 19:00:11       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 19:00:11       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 19:00:11       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 19:00:11       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 19:00:15       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 19:00:16       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7086415978645769
[2018-06-08 19:00:17       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8772102209162833
[2018-06-08 19:00:17       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9267396265843856
[2018-06-08 19:00:18       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9951739661151892
[2018-06-08 19:00:19       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999546425
[2018-06-08 19:00:20       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0
[2018-06-08 19:00:20       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 19:00:20       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 19:00:20       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 19:00:20       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 19:00:20       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_58.pickle"
[2018-06-08 19:00:20  start_training.py:128 -                      main()] Fidelity obtained: 0.9999999999999991
[2018-06-08 19:00:23  start_training.py: 99 -                      main()] Starting training no.59
[2018-06-08 19:00:23  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 19:00:23    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 19:00:23    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 19:00:23    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 19:00:23    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 19:00:23           model.py:140 -       _set_initial_values()] Initial parameters values: 4.
[2018-06-08 19:00:23           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 19:00:23           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 19:00:23       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 19:00:23       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 19:00:23       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 19:00:23       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 19:00:23       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 19:00:23       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 19:00:23       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 19:00:23       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 19:00:23       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 19:00:23       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 19:00:27       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 19:00:27       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8413226154085913
[2018-06-08 19:00:28       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.37155097116121255
[2018-06-08 19:00:29       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9415581875597914
[2018-06-08 19:00:30       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.891405785559236
[2018-06-08 19:00:31       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8787046891950462
[2018-06-08 19:00:31       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9662868198058345
[2018-06-08 19:00:32       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9989681693550733
[2018-06-08 19:00:33       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9945976058531746
[2018-06-08 19:00:34       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.999998429893379
[2018-06-08 19:00:35       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999999156
[2018-06-08 19:00:35       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999999996
[2018-06-08 19:00:36       Optimizer.py:490 -                      _run()]   Epoch no. 11: 1.0000000000000002
[2018-06-08 19:00:37       Optimizer.py:490 -                      _run()]   Epoch no. 12: 1.0000000000000002
[2018-06-08 19:00:38       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999999999999
[2018-06-08 19:00:39       Optimizer.py:490 -                      _run()]   Epoch no. 14: 1.0000000000000007
[2018-06-08 19:00:39       Optimizer.py:490 -                      _run()]   Epoch no. 15: 1.0000000000000004
[2018-06-08 19:00:40       Optimizer.py:490 -                      _run()]   Epoch no. 16: 1.0000000000000004
[2018-06-08 19:00:41       Optimizer.py:490 -                      _run()]   Epoch no. 17: 1.0
[2018-06-08 19:00:41       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 19:00:41       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 19:00:41       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 19:00:41       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 19:00:41       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_59.pickle"
[2018-06-08 19:00:41  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000004
[2018-06-08 19:00:44  start_training.py: 99 -                      main()] Starting training no.60
[2018-06-08 19:00:44  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 19:00:44    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 19:00:44    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 19:00:44    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 19:00:44    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 19:00:44           model.py:140 -       _set_initial_values()] Initial parameters values: 4.
[2018-06-08 19:00:44           model.py:374 -                  __init__()] Number of system qubits: 3.
[2018-06-08 19:00:44           model.py:377 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 19:00:44       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 19:00:44       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 19:00:44       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 19:00:44       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 19:00:44       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 19:00:44       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 19:00:44       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 19:00:44       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 19:00:44       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 19:00:44       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 19:00:48       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 19:00:48       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9505167350484262
[2018-06-08 19:00:49       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8205254060841018
[2018-06-08 19:00:50       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7818599156211623
[2018-06-08 19:00:51       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7977203288773702
[2018-06-08 19:00:51       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7846348272725993
[2018-06-08 19:00:52       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9801494279683949
[2018-06-08 19:00:53       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999981433886314
[2018-06-08 19:00:54       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999999949
[2018-06-08 19:00:55       Optimizer.py:490 -                      _run()]   Epoch no. 8: 1.0000000000000002
[2018-06-08 19:00:55       Optimizer.py:490 -                      _run()]   Epoch no. 9: 1.0000000000000002
[2018-06-08 19:00:56       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999999991
[2018-06-08 19:00:57       Optimizer.py:490 -                      _run()]   Epoch no. 11: 1.0000000000000002
[2018-06-08 19:00:58       Optimizer.py:490 -                      _run()]   Epoch no. 12: 1.0000000000000002
[2018-06-08 19:00:58       Optimizer.py:490 -                      _run()]   Epoch no. 13: 1.0000000000000004
[2018-06-08 19:00:59       Optimizer.py:490 -                      _run()]   Epoch no. 14: 1.0000000000000004
[2018-06-08 19:01:00       Optimizer.py:490 -                      _run()]   Epoch no. 15: 1.0000000000000009
[2018-06-08 19:01:01       Optimizer.py:490 -                      _run()]   Epoch no. 16: 1.0000000000000002
[2018-06-08 19:01:01       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999999999996
[2018-06-08 19:01:02       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999999999999
[2018-06-08 19:01:03       Optimizer.py:490 -                      _run()]   Epoch no. 19: 1.0
[2018-06-08 19:01:03       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 19:01:03       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 19:01:03       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 19:01:03       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 19:01:03       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Toffoli/toffoli_noancillae_diagonalReducedModel_initvaluesRandom/training_no_60.pickle"
[2018-06-08 19:01:03  start_training.py:128 -                      main()] Fidelity obtained: 0.9999999999999996
[2018-06-08 19:01:03  start_training.py:142 -                  <module>()] Training finished. Deleting placeholder file.
