[2018-06-08 13:03:16  start_training.py:141 -                  <module>()] Starting script
[2018-06-08 13:03:16  start_training.py: 73 -                      main()] We are going for a total of 60attempts.
[2018-06-08 13:03:16  start_training.py: 75 -                      main()] The following initial values will be used:['random', 0, 1, 2, 3, 4].
[2018-06-08 13:03:16  start_training.py: 89 -                      main()] Random initial values
[2018-06-08 13:03:19  start_training.py:101 -                      main()] Starting training no.1
[2018-06-08 13:03:19    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:03:19    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:03:19    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:03:19    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:03:19           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:03:19           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:03:19       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:03:19       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:03:19       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:03:19       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:03:19       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:03:19       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:03:19       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:03:20       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:03:20       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:03:20       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:03:32       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:03:32       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.610362906547209
[2018-06-08 13:03:33       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7084828908578846
[2018-06-08 13:03:33       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7909981207109782
[2018-06-08 13:03:34       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8308424721230456
[2018-06-08 13:03:35       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.773790033350616
[2018-06-08 13:03:35       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.792693847300125
[2018-06-08 13:03:36       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7939837553679071
[2018-06-08 13:03:37       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.7425703793179212
[2018-06-08 13:03:37       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.6889029604834751
[2018-06-08 13:03:38       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.7967895467210275
[2018-06-08 13:03:38       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.7900830008154626
[2018-06-08 13:03:39       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8225975729162447
[2018-06-08 13:03:40       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8223640709776897
[2018-06-08 13:03:40       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8291782422281229
[2018-06-08 13:03:41       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8165847514351302
[2018-06-08 13:03:41       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8195091205602073
[2018-06-08 13:03:42       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8639511818546022
[2018-06-08 13:03:43       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8081026786526556
[2018-06-08 13:03:43       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8540382538337932
[2018-06-08 13:03:44       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8521744461165948
[2018-06-08 13:03:44       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8536722894221266
[2018-06-08 13:03:45       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8456831432226043
[2018-06-08 13:03:45       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8487787917825469
[2018-06-08 13:03:46       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8453092358217452
[2018-06-08 13:03:47       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8516988511671478
[2018-06-08 13:03:47       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.852455103477882
[2018-06-08 13:03:48       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8622757354051653
[2018-06-08 13:03:48       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8425951913280442
[2018-06-08 13:03:49       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8424539545468502
[2018-06-08 13:03:49       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8568907553578111
[2018-06-08 13:03:50       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8325944761252903
[2018-06-08 13:03:51       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.84333129328619
[2018-06-08 13:03:51       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8465054839317357
[2018-06-08 13:03:52       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8489265376621588
[2018-06-08 13:03:53       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8432270175370816
[2018-06-08 13:03:54       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.845309852431615
[2018-06-08 13:03:54       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8578666349756997
[2018-06-08 13:03:55       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8457494684529375
[2018-06-08 13:03:56       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8474912307518297
[2018-06-08 13:03:57       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8497518688363327
[2018-06-08 13:03:58       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8503045221504744
[2018-06-08 13:03:58       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8624044430564901
[2018-06-08 13:03:59       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.860400907823663
[2018-06-08 13:04:00       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8601885103995736
[2018-06-08 13:04:01       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8454832287295995
[2018-06-08 13:04:01       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8581711233066163
[2018-06-08 13:04:02       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8507232448388846
[2018-06-08 13:04:03       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.836421426195278
[2018-06-08 13:04:03       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8504703760640686
[2018-06-08 13:04:04       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8526451383424696
[2018-06-08 13:04:05       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8612996989629874
[2018-06-08 13:04:05       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8479335887147613
[2018-06-08 13:04:06       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8599139284705052
[2018-06-08 13:04:06       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8567995219005428
[2018-06-08 13:04:07       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8628568152055885
[2018-06-08 13:04:08       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8621457268308954
[2018-06-08 13:04:08       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8525230876766533
[2018-06-08 13:04:09       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8494492115159068
[2018-06-08 13:04:09       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8569548254993561
[2018-06-08 13:04:10       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8524238496598059
[2018-06-08 13:04:11       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.863776371397734
[2018-06-08 13:04:11       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8419858044172516
[2018-06-08 13:04:12       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.858100530489202
[2018-06-08 13:04:12       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8622413564752356
[2018-06-08 13:04:13       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8560775299278148
[2018-06-08 13:04:14       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8330120666834137
[2018-06-08 13:04:14       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8606326676986791
[2018-06-08 13:04:15       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8615941570148966
[2018-06-08 13:04:16       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8603203560493591
[2018-06-08 13:04:16       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8593450614843694
[2018-06-08 13:04:17       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8550486175495908
[2018-06-08 13:04:17       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8624730423279332
[2018-06-08 13:04:18       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.854962293144582
[2018-06-08 13:04:19       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8482620502574193
[2018-06-08 13:04:19       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8639507599725404
[2018-06-08 13:04:20       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8583630802095431
[2018-06-08 13:04:21       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8632673408220823
[2018-06-08 13:04:21       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8588973547768487
[2018-06-08 13:04:22       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8598979962209374
[2018-06-08 13:04:22       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8630507131883755
[2018-06-08 13:04:23       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8604126093646518
[2018-06-08 13:04:23       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8626819151608884
[2018-06-08 13:04:24       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8569116323026609
[2018-06-08 13:04:25       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8561558055915536
[2018-06-08 13:04:25       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.861816244451593
[2018-06-08 13:04:26       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8545752423672972
[2018-06-08 13:04:27       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.86109786780114
[2018-06-08 13:04:27       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8592019631824627
[2018-06-08 13:04:28       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8602243961994307
[2018-06-08 13:04:28       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8636011788118831
[2018-06-08 13:04:29       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8640084207957635
[2018-06-08 13:04:29       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8660172668943195
[2018-06-08 13:04:30       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.838615042055435
[2018-06-08 13:04:31       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8612897945719129
[2018-06-08 13:04:31       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8637683303645498
[2018-06-08 13:04:32       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.858533890142461
[2018-06-08 13:04:32       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8607983756120671
[2018-06-08 13:04:33       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8499314369592238
[2018-06-08 13:04:33       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8604225495305436
[2018-06-08 13:04:34       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8569560583935185
[2018-06-08 13:04:34       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:04:34       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:04:34       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:04:34       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_1.pickle"
[2018-06-08 13:04:34  start_training.py:129 -                      main()] Fidelity obtained: 0.8597473087645814
[2018-06-08 13:04:36  start_training.py:101 -                      main()] Starting training no.2
[2018-06-08 13:04:36    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:04:36    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:04:36    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:04:36    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:04:36           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:04:36           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:04:36       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:04:36       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:04:36       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:04:36       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:04:36       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:04:36       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:04:36       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:04:36       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:04:36       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:04:36       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:04:40       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:04:40       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.601140986065548
[2018-06-08 13:04:41       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6414980223640049
[2018-06-08 13:04:42       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6503574833051217
[2018-06-08 13:04:42       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7693911762670066
[2018-06-08 13:04:43       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8341934507544195
[2018-06-08 13:04:44       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.801079958493859
[2018-06-08 13:04:44       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7963454016591902
[2018-06-08 13:04:45       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8167240547925328
[2018-06-08 13:04:45       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8415531331555083
[2018-06-08 13:04:46       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8600822994039536
[2018-06-08 13:04:47       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8055239193660674
[2018-06-08 13:04:47       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8153529332197514
[2018-06-08 13:04:48       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8318631865027888
[2018-06-08 13:04:48       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8434809080775552
[2018-06-08 13:04:49       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8494670820343204
[2018-06-08 13:04:50       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8311666890576487
[2018-06-08 13:04:50       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8149776454088208
[2018-06-08 13:04:51       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8620801901460218
[2018-06-08 13:04:51       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8265495733417052
[2018-06-08 13:04:52       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.852676970454152
[2018-06-08 13:04:53       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8659911325360529
[2018-06-08 13:04:53       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8686249406479831
[2018-06-08 13:04:54       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.859002010539124
[2018-06-08 13:04:55       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.858749579621759
[2018-06-08 13:04:55       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8556320346205744
[2018-06-08 13:04:56       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8616498744110865
[2018-06-08 13:04:57       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8652198595039922
[2018-06-08 13:04:57       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8588394050044024
[2018-06-08 13:04:58       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8570296398538432
[2018-06-08 13:04:58       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.850909668310084
[2018-06-08 13:04:59       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8370739185575224
[2018-06-08 13:05:00       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8731891974708305
[2018-06-08 13:05:00       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8612632613083642
[2018-06-08 13:05:01       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8609137333819487
[2018-06-08 13:05:02       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8616031615546396
[2018-06-08 13:05:02       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8453698235774993
[2018-06-08 13:05:03       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8532062119119814
[2018-06-08 13:05:04       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8647031359322987
[2018-06-08 13:05:04       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8667863325538634
[2018-06-08 13:05:05       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8677900430862764
[2018-06-08 13:05:06       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8271943304960678
[2018-06-08 13:05:07       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8665919515693676
[2018-06-08 13:05:07       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8640521078281506
[2018-06-08 13:05:08       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.85909433370158
[2018-06-08 13:05:08       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8557132920238645
[2018-06-08 13:05:09       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8577813737729688
[2018-06-08 13:05:10       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8669391126556155
[2018-06-08 13:05:10       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8529189130793827
[2018-06-08 13:05:11       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8657119840457501
[2018-06-08 13:05:12       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.868696281508644
[2018-06-08 13:05:12       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8617809001194392
[2018-06-08 13:05:13       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8694621502701037
[2018-06-08 13:05:14       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8720332174772081
[2018-06-08 13:05:14       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8671050733731387
[2018-06-08 13:05:15       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8426867631293987
[2018-06-08 13:05:15       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8632719773986068
[2018-06-08 13:05:16       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8708173212031833
[2018-06-08 13:05:17       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8694482076336649
[2018-06-08 13:05:17       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8718579465836068
[2018-06-08 13:05:18       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8619857881814074
[2018-06-08 13:05:18       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8627967496024255
[2018-06-08 13:05:19       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8654457640645539
[2018-06-08 13:05:20       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8676629408700604
[2018-06-08 13:05:20       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8698034518132921
[2018-06-08 13:05:21       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8635464771923489
[2018-06-08 13:05:22       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8693223955271407
[2018-06-08 13:05:22       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8650461391915811
[2018-06-08 13:05:23       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8583927992748364
[2018-06-08 13:05:23       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8663565835027659
[2018-06-08 13:05:24       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.864062932777976
[2018-06-08 13:05:25       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8621042440844816
[2018-06-08 13:05:26       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8519347352424509
[2018-06-08 13:05:27       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.856895362421133
[2018-06-08 13:05:27       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8644725119014453
[2018-06-08 13:05:28       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8686174127837968
[2018-06-08 13:05:29       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8546622714944329
[2018-06-08 13:05:30       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8688562791087978
[2018-06-08 13:05:31       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8679104790990471
[2018-06-08 13:05:31       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8604414337857936
[2018-06-08 13:05:32       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8647787730238342
[2018-06-08 13:05:32       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8669477512994253
[2018-06-08 13:05:33       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8695017654170714
[2018-06-08 13:05:34       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8640118871234518
[2018-06-08 13:05:34       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8682572153483398
[2018-06-08 13:05:35       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8613233707522017
[2018-06-08 13:05:35       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8698757157439881
[2018-06-08 13:05:36       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8663482699855133
[2018-06-08 13:05:37       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8693168430729586
[2018-06-08 13:05:37       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.869632896118151
[2018-06-08 13:05:38       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8606395412053768
[2018-06-08 13:05:38       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8694055753007478
[2018-06-08 13:05:39       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8646967867304798
[2018-06-08 13:05:40       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8568951063507635
[2018-06-08 13:05:40       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8709924972099492
[2018-06-08 13:05:41       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8685940511519783
[2018-06-08 13:05:42       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.860418607651397
[2018-06-08 13:05:42       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8639875953660868
[2018-06-08 13:05:43       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8682902021123994
[2018-06-08 13:05:43       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8695034181586763
[2018-06-08 13:05:44       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8709888754848751
[2018-06-08 13:05:44       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:05:44       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:05:44       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:05:44       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_2.pickle"
[2018-06-08 13:05:44  start_training.py:129 -                      main()] Fidelity obtained: 0.8684410986125296
[2018-06-08 13:05:46  start_training.py:101 -                      main()] Starting training no.3
[2018-06-08 13:05:46    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:05:46    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:05:46    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:05:46    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:05:47           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:05:47           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:05:47       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:05:47       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:05:47       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:05:47       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:05:47       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:05:47       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:05:47       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:05:47       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:05:47       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:05:47       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:05:50       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:05:51       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7751906113808223
[2018-06-08 13:05:52       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7182372488200235
[2018-06-08 13:05:53       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8689717065373117
[2018-06-08 13:05:54       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.944361671020454
[2018-06-08 13:05:55       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9817514443929579
[2018-06-08 13:05:56       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9765255262056527
[2018-06-08 13:05:57       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8791622324149092
[2018-06-08 13:05:57       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9988822812912632
[2018-06-08 13:05:58       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9996899743121702
[2018-06-08 13:05:59       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9997713989044467
[2018-06-08 13:05:59       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.999874844574136
[2018-06-08 13:06:00       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999477562428225
[2018-06-08 13:06:00       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999604369264787
[2018-06-08 13:06:01       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999746174604408
[2018-06-08 13:06:02       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999818003593441
[2018-06-08 13:06:02       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.999991213348414
[2018-06-08 13:06:03       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999948895792399
[2018-06-08 13:06:03       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999964586732429
[2018-06-08 13:06:04       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999979118442023
[2018-06-08 13:06:05       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999986508518477
[2018-06-08 13:06:05       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999985756258719
[2018-06-08 13:06:06       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999991111214609
[2018-06-08 13:06:06       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999994510612557
[2018-06-08 13:06:07       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999994949588892
[2018-06-08 13:06:08       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999997104625343
[2018-06-08 13:06:08       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999997397391367
[2018-06-08 13:06:09       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999998609291931
[2018-06-08 13:06:09       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999007045486
[2018-06-08 13:06:10       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999207645895
[2018-06-08 13:06:11       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999999343787646
[2018-06-08 13:06:11       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999999501837471
[2018-06-08 13:06:12       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999595090641
[2018-06-08 13:06:13       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.99999996800119
[2018-06-08 13:06:13       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999764195081
[2018-06-08 13:06:14       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999999817817572
[2018-06-08 13:06:14       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999858405697
[2018-06-08 13:06:15       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999892657386
[2018-06-08 13:06:16       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999999911374929
[2018-06-08 13:06:16       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.999999993017252
[2018-06-08 13:06:17       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999945702805
[2018-06-08 13:06:17       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999999946734255
[2018-06-08 13:06:18       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999999963651508
[2018-06-08 13:06:19       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999966791059
[2018-06-08 13:06:19       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.999999997669269
[2018-06-08 13:06:20       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999999980515287
[2018-06-08 13:06:21       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999980698553
[2018-06-08 13:06:21       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999985652045
[2018-06-08 13:06:22       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999999988559459
[2018-06-08 13:06:23       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999999990224674
[2018-06-08 13:06:23       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999999989084032
[2018-06-08 13:06:24       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999999993475036
[2018-06-08 13:06:24       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999999994345654
[2018-06-08 13:06:25       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999999995539902
[2018-06-08 13:06:26       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999999996230082
[2018-06-08 13:06:26       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999999996461773
[2018-06-08 13:06:27       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999999997138275
[2018-06-08 13:06:27       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999997501453
[2018-06-08 13:06:28       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999999998019564
[2018-06-08 13:06:29       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999999998060279
[2018-06-08 13:06:29       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999999998534617
[2018-06-08 13:06:30       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999999998738014
[2018-06-08 13:06:30       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999999998746658
[2018-06-08 13:06:31       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.999999999904668
[2018-06-08 13:06:32       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999999999151018
[2018-06-08 13:06:32       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999999999270328
[2018-06-08 13:06:33       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999999999368263
[2018-06-08 13:06:34       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999999999414326
[2018-06-08 13:06:34       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999999999403516
[2018-06-08 13:06:35       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999999999587204
[2018-06-08 13:06:35       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999999999643588
[2018-06-08 13:06:36       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999999999667117
[2018-06-08 13:06:37       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999999999707176
[2018-06-08 13:06:37       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999999999736758
[2018-06-08 13:06:38       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999999999784478
[2018-06-08 13:06:38       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999999999795451
[2018-06-08 13:06:39       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999999999833643
[2018-06-08 13:06:40       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999999999851119
[2018-06-08 13:06:40       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999999999867485
[2018-06-08 13:06:41       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.999999999988236
[2018-06-08 13:06:42       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999999999891257
[2018-06-08 13:06:42       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999999999903483
[2018-06-08 13:06:43       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.999999999991536
[2018-06-08 13:06:43       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999999999926991
[2018-06-08 13:06:44       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999999999930894
[2018-06-08 13:06:45       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999999999937663
[2018-06-08 13:06:45       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999999999947036
[2018-06-08 13:06:46       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999999999947069
[2018-06-08 13:06:47       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999999999955987
[2018-06-08 13:06:47       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999999999961804
[2018-06-08 13:06:48       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999999999965655
[2018-06-08 13:06:48       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.999999999996922
[2018-06-08 13:06:49       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999999999972539
[2018-06-08 13:06:50       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.999999999997428
[2018-06-08 13:06:50       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.999999999997748
[2018-06-08 13:06:51       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999999999979039
[2018-06-08 13:06:51       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999999999980528
[2018-06-08 13:06:52       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999999999983253
[2018-06-08 13:06:53       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999999999985105
[2018-06-08 13:06:53       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999999999986519
[2018-06-08 13:06:54       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999999999987566
[2018-06-08 13:06:54       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:06:54       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:06:54       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:06:54       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_3.pickle"
[2018-06-08 13:06:54  start_training.py:129 -                      main()] Fidelity obtained: 0.9999999999988102
[2018-06-08 13:06:56  start_training.py:101 -                      main()] Starting training no.4
[2018-06-08 13:06:56    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:06:56    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:06:56    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:06:56    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:06:56           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:06:56           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:06:56       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:06:56       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:06:56       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:06:56       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:06:56       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:06:56       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:06:56       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:06:56       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:06:56       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:06:56       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:06:59       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:06:59       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.40649621859216595
[2018-06-08 13:07:00       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.10988071171698609
[2018-06-08 13:07:01       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7632208446918686
[2018-06-08 13:07:02       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.789349762739812
[2018-06-08 13:07:03       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7431711309402107
[2018-06-08 13:07:04       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8384185290269354
[2018-06-08 13:07:04       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7386053660908156
[2018-06-08 13:07:05       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8170812923672277
[2018-06-08 13:07:06       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.7970627539160324
[2018-06-08 13:07:06       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8142920691564783
[2018-06-08 13:07:07       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8234333614779628
[2018-06-08 13:07:08       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8274983477648031
[2018-06-08 13:07:08       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8325416953328089
[2018-06-08 13:07:09       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.7992279616017619
[2018-06-08 13:07:09       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8065433680983065
[2018-06-08 13:07:10       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.7965567904715917
[2018-06-08 13:07:10       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.833958022851902
[2018-06-08 13:07:11       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8252500039233575
[2018-06-08 13:07:12       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8474488076716041
[2018-06-08 13:07:12       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8521539988562757
[2018-06-08 13:07:13       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8384198509098931
[2018-06-08 13:07:13       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8445340738943011
[2018-06-08 13:07:14       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8458716705768304
[2018-06-08 13:07:15       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.7995227051432682
[2018-06-08 13:07:15       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8530439210196534
[2018-06-08 13:07:16       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8586102048148195
[2018-06-08 13:07:16       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8493444959717331
[2018-06-08 13:07:17       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8523804170560046
[2018-06-08 13:07:17       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8540678795809248
[2018-06-08 13:07:18       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8521357810065529
[2018-06-08 13:07:19       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8439818975226596
[2018-06-08 13:07:19       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8592586672864109
[2018-06-08 13:07:20       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.831264397334837
[2018-06-08 13:07:20       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8523441964621076
[2018-06-08 13:07:21       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8316696213559819
[2018-06-08 13:07:21       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8654235892162129
[2018-06-08 13:07:22       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8622015321833955
[2018-06-08 13:07:23       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8599317144906061
[2018-06-08 13:07:23       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8581245968233416
[2018-06-08 13:07:24       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8404781317005342
[2018-06-08 13:07:24       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8619476752704606
[2018-06-08 13:07:25       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8483905850376692
[2018-06-08 13:07:25       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8534320696074695
[2018-06-08 13:07:26       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8602564587564655
[2018-06-08 13:07:27       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8524510804634461
[2018-06-08 13:07:27       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8635887157805225
[2018-06-08 13:07:28       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8660482308764554
[2018-06-08 13:07:28       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8660645419290945
[2018-06-08 13:07:29       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8520190577345218
[2018-06-08 13:07:29       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8500030578715938
[2018-06-08 13:07:30       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8535582081788584
[2018-06-08 13:07:31       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8590565752614835
[2018-06-08 13:07:31       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8591060186037879
[2018-06-08 13:07:32       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8582516195221567
[2018-06-08 13:07:32       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8650238403755801
[2018-06-08 13:07:33       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8652486167946796
[2018-06-08 13:07:34       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8520678441123876
[2018-06-08 13:07:35       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8582784488710502
[2018-06-08 13:07:35       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.860219264771601
[2018-06-08 13:07:36       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8657573158774445
[2018-06-08 13:07:37       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8591806587773272
[2018-06-08 13:07:38       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8610511098460343
[2018-06-08 13:07:39       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8494382093405054
[2018-06-08 13:07:39       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8633516964725725
[2018-06-08 13:07:40       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8657280711251941
[2018-06-08 13:07:41       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8607268623513
[2018-06-08 13:07:42       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8637655696570902
[2018-06-08 13:07:43       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.845732498671397
[2018-06-08 13:07:44       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8537695719530898
[2018-06-08 13:07:44       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8647338544694765
[2018-06-08 13:07:45       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.861074727431274
[2018-06-08 13:07:46       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8570515894815933
[2018-06-08 13:07:47       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8620025244663885
[2018-06-08 13:07:48       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8578358307052715
[2018-06-08 13:07:48       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8656495941710349
[2018-06-08 13:07:49       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8641508282947439
[2018-06-08 13:07:50       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8612415123602384
[2018-06-08 13:07:50       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8591990607868183
[2018-06-08 13:07:51       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8630079153290424
[2018-06-08 13:07:51       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.864711108987962
[2018-06-08 13:07:52       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8624542197555847
[2018-06-08 13:07:53       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8645149452123049
[2018-06-08 13:07:53       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.844544510930386
[2018-06-08 13:07:54       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8611172697339674
[2018-06-08 13:07:54       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8584043933326047
[2018-06-08 13:07:55       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8593016724675396
[2018-06-08 13:07:56       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8568755402067569
[2018-06-08 13:07:56       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8598616031048093
[2018-06-08 13:07:57       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8564091024132969
[2018-06-08 13:07:57       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8628579157111469
[2018-06-08 13:07:58       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8584050648230915
[2018-06-08 13:07:58       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.858682116312848
[2018-06-08 13:07:59       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8604750806093491
[2018-06-08 13:08:00       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8667188079955165
[2018-06-08 13:08:00       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8664743741685185
[2018-06-08 13:08:01       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8520229842720319
[2018-06-08 13:08:01       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8663716900728593
[2018-06-08 13:08:02       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8659187203046733
[2018-06-08 13:08:02       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8594012273598718
[2018-06-08 13:08:03       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8576302726225471
[2018-06-08 13:08:03       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:08:03       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:08:03       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:08:03       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_4.pickle"
[2018-06-08 13:08:03  start_training.py:129 -                      main()] Fidelity obtained: 0.863649426041587
[2018-06-08 13:08:05  start_training.py:101 -                      main()] Starting training no.5
[2018-06-08 13:08:05    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:08:05    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:08:05    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:08:05    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:08:05           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:08:05           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:08:05       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:08:05       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:08:05       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:08:05       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:08:05       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:08:05       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:08:05       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:08:05       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:08:05       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:08:06       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:08:09       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:08:10       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.4301989376320563
[2018-06-08 13:08:11       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.79690456161794
[2018-06-08 13:08:11       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6627861216746563
[2018-06-08 13:08:12       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9337618600484151
[2018-06-08 13:08:13       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9993809893001828
[2018-06-08 13:08:13       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999957366256967
[2018-06-08 13:08:14       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.99999999999998
[2018-06-08 13:08:15       Optimizer.py:490 -                      _run()]   Epoch no. 7: 1.0
[2018-06-08 13:08:15       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:08:15       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:08:15       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:08:15       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:08:15       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_5.pickle"
[2018-06-08 13:08:15  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:08:17  start_training.py:101 -                      main()] Starting training no.6
[2018-06-08 13:08:17    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:08:17    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:08:17    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:08:17    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:08:17           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:08:17           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:08:17       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:08:17       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:08:17       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:08:17       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:08:17       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:08:17       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:08:17       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:08:17       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:08:17       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:08:17       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:08:21       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:08:22       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7413415959292413
[2018-06-08 13:08:23       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8934661482017353
[2018-06-08 13:08:24       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6894189550979821
[2018-06-08 13:08:25       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8742907157139895
[2018-06-08 13:08:26       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8968381464399887
[2018-06-08 13:08:27       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9985141565290853
[2018-06-08 13:08:28       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9993103621239566
[2018-06-08 13:08:29       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999985967459
[2018-06-08 13:08:29       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999999999999
[2018-06-08 13:08:30       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999999999
[2018-06-08 13:08:30       Optimizer.py:490 -                      _run()]   Epoch no. 10: 1.0
[2018-06-08 13:08:30       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:08:30       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:08:30       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:08:30       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:08:30       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_6.pickle"
[2018-06-08 13:08:30  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:08:32  start_training.py:101 -                      main()] Starting training no.7
[2018-06-08 13:08:32    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:08:32    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:08:32    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:08:32    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:08:33           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:08:33           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:08:33       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:08:33       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:08:33       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:08:33       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:08:33       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:08:33       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:08:33       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:08:33       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:08:33       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:08:33       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:08:36       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:08:37       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5455530760629432
[2018-06-08 13:08:38       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9034490839577923
[2018-06-08 13:08:38       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6546466300407562
[2018-06-08 13:08:39       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9171945946343864
[2018-06-08 13:08:40       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9984460718135538
[2018-06-08 13:08:41       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.999995786354234
[2018-06-08 13:08:42       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999749433686
[2018-06-08 13:08:43       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999991026409
[2018-06-08 13:08:44       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999999698713
[2018-06-08 13:08:45       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999985174
[2018-06-08 13:08:45       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999998626
[2018-06-08 13:08:46       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.999999999999992
[2018-06-08 13:08:47       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999999999994
[2018-06-08 13:08:47       Optimizer.py:490 -                      _run()]   Epoch no. 13: 1.0
[2018-06-08 13:08:47       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:08:47       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:08:47       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:08:47       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:08:47       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_7.pickle"
[2018-06-08 13:08:47  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:08:49  start_training.py:101 -                      main()] Starting training no.8
[2018-06-08 13:08:49    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:08:49    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:08:49    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:08:49    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:08:49           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:08:49           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:08:49       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:08:49       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:08:49       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:08:49       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:08:49       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:08:49       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:08:49       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:08:50       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:08:50       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:08:50       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:08:53       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:08:54       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7280754867989248
[2018-06-08 13:08:55       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7528203934310157
[2018-06-08 13:08:55       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6483187204898307
[2018-06-08 13:08:56       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.809301529249649
[2018-06-08 13:08:57       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9829516069819924
[2018-06-08 13:08:58       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9998019249628767
[2018-06-08 13:08:59       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999994408809
[2018-06-08 13:09:00       Optimizer.py:490 -                      _run()]   Epoch no. 7: 1.0
[2018-06-08 13:09:00       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:09:00       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:09:00       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:09:00       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:09:00       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_8.pickle"
[2018-06-08 13:09:00  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:09:03  start_training.py:101 -                      main()] Starting training no.9
[2018-06-08 13:09:03    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:09:03    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:09:03    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:09:03    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:09:03           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:09:03           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:09:03       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:09:03       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:09:03       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:09:03       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:09:03       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:09:03       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:09:03       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:09:03       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:09:03       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:09:03       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:09:07       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:09:08       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.380038092825843
[2018-06-08 13:09:09       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8145146963353659
[2018-06-08 13:09:10       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9400331512144576
[2018-06-08 13:09:11       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.5091939495575079
[2018-06-08 13:09:12       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8975511925844848
[2018-06-08 13:09:13       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9990565613732728
[2018-06-08 13:09:14       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.924697643809574
[2018-06-08 13:09:15       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9995782929458548
[2018-06-08 13:09:16       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999998543866
[2018-06-08 13:09:16       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999992382
[2018-06-08 13:09:17       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999999837
[2018-06-08 13:09:18       Optimizer.py:490 -                      _run()]   Epoch no. 11: 1.0
[2018-06-08 13:09:18       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:09:18       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:09:18       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:09:18       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:09:18       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_9.pickle"
[2018-06-08 13:09:18  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:09:20  start_training.py:101 -                      main()] Starting training no.10
[2018-06-08 13:09:20    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:09:20    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:09:20    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:09:20    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:09:20           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:09:20           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:09:20       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:09:20       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:09:20       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:09:20       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:09:20       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:09:20       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:09:20       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:09:20       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:09:20       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:09:20       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:09:23       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:09:24       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7228876542239081
[2018-06-08 13:09:24       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6272198930205457
[2018-06-08 13:09:25       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7944270600690833
[2018-06-08 13:09:26       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7725651450575997
[2018-06-08 13:09:26       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7778348947590561
[2018-06-08 13:09:27       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8011755700719041
[2018-06-08 13:09:27       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7765735811354539
[2018-06-08 13:09:28       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8332547722330945
[2018-06-08 13:09:29       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8543761510477208
[2018-06-08 13:09:29       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8303806520661258
[2018-06-08 13:09:30       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8357755076501582
[2018-06-08 13:09:30       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.712338711014446
[2018-06-08 13:09:31       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8442937661805371
[2018-06-08 13:09:32       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.7684942737157827
[2018-06-08 13:09:32       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8559966587441831
[2018-06-08 13:09:33       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8337772819273589
[2018-06-08 13:09:33       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8404267664980715
[2018-06-08 13:09:34       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.846562055630206
[2018-06-08 13:09:35       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8549823700820868
[2018-06-08 13:09:35       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8619472598145344
[2018-06-08 13:09:36       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8403514010251196
[2018-06-08 13:09:37       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.7866633577109926
[2018-06-08 13:09:37       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8392548850887431
[2018-06-08 13:09:38       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8309686099431487
[2018-06-08 13:09:38       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8290557819755431
[2018-06-08 13:09:39       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8547063976699382
[2018-06-08 13:09:39       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8544036304116968
[2018-06-08 13:09:40       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8581606585574231
[2018-06-08 13:09:41       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8460428554738043
[2018-06-08 13:09:41       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8553578254998857
[2018-06-08 13:09:42       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8432925792136426
[2018-06-08 13:09:42       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8634184152799859
[2018-06-08 13:09:43       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8634655128096864
[2018-06-08 13:09:44       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8427093511372459
[2018-06-08 13:09:44       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8591364077199731
[2018-06-08 13:09:45       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8570982527522765
[2018-06-08 13:09:45       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8545619694926073
[2018-06-08 13:09:46       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8590931808125145
[2018-06-08 13:09:47       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8577211333633612
[2018-06-08 13:09:47       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8647207006169075
[2018-06-08 13:09:48       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8654739069294878
[2018-06-08 13:09:48       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8640606336379407
[2018-06-08 13:09:49       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.864954411032719
[2018-06-08 13:09:50       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8527514359449817
[2018-06-08 13:09:51       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8632679505947649
[2018-06-08 13:09:51       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.865890426579805
[2018-06-08 13:09:52       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8578782126449843
[2018-06-08 13:09:53       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8479617212094023
[2018-06-08 13:09:53       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8635353785579256
[2018-06-08 13:09:54       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8427637945082855
[2018-06-08 13:09:54       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8543818560487026
[2018-06-08 13:09:55       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8590727261432107
[2018-06-08 13:09:56       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8633229491796987
[2018-06-08 13:09:56       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8608323087423329
[2018-06-08 13:09:57       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8646995162507674
[2018-06-08 13:09:57       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8552458725019153
[2018-06-08 13:09:58       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8504531349609634
[2018-06-08 13:09:59       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8597824501023967
[2018-06-08 13:09:59       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8610560738017423
[2018-06-08 13:10:00       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8576651151504155
[2018-06-08 13:10:01       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8620036764288601
[2018-06-08 13:10:01       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8390410133434618
[2018-06-08 13:10:02       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.861413622754274
[2018-06-08 13:10:02       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8619681850258302
[2018-06-08 13:10:03       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8635665324779163
[2018-06-08 13:10:04       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8525252255343484
[2018-06-08 13:10:04       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8531701203174579
[2018-06-08 13:10:05       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.857870491788498
[2018-06-08 13:10:06       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8610200770040168
[2018-06-08 13:10:06       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8420760812709394
[2018-06-08 13:10:07       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8519025252011333
[2018-06-08 13:10:07       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.860434514142145
[2018-06-08 13:10:08       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8582451079049543
[2018-06-08 13:10:09       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8520174869150331
[2018-06-08 13:10:09       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8647790661511254
[2018-06-08 13:10:10       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8589843109411831
[2018-06-08 13:10:11       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.862237555074529
[2018-06-08 13:10:11       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8579866036534934
[2018-06-08 13:10:12       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8654251229004167
[2018-06-08 13:10:12       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8545287658772561
[2018-06-08 13:10:13       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8611100325356951
[2018-06-08 13:10:14       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8669530293791076
[2018-06-08 13:10:14       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.857917311969333
[2018-06-08 13:10:15       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.861975782878377
[2018-06-08 13:10:15       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8660543997384713
[2018-06-08 13:10:16       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8629343721706323
[2018-06-08 13:10:17       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8616578498634745
[2018-06-08 13:10:17       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8636929523303459
[2018-06-08 13:10:18       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.861659685503225
[2018-06-08 13:10:18       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8610044421369643
[2018-06-08 13:10:19       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8642386575773868
[2018-06-08 13:10:19       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8595944773938272
[2018-06-08 13:10:20       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8643174997138101
[2018-06-08 13:10:21       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8668185957242968
[2018-06-08 13:10:21       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8568898369313428
[2018-06-08 13:10:22       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8648805174701178
[2018-06-08 13:10:22       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8667478326510886
[2018-06-08 13:10:23       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8662027738909341
[2018-06-08 13:10:23       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8666521788120649
[2018-06-08 13:10:24       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8625102762336653
[2018-06-08 13:10:24       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:10:24       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:10:24       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:10:24       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_10.pickle"
[2018-06-08 13:10:24  start_training.py:129 -                      main()] Fidelity obtained: 0.86580949288241
[2018-06-08 13:10:26  start_training.py:101 -                      main()] Starting training no.11
[2018-06-08 13:10:26    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:10:26    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:10:26    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:10:26    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:10:26           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:10:26           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:10:26       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:10:26       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:10:26       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:10:26       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:10:26       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:10:26       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:10:26       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:10:26       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:10:26       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:10:26       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:10:30       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:10:30       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.853446612782191
[2018-06-08 13:10:31       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5516799669493367
[2018-06-08 13:10:32       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7833792073100697
[2018-06-08 13:10:32       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8153262374290969
[2018-06-08 13:10:33       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7054398113501748
[2018-06-08 13:10:34       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8440550261342459
[2018-06-08 13:10:34       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8287184130230355
[2018-06-08 13:10:35       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8465019586361051
[2018-06-08 13:10:36       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.797170732431781
[2018-06-08 13:10:36       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.7106433436757098
[2018-06-08 13:10:37       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8401789725249864
[2018-06-08 13:10:38       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8662338704449728
[2018-06-08 13:10:38       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8113831932131345
[2018-06-08 13:10:39       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8507555853320725
[2018-06-08 13:10:40       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8345173902432549
[2018-06-08 13:10:40       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8454809838150777
[2018-06-08 13:10:41       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8495675403933215
[2018-06-08 13:10:42       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8478476931465999
[2018-06-08 13:10:42       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.7784153063975698
[2018-06-08 13:10:43       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8512558440917054
[2018-06-08 13:10:44       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8404247822115901
[2018-06-08 13:10:44       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8333960132179413
[2018-06-08 13:10:45       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8238800674505324
[2018-06-08 13:10:45       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8571797162020128
[2018-06-08 13:10:46       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8690996592838333
[2018-06-08 13:10:47       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8691680942604648
[2018-06-08 13:10:48       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8613843847988933
[2018-06-08 13:10:48       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8487782694377987
[2018-06-08 13:10:49       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8629412837558248
[2018-06-08 13:10:50       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8627389882177945
[2018-06-08 13:10:50       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8668081315086588
[2018-06-08 13:10:51       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8455359900020628
[2018-06-08 13:10:52       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8619573611585061
[2018-06-08 13:10:52       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8559737242603761
[2018-06-08 13:10:53       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8571303447688783
[2018-06-08 13:10:54       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8680637231790574
[2018-06-08 13:10:54       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8248542875085566
[2018-06-08 13:10:55       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8696364253534118
[2018-06-08 13:10:56       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8678762405368903
[2018-06-08 13:10:57       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8700403759086278
[2018-06-08 13:10:57       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8457825755930537
[2018-06-08 13:10:58       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.858026871682495
[2018-06-08 13:10:59       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8642832428912068
[2018-06-08 13:10:59       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8708256985645542
[2018-06-08 13:11:00       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8569027494962271
[2018-06-08 13:11:01       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8717527525773207
[2018-06-08 13:11:02       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8607365114105455
[2018-06-08 13:11:03       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8654959313836401
[2018-06-08 13:11:04       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8357758703216023
[2018-06-08 13:11:05       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8541820185401366
[2018-06-08 13:11:06       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8717591941559718
[2018-06-08 13:11:06       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8641774124643007
[2018-06-08 13:11:07       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8602023753210649
[2018-06-08 13:11:08       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8690866129883945
[2018-06-08 13:11:08       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8645487710968145
[2018-06-08 13:11:09       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8634268118060401
[2018-06-08 13:11:10       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8595802158370369
[2018-06-08 13:11:11       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8611268298765421
[2018-06-08 13:11:12       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8697550317734682
[2018-06-08 13:11:13       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8699060728303709
[2018-06-08 13:11:14       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8625602965224622
[2018-06-08 13:11:15       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8550155881909349
[2018-06-08 13:11:15       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8596150707743218
[2018-06-08 13:11:16       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8573667137141266
[2018-06-08 13:11:16       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8650703246937071
[2018-06-08 13:11:17       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8666304116357432
[2018-06-08 13:11:18       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8638357730762735
[2018-06-08 13:11:18       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8549525543281592
[2018-06-08 13:11:19       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8609433562400335
[2018-06-08 13:11:20       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8697735525667721
[2018-06-08 13:11:20       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8586216040640333
[2018-06-08 13:11:21       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8674965107268621
[2018-06-08 13:11:21       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8717334559458321
[2018-06-08 13:11:22       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8586861093210166
[2018-06-08 13:11:23       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8703552795989077
[2018-06-08 13:11:23       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8686058369866463
[2018-06-08 13:11:24       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.871314348543762
[2018-06-08 13:11:25       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8688653491051196
[2018-06-08 13:11:25       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8681818954665063
[2018-06-08 13:11:26       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8669845286115765
[2018-06-08 13:11:27       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8716503234194433
[2018-06-08 13:11:27       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8636398539922271
[2018-06-08 13:11:28       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8616268234559981
[2018-06-08 13:11:29       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.869625853811104
[2018-06-08 13:11:29       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8709854172297099
[2018-06-08 13:11:30       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.871288102399856
[2018-06-08 13:11:31       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8609526673051832
[2018-06-08 13:11:31       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8720684359530808
[2018-06-08 13:11:32       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8673508518343239
[2018-06-08 13:11:32       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8647989554754971
[2018-06-08 13:11:33       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.868658775783452
[2018-06-08 13:11:34       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8576277047058768
[2018-06-08 13:11:35       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8691208638588273
[2018-06-08 13:11:35       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.866366032282465
[2018-06-08 13:11:36       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8702900222757356
[2018-06-08 13:11:37       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8701507833752763
[2018-06-08 13:11:37       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.868145103436944
[2018-06-08 13:11:38       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8699096911145042
[2018-06-08 13:11:39       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8675775687924424
[2018-06-08 13:11:39       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8678569655974481
[2018-06-08 13:11:39       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:11:39       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:11:39       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:11:39       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_11.pickle"
[2018-06-08 13:11:39  start_training.py:129 -                      main()] Fidelity obtained: 0.8636845008511358
[2018-06-08 13:11:41  start_training.py:101 -                      main()] Starting training no.12
[2018-06-08 13:11:41    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:11:41    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:11:41    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:11:41    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:11:41           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:11:41           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:11:41       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:11:41       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:11:41       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:11:41       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:11:41       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:11:41       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:11:41       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:11:42       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:11:42       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:11:42       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:11:46       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:11:46       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.18253499066798756
[2018-06-08 13:11:47       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.22196320417827065
[2018-06-08 13:11:48       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.3810434914304182
[2018-06-08 13:11:48       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7537608713028048
[2018-06-08 13:11:49       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7550594553679645
[2018-06-08 13:11:50       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.973094260448
[2018-06-08 13:11:50       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9311522228454163
[2018-06-08 13:11:51       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9660853337225309
[2018-06-08 13:11:52       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9464586589463476
[2018-06-08 13:11:52       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.999471157593345
[2018-06-08 13:11:53       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999969394742267
[2018-06-08 13:11:54       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999976046595893
[2018-06-08 13:11:54       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999990405110486
[2018-06-08 13:11:55       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999986917928877
[2018-06-08 13:11:56       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999987466664941
[2018-06-08 13:11:56       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999988903604347
[2018-06-08 13:11:57       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999991118235928
[2018-06-08 13:11:57       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999991038247389
[2018-06-08 13:11:58       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999984038364683
[2018-06-08 13:11:59       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999992540533928
[2018-06-08 13:11:59       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999989829578871
[2018-06-08 13:12:00       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999991919471877
[2018-06-08 13:12:00       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999992152005356
[2018-06-08 13:12:01       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999992717057822
[2018-06-08 13:12:02       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999993602598084
[2018-06-08 13:12:02       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999993554314188
[2018-06-08 13:12:03       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.999999462316828
[2018-06-08 13:12:03       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999994533328587
[2018-06-08 13:12:04       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999991010674435
[2018-06-08 13:12:05       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999994810819192
[2018-06-08 13:12:05       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999992646141626
[2018-06-08 13:12:06       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.999999467905326
[2018-06-08 13:12:07       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999994739482382
[2018-06-08 13:12:07       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999994390464821
[2018-06-08 13:12:08       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999995562106042
[2018-06-08 13:12:09       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999994415710596
[2018-06-08 13:12:09       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999995590739991
[2018-06-08 13:12:10       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999995825515076
[2018-06-08 13:12:11       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.999999597229003
[2018-06-08 13:12:11       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999996137561683
[2018-06-08 13:12:12       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999995726552886
[2018-06-08 13:12:13       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999996293596807
[2018-06-08 13:12:13       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999996479310782
[2018-06-08 13:12:14       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.999999627224526
[2018-06-08 13:12:14       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999994604481626
[2018-06-08 13:12:15       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999996306013892
[2018-06-08 13:12:16       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999996764634648
[2018-06-08 13:12:16       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999996228753721
[2018-06-08 13:12:17       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999996876153119
[2018-06-08 13:12:17       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.999999678232017
[2018-06-08 13:12:18       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999996964103036
[2018-06-08 13:12:19       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999997071166181
[2018-06-08 13:12:19       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.99999964948104
[2018-06-08 13:12:20       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999997186031166
[2018-06-08 13:12:21       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.999999721301846
[2018-06-08 13:12:21       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.999999615396889
[2018-06-08 13:12:22       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999997290454562
[2018-06-08 13:12:23       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999997304618315
[2018-06-08 13:12:24       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.999999703500192
[2018-06-08 13:12:25       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999997343701956
[2018-06-08 13:12:25       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999997449743173
[2018-06-08 13:12:26       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999997263260709
[2018-06-08 13:12:27       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999997536323797
[2018-06-08 13:12:27       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999997637357295
[2018-06-08 13:12:28       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999996573086044
[2018-06-08 13:12:29       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999997614459879
[2018-06-08 13:12:29       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999997541125819
[2018-06-08 13:12:30       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.999999764190007
[2018-06-08 13:12:30       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999997649256563
[2018-06-08 13:12:31       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999997831957737
[2018-06-08 13:12:32       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999997771926756
[2018-06-08 13:12:32       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999997534223778
[2018-06-08 13:12:33       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999997516554927
[2018-06-08 13:12:33       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999997700198108
[2018-06-08 13:12:34       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999997897667771
[2018-06-08 13:12:35       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999997953643127
[2018-06-08 13:12:35       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999998035613494
[2018-06-08 13:12:36       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999998047927938
[2018-06-08 13:12:36       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999997861314601
[2018-06-08 13:12:37       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.99999980698751
[2018-06-08 13:12:38       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999998086213704
[2018-06-08 13:12:38       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999998043609586
[2018-06-08 13:12:39       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999998166828604
[2018-06-08 13:12:39       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999998169137014
[2018-06-08 13:12:40       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999998168478669
[2018-06-08 13:12:41       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999998194080432
[2018-06-08 13:12:41       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999998238495867
[2018-06-08 13:12:42       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999998285823665
[2018-06-08 13:12:42       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.999999829247823
[2018-06-08 13:12:43       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999998272455919
[2018-06-08 13:12:44       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999998298113841
[2018-06-08 13:12:44       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999998345175395
[2018-06-08 13:12:45       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999998341918527
[2018-06-08 13:12:46       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999998354950485
[2018-06-08 13:12:46       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999998208173408
[2018-06-08 13:12:47       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999998420590369
[2018-06-08 13:12:47       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999998416427551
[2018-06-08 13:12:48       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999998269574049
[2018-06-08 13:12:49       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999998153003754
[2018-06-08 13:12:49       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999998436945932
[2018-06-08 13:12:49       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:12:49       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:12:49       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:12:49       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_12.pickle"
[2018-06-08 13:12:49  start_training.py:129 -                      main()] Fidelity obtained: 0.9999998321504553
[2018-06-08 13:12:51  start_training.py:101 -                      main()] Starting training no.13
[2018-06-08 13:12:51    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:12:51    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:12:51    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:12:51    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:12:51           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:12:51           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:12:51       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:12:51       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:12:51       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:12:51       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:12:51       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:12:51       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:12:51       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:12:52       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:12:52       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:12:52       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:12:55       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:12:55       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.16774191279911788
[2018-06-08 13:12:56       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7931396067600944
[2018-06-08 13:12:57       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6902767150173338
[2018-06-08 13:12:57       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.6646257494600011
[2018-06-08 13:12:58       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9959651713102591
[2018-06-08 13:12:59       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999055068430778
[2018-06-08 13:12:59       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999899624814523
[2018-06-08 13:13:00       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999995423787306
[2018-06-08 13:13:01       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999882870921
[2018-06-08 13:13:02       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999985049804
[2018-06-08 13:13:02       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999292203
[2018-06-08 13:13:03       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999999999943548
[2018-06-08 13:13:04       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999999992855
[2018-06-08 13:13:04       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999999999322
[2018-06-08 13:13:05       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999999999879
[2018-06-08 13:13:06       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999999999987
[2018-06-08 13:13:06       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999999999999
[2018-06-08 13:13:07       Optimizer.py:490 -                      _run()]   Epoch no. 17: 1.0
[2018-06-08 13:13:07       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:13:07       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:13:07       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:13:07       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:13:07       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_13.pickle"
[2018-06-08 13:13:07  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:13:09  start_training.py:101 -                      main()] Starting training no.14
[2018-06-08 13:13:09    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:13:09    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:13:09    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:13:09    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:13:09           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:13:09           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:13:09       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:13:09       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:13:09       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:13:09       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:13:09       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:13:09       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:13:09       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:13:09       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:13:09       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:13:09       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:13:13       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:13:14       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7269140562109571
[2018-06-08 13:13:14       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.363229098304972
[2018-06-08 13:13:15       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.329320746444703
[2018-06-08 13:13:16       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.38353535138060607
[2018-06-08 13:13:16       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.14441180799995798
[2018-06-08 13:13:17       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.908291071998302
[2018-06-08 13:13:17       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7738845435586975
[2018-06-08 13:13:18       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9263382932441837
[2018-06-08 13:13:19       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8672449229081961
[2018-06-08 13:13:19       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9104506462175564
[2018-06-08 13:13:20       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9886729234997347
[2018-06-08 13:13:21       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9868945622899435
[2018-06-08 13:13:21       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9460489938904837
[2018-06-08 13:13:22       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9640365983380768
[2018-06-08 13:13:22       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.999996291023386
[2018-06-08 13:13:23       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999999769499
[2018-06-08 13:13:24       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999999999987
[2018-06-08 13:13:24       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999999999999
[2018-06-08 13:13:25       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999999999999
[2018-06-08 13:13:25       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999999999997
[2018-06-08 13:13:26       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999999999999
[2018-06-08 13:13:27       Optimizer.py:490 -                      _run()]   Epoch no. 21: 1.0000000000000002
[2018-06-08 13:13:27       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999999999999
[2018-06-08 13:13:28       Optimizer.py:490 -                      _run()]   Epoch no. 23: 1.0
[2018-06-08 13:13:28       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:13:28       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:13:28       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:13:28       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:13:28       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_14.pickle"
[2018-06-08 13:13:28  start_training.py:129 -                      main()] Fidelity obtained: 1.000000000000001
[2018-06-08 13:13:30  start_training.py:101 -                      main()] Starting training no.15
[2018-06-08 13:13:30    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:13:30    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:13:30    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:13:30    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:13:30           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:13:30           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:13:30       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:13:30       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:13:30       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:13:30       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:13:30       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:13:30       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:13:30       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:13:30       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:13:30       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:13:30       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:13:33       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:13:33       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5626078999157909
[2018-06-08 13:13:34       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5524253788034043
[2018-06-08 13:13:35       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6519292317928085
[2018-06-08 13:13:35       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7109818497547832
[2018-06-08 13:13:36       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9903072614437598
[2018-06-08 13:13:37       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9907916460452313
[2018-06-08 13:13:37       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999997464825
[2018-06-08 13:13:38       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999999993
[2018-06-08 13:13:39       Optimizer.py:490 -                      _run()]   Epoch no. 8: 1.0000000000000002
[2018-06-08 13:13:39       Optimizer.py:490 -                      _run()]   Epoch no. 9: 1.0000000000000002
[2018-06-08 13:13:40       Optimizer.py:490 -                      _run()]   Epoch no. 10: 1.0
[2018-06-08 13:13:40       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:13:40       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:13:40       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:13:40       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:13:40       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_15.pickle"
[2018-06-08 13:13:40  start_training.py:129 -                      main()] Fidelity obtained: 1.0000000000000002
[2018-06-08 13:13:42  start_training.py:101 -                      main()] Starting training no.16
[2018-06-08 13:13:42    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:13:42    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:13:42    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:13:42    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:13:42           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:13:42           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:13:42       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:13:42       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:13:42       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:13:42       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:13:42       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:13:42       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:13:42       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:13:42       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:13:42       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:13:42       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:13:46       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:13:46       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5776355519182893
[2018-06-08 13:13:47       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8423165343526285
[2018-06-08 13:13:48       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8632556627946556
[2018-06-08 13:13:49       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9290008833537506
[2018-06-08 13:13:49       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9935924426193058
[2018-06-08 13:13:50       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9996728132544106
[2018-06-08 13:13:51       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999276082816242
[2018-06-08 13:13:51       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999917832408436
[2018-06-08 13:13:52       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999985862466706
[2018-06-08 13:13:53       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999996869859221
[2018-06-08 13:13:53       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999997687434459
[2018-06-08 13:13:54       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999999608008133
[2018-06-08 13:13:55       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999783188644
[2018-06-08 13:13:55       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999948860075
[2018-06-08 13:13:56       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999975342942
[2018-06-08 13:13:57       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999991646156
[2018-06-08 13:13:57       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999996346696
[2018-06-08 13:13:58       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999998106344
[2018-06-08 13:13:58       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999999046838
[2018-06-08 13:13:59       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999999616981
[2018-06-08 13:14:00       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999999780276
[2018-06-08 13:14:00       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999999892598
[2018-06-08 13:14:01       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999999946609
[2018-06-08 13:14:01       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999999975121
[2018-06-08 13:14:02       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999999999983296
[2018-06-08 13:14:03       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999999999989367
[2018-06-08 13:14:03       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999999995798
[2018-06-08 13:14:04       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999999996655
[2018-06-08 13:14:05       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999999998461
[2018-06-08 13:14:05       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999999999998517
[2018-06-08 13:14:06       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999999999999537
[2018-06-08 13:14:06       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999999999719
[2018-06-08 13:14:07       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999999999999833
[2018-06-08 13:14:08       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999999999898
[2018-06-08 13:14:09       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999999999999915
[2018-06-08 13:14:10       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999999999976
[2018-06-08 13:14:11       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999999999984
[2018-06-08 13:14:11       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999999999999993
[2018-06-08 13:14:12       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999999999999999
[2018-06-08 13:14:13       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999999999996
[2018-06-08 13:14:13       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999999999999999
[2018-06-08 13:14:14       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999999999999999
[2018-06-08 13:14:15       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999999999999
[2018-06-08 13:14:15       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999999999999997
[2018-06-08 13:14:16       Optimizer.py:490 -                      _run()]   Epoch no. 44: 1.0
[2018-06-08 13:14:16       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:14:16       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:14:16       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:14:16       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:14:16       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_16.pickle"
[2018-06-08 13:14:16  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:14:18  start_training.py:101 -                      main()] Starting training no.17
[2018-06-08 13:14:18    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:14:18    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:14:18    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:14:18    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:14:18           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:14:18           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:14:18       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:14:18       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:14:18       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:14:18       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:14:18       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:14:18       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:14:18       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:14:18       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:14:18       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:14:18       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:14:22       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:14:23       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6612419343758618
[2018-06-08 13:14:24       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.2550507148177952
[2018-06-08 13:14:24       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9267328810035544
[2018-06-08 13:14:25       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9493947492054893
[2018-06-08 13:14:26       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.600834008662735
[2018-06-08 13:14:26       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9942222161021824
[2018-06-08 13:14:27       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999982519158
[2018-06-08 13:14:28       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999999997
[2018-06-08 13:14:28       Optimizer.py:490 -                      _run()]   Epoch no. 8: 1.0
[2018-06-08 13:14:28       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:14:28       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:14:28       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:14:28       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:14:28       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_17.pickle"
[2018-06-08 13:14:28  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:14:30  start_training.py:101 -                      main()] Starting training no.18
[2018-06-08 13:14:30    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:14:30    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:14:30    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:14:30    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:14:30           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:14:30           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:14:30       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:14:30       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:14:30       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:14:30       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:14:30       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:14:30       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:14:30       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:14:30       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:14:30       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:14:31       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:14:34       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:14:35       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.32355817226287825
[2018-06-08 13:14:36       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6471884404157331
[2018-06-08 13:14:37       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6257702842094671
[2018-06-08 13:14:37       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.45636055348420135
[2018-06-08 13:14:38       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.23849018418674184
[2018-06-08 13:14:39       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.34530974892027705
[2018-06-08 13:14:39       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9207512830792957
[2018-06-08 13:14:40       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.40755975493704844
[2018-06-08 13:14:40       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9632616552785184
[2018-06-08 13:14:41       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9026688331408296
[2018-06-08 13:14:42       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.906032219235915
[2018-06-08 13:14:42       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.7149067133380895
[2018-06-08 13:14:43       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9795984305332499
[2018-06-08 13:14:44       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8296703329450835
[2018-06-08 13:14:44       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999956574044557
[2018-06-08 13:14:45       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999999990853
[2018-06-08 13:14:46       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999999999999
[2018-06-08 13:14:46       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999999999994
[2018-06-08 13:14:47       Optimizer.py:490 -                      _run()]   Epoch no. 18: 1.0000000000000009
[2018-06-08 13:14:47       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.999999999999999
[2018-06-08 13:14:48       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.999999999999998
[2018-06-08 13:14:49       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999999999979
[2018-06-08 13:14:49       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999999999983
[2018-06-08 13:14:50       Optimizer.py:490 -                      _run()]   Epoch no. 23: 1.0000000000000002
[2018-06-08 13:14:51       Optimizer.py:490 -                      _run()]   Epoch no. 24: 1.0000000000000007
[2018-06-08 13:14:51       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999999999999994
[2018-06-08 13:14:52       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999999999996
[2018-06-08 13:14:53       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999999999997
[2018-06-08 13:14:53       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999999999973
[2018-06-08 13:14:54       Optimizer.py:490 -                      _run()]   Epoch no. 29: 1.0000000000000007
[2018-06-08 13:14:54       Optimizer.py:490 -                      _run()]   Epoch no. 30: 1.0000000000000013
[2018-06-08 13:14:55       Optimizer.py:490 -                      _run()]   Epoch no. 31: 1.0000000000000016
[2018-06-08 13:14:56       Optimizer.py:490 -                      _run()]   Epoch no. 32: 1.0000000000000018
[2018-06-08 13:14:57       Optimizer.py:490 -                      _run()]   Epoch no. 33: 1.0
[2018-06-08 13:14:57       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:14:57       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:14:57       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:14:57       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:14:57       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_18.pickle"
[2018-06-08 13:14:57  start_training.py:129 -                      main()] Fidelity obtained: 1.0000000000000009
[2018-06-08 13:15:00  start_training.py:101 -                      main()] Starting training no.19
[2018-06-08 13:15:00    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:15:00    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:15:00    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:15:00    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:15:00           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:15:00           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:15:00       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:15:00       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:15:00       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:15:00       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:15:00       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:15:00       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:15:00       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:15:00       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:15:00       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:15:00       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:15:04       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:15:05       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.39467001163815996
[2018-06-08 13:15:05       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.21765152099653826
[2018-06-08 13:15:06       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.414739550648413
[2018-06-08 13:15:07       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.30938150118861363
[2018-06-08 13:15:07       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.1094793943173891
[2018-06-08 13:15:08       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.5950165393438694
[2018-06-08 13:15:09       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9959183725485992
[2018-06-08 13:15:09       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9981007811621754
[2018-06-08 13:15:10       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9995124695269813
[2018-06-08 13:15:11       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999655444870136
[2018-06-08 13:15:11       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999965419031875
[2018-06-08 13:15:12       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999991842250125
[2018-06-08 13:15:13       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999979024952332
[2018-06-08 13:15:13       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999860482107659
[2018-06-08 13:15:14       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999990924458774
[2018-06-08 13:15:15       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999989468645794
[2018-06-08 13:15:16       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999992864055938
[2018-06-08 13:15:16       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999996404472924
[2018-06-08 13:15:17       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999995407840673
[2018-06-08 13:15:18       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999993131788182
[2018-06-08 13:15:19       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.999999757610389
[2018-06-08 13:15:19       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999997023360061
[2018-06-08 13:15:20       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999996355029864
[2018-06-08 13:15:21       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999997641381594
[2018-06-08 13:15:22       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.99999982799993
[2018-06-08 13:15:22       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999998344113733
[2018-06-08 13:15:23       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999998044686264
[2018-06-08 13:15:23       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999998438432446
[2018-06-08 13:15:24       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999998153893058
[2018-06-08 13:15:25       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999998642601722
[2018-06-08 13:15:25       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999998858472982
[2018-06-08 13:15:26       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999997373941614
[2018-06-08 13:15:26       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999998443632316
[2018-06-08 13:15:27       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999998212413657
[2018-06-08 13:15:28       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999998931959955
[2018-06-08 13:15:28       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999998951191108
[2018-06-08 13:15:29       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999998964143344
[2018-06-08 13:15:30       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999998824011491
[2018-06-08 13:15:30       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999999066389601
[2018-06-08 13:15:31       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999998905090207
[2018-06-08 13:15:31       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.999999917133937
[2018-06-08 13:15:32       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999998924143035
[2018-06-08 13:15:33       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999262829603
[2018-06-08 13:15:33       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999999289897494
[2018-06-08 13:15:34       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999999302133333
[2018-06-08 13:15:34       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999308365465
[2018-06-08 13:15:35       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999353891973
[2018-06-08 13:15:36       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999999360860656
[2018-06-08 13:15:36       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.99999993693747
[2018-06-08 13:15:37       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999999275602497
[2018-06-08 13:15:37       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999999343861403
[2018-06-08 13:15:38       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999999437946075
[2018-06-08 13:15:39       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999999255898568
[2018-06-08 13:15:39       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999999477001404
[2018-06-08 13:15:40       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999999484894534
[2018-06-08 13:15:41       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999999442324197
[2018-06-08 13:15:41       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999508513747
[2018-06-08 13:15:42       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999999509102477
[2018-06-08 13:15:42       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999999530149725
[2018-06-08 13:15:43       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999999496035804
[2018-06-08 13:15:44       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999999385297407
[2018-06-08 13:15:44       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999999538072117
[2018-06-08 13:15:45       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999999292008949
[2018-06-08 13:15:46       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999999586253229
[2018-06-08 13:15:47       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999999570491849
[2018-06-08 13:15:47       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999999507796674
[2018-06-08 13:15:48       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999999599803613
[2018-06-08 13:15:49       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.99999996270108
[2018-06-08 13:15:49       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999999607950738
[2018-06-08 13:15:50       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.999999963393604
[2018-06-08 13:15:51       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999999650657928
[2018-06-08 13:15:51       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999999659183072
[2018-06-08 13:15:52       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.999999967027673
[2018-06-08 13:15:53       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999999638211574
[2018-06-08 13:15:54       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999999677345032
[2018-06-08 13:15:54       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999999627318487
[2018-06-08 13:15:55       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999999599961258
[2018-06-08 13:15:56       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999999697784655
[2018-06-08 13:15:56       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999999700186762
[2018-06-08 13:15:57       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999999631735393
[2018-06-08 13:15:57       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999999716408865
[2018-06-08 13:15:58       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999999722032675
[2018-06-08 13:15:59       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999999728606993
[2018-06-08 13:15:59       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999999733114159
[2018-06-08 13:16:00       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999999735581391
[2018-06-08 13:16:00       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999999648577145
[2018-06-08 13:16:01       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999999746204218
[2018-06-08 13:16:02       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999999746458037
[2018-06-08 13:16:02       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999999748412898
[2018-06-08 13:16:03       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999999754745998
[2018-06-08 13:16:03       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.999999976598688
[2018-06-08 13:16:04       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999999698950752
[2018-06-08 13:16:05       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999999758083841
[2018-06-08 13:16:06       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999999776488423
[2018-06-08 13:16:06       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999999783267326
[2018-06-08 13:16:07       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999999787281811
[2018-06-08 13:16:07       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999999789534881
[2018-06-08 13:16:08       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999999789596794
[2018-06-08 13:16:09       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999999789520244
[2018-06-08 13:16:09       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999999794336341
[2018-06-08 13:16:09       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:16:09       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:16:09       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:16:09       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_19.pickle"
[2018-06-08 13:16:09  start_training.py:129 -                      main()] Fidelity obtained: 0.9999999796266191
[2018-06-08 13:16:12  start_training.py:101 -                      main()] Starting training no.20
[2018-06-08 13:16:12    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:16:12    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:16:12    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:16:12    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:16:13           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:16:13           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:16:13       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:16:13       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:16:13       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:16:13       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:16:13       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:16:13       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:16:13       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:16:13       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:16:13       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:16:13       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:16:17       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:16:18       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6086465351733802
[2018-06-08 13:16:19       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5321521984408282
[2018-06-08 13:16:20       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.4545569925016696
[2018-06-08 13:16:21       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.6477048823482295
[2018-06-08 13:16:21       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7245550694220416
[2018-06-08 13:16:22       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.6728135524614673
[2018-06-08 13:16:23       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7289766567452731
[2018-06-08 13:16:24       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.7705136918690784
[2018-06-08 13:16:24       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.7902067523092207
[2018-06-08 13:16:25       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8007630430309916
[2018-06-08 13:16:26       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8393520922431043
[2018-06-08 13:16:26       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.6450296039426057
[2018-06-08 13:16:27       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.7904013202647496
[2018-06-08 13:16:28       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8281928815285677
[2018-06-08 13:16:28       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8211003411578852
[2018-06-08 13:16:29       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8516167266842509
[2018-06-08 13:16:30       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8577554100448043
[2018-06-08 13:16:30       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8440857063915388
[2018-06-08 13:16:31       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8551838957184229
[2018-06-08 13:16:32       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.7930415089561085
[2018-06-08 13:16:32       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8523243217559873
[2018-06-08 13:16:33       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8381088472005364
[2018-06-08 13:16:34       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8463186323642168
[2018-06-08 13:16:34       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8451536845323376
[2018-06-08 13:16:35       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8328915938530599
[2018-06-08 13:16:36       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8588008683796357
[2018-06-08 13:16:36       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8265950873723868
[2018-06-08 13:16:37       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8408634480450357
[2018-06-08 13:16:37       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8596202840180289
[2018-06-08 13:16:38       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8425419670593983
[2018-06-08 13:16:39       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.811569984748614
[2018-06-08 13:16:39       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8503800613929675
[2018-06-08 13:16:40       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8506014711325072
[2018-06-08 13:16:40       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8436886551121259
[2018-06-08 13:16:41       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8548913977250581
[2018-06-08 13:16:42       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8532784885079056
[2018-06-08 13:16:42       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8615949559246551
[2018-06-08 13:16:43       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8532792160956919
[2018-06-08 13:16:43       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8469571394582025
[2018-06-08 13:16:44       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8612697263187337
[2018-06-08 13:16:45       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8324614354950819
[2018-06-08 13:16:45       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8538000063039144
[2018-06-08 13:16:46       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8545037831925764
[2018-06-08 13:16:46       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8611527587317798
[2018-06-08 13:16:47       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8625344147956834
[2018-06-08 13:16:48       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8603847055603023
[2018-06-08 13:16:48       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8496997739678248
[2018-06-08 13:16:49       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.858095035190462
[2018-06-08 13:16:49       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8442689601244412
[2018-06-08 13:16:50       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8608541425954357
[2018-06-08 13:16:51       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8512859000690298
[2018-06-08 13:16:51       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8644345918456838
[2018-06-08 13:16:52       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8641235038789494
[2018-06-08 13:16:52       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8430109291813223
[2018-06-08 13:16:53       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.86766141973538
[2018-06-08 13:16:54       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8460401744421895
[2018-06-08 13:16:54       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8503372358120869
[2018-06-08 13:16:55       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8620731059042471
[2018-06-08 13:16:56       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8549160740665122
[2018-06-08 13:16:56       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8615129123916723
[2018-06-08 13:16:57       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8625237372821434
[2018-06-08 13:16:57       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8594668289024721
[2018-06-08 13:16:58       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.855446599287623
[2018-06-08 13:16:59       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8593286186897943
[2018-06-08 13:16:59       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8658575922791479
[2018-06-08 13:17:00       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8620051792247306
[2018-06-08 13:17:00       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8656946089787912
[2018-06-08 13:17:01       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8607205013869074
[2018-06-08 13:17:02       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8590448849954124
[2018-06-08 13:17:02       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8627443177345485
[2018-06-08 13:17:03       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8657275005712328
[2018-06-08 13:17:03       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8602106019099652
[2018-06-08 13:17:04       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8673558350454772
[2018-06-08 13:17:05       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8577887516948082
[2018-06-08 13:17:05       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8634230673370032
[2018-06-08 13:17:06       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8645293660287819
[2018-06-08 13:17:06       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8624575613196808
[2018-06-08 13:17:07       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8517713986030979
[2018-06-08 13:17:08       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.865710346836769
[2018-06-08 13:17:08       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8615497584085591
[2018-06-08 13:17:09       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8569436672864659
[2018-06-08 13:17:10       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8606020732742199
[2018-06-08 13:17:10       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8595776004191567
[2018-06-08 13:17:11       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8589317474670586
[2018-06-08 13:17:11       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8445110215473528
[2018-06-08 13:17:12       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8606807941038567
[2018-06-08 13:17:13       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8565371498591261
[2018-06-08 13:17:13       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8587185295291707
[2018-06-08 13:17:14       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8609849151837485
[2018-06-08 13:17:14       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8628715000907394
[2018-06-08 13:17:15       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8540808913664655
[2018-06-08 13:17:16       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8507289789200168
[2018-06-08 13:17:16       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8615005725503012
[2018-06-08 13:17:17       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8652080126451112
[2018-06-08 13:17:18       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8617347250464001
[2018-06-08 13:17:18       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8657703465259823
[2018-06-08 13:17:19       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8628318568339242
[2018-06-08 13:17:20       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8595323467062194
[2018-06-08 13:17:20       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8673187666119735
[2018-06-08 13:17:21       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8616620352093827
[2018-06-08 13:17:21       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:17:21       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:17:21       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:17:21       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_20.pickle"
[2018-06-08 13:17:21  start_training.py:129 -                      main()] Fidelity obtained: 0.8622401175585447
[2018-06-08 13:17:23  start_training.py:101 -                      main()] Starting training no.21
[2018-06-08 13:17:23    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:17:23    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:17:23    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:17:23    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:17:23           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:17:23           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:17:23       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:17:23       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:17:23       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:17:23       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:17:23       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:17:23       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:17:23       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:17:23       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:17:23       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:17:23       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:17:27       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:17:28       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8987347871226791
[2018-06-08 13:17:28       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5965832250974193
[2018-06-08 13:17:29       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7923892438968407
[2018-06-08 13:17:30       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8034805333247276
[2018-06-08 13:17:31       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7438794834427802
[2018-06-08 13:17:32       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.7346957223511922
[2018-06-08 13:17:33       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7904520650417828
[2018-06-08 13:17:33       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.7728461232477332
[2018-06-08 13:17:34       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8370876142215211
[2018-06-08 13:17:35       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8412425041658806
[2018-06-08 13:17:36       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8456790957328069
[2018-06-08 13:17:36       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8234763803049181
[2018-06-08 13:17:37       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8278680039878484
[2018-06-08 13:17:37       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8239347702910801
[2018-06-08 13:17:38       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.7547324142419128
[2018-06-08 13:17:39       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8249211162193977
[2018-06-08 13:17:39       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8591966298314747
[2018-06-08 13:17:40       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.850464133906383
[2018-06-08 13:17:40       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8289186176547707
[2018-06-08 13:17:41       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8233215399723209
[2018-06-08 13:17:42       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8617572789697941
[2018-06-08 13:17:42       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8214017149354281
[2018-06-08 13:17:43       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8611474216828163
[2018-06-08 13:17:43       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8173145171874239
[2018-06-08 13:17:44       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8517347989408247
[2018-06-08 13:17:45       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8390919728685721
[2018-06-08 13:17:45       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8481326945049403
[2018-06-08 13:17:46       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8553597216434552
[2018-06-08 13:17:46       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8603740806783903
[2018-06-08 13:17:47       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8653114246244558
[2018-06-08 13:17:48       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8651662153250945
[2018-06-08 13:17:49       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8622066637683332
[2018-06-08 13:17:49       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8359581861653524
[2018-06-08 13:17:50       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8658704087125457
[2018-06-08 13:17:51       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8593654524544503
[2018-06-08 13:17:51       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8428832495594221
[2018-06-08 13:17:52       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8570438615163347
[2018-06-08 13:17:52       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8696451929916413
[2018-06-08 13:17:53       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8397925747953535
[2018-06-08 13:17:54       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8541519906309396
[2018-06-08 13:17:54       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8543054865255296
[2018-06-08 13:17:55       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8621660590782726
[2018-06-08 13:17:55       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8661986275245639
[2018-06-08 13:17:56       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8645300054427061
[2018-06-08 13:17:57       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8529555498962796
[2018-06-08 13:17:57       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8635202959083519
[2018-06-08 13:17:58       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8575346092106635
[2018-06-08 13:17:58       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8602068837208233
[2018-06-08 13:17:59       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.856120359935111
[2018-06-08 13:18:00       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8625949557918818
[2018-06-08 13:18:01       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8671151179884449
[2018-06-08 13:18:02       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8646049792469559
[2018-06-08 13:18:03       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.865965887932769
[2018-06-08 13:18:04       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.869771664631816
[2018-06-08 13:18:05       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8691175635807308
[2018-06-08 13:18:05       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8576332736933527
[2018-06-08 13:18:06       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8694785207838188
[2018-06-08 13:18:07       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8667755638182928
[2018-06-08 13:18:08       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8621869452197685
[2018-06-08 13:18:08       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8709202686195188
[2018-06-08 13:18:09       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8613853687831045
[2018-06-08 13:18:10       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8694788262446618
[2018-06-08 13:18:10       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8641748837951014
[2018-06-08 13:18:11       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8686506372063953
[2018-06-08 13:18:12       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8652864797847054
[2018-06-08 13:18:12       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8657204690325949
[2018-06-08 13:18:13       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8713871728957802
[2018-06-08 13:18:14       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8480676744487833
[2018-06-08 13:18:14       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.868940353508857
[2018-06-08 13:18:15       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8564042830560773
[2018-06-08 13:18:16       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8565959131430764
[2018-06-08 13:18:16       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8676028159975401
[2018-06-08 13:18:17       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8633081991914756
[2018-06-08 13:18:17       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8611414157559321
[2018-06-08 13:18:18       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8576016187777172
[2018-06-08 13:18:19       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8655782782497902
[2018-06-08 13:18:19       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.863153225015202
[2018-06-08 13:18:20       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8701172384907129
[2018-06-08 13:18:21       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8627862632861677
[2018-06-08 13:18:21       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8687080636906518
[2018-06-08 13:18:22       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8613982929217963
[2018-06-08 13:18:23       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8565348802915529
[2018-06-08 13:18:23       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8703295292206359
[2018-06-08 13:18:24       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8610614576578189
[2018-06-08 13:18:24       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8663421528024373
[2018-06-08 13:18:25       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8716129858675531
[2018-06-08 13:18:26       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8684284301753701
[2018-06-08 13:18:26       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8591023461544544
[2018-06-08 13:18:27       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8709444881843276
[2018-06-08 13:18:28       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8683857306707796
[2018-06-08 13:18:28       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8666452404838124
[2018-06-08 13:18:29       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.869815439045804
[2018-06-08 13:18:30       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.869360025278333
[2018-06-08 13:18:30       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8723286155012314
[2018-06-08 13:18:31       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8646415647870433
[2018-06-08 13:18:32       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8723669924329388
[2018-06-08 13:18:33       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8682239792588824
[2018-06-08 13:18:34       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8688182859111143
[2018-06-08 13:18:35       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8719991527564674
[2018-06-08 13:18:36       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8706243131239364
[2018-06-08 13:18:36       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:18:36       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:18:36       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:18:36       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_21.pickle"
[2018-06-08 13:18:36  start_training.py:129 -                      main()] Fidelity obtained: 0.8655763374373907
[2018-06-08 13:18:39  start_training.py:101 -                      main()] Starting training no.22
[2018-06-08 13:18:39    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:18:39    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:18:39    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:18:39    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:18:39           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:18:39           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:18:39       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:18:39       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:18:39       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:18:39       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:18:39       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:18:39       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:18:39       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:18:39       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:18:39       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:18:39       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:18:43       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:18:44       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5122663262008884
[2018-06-08 13:18:45       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7524416846355549
[2018-06-08 13:18:46       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6880419457735902
[2018-06-08 13:18:47       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8200741278930717
[2018-06-08 13:18:48       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7963763364289212
[2018-06-08 13:18:49       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8511059107345516
[2018-06-08 13:18:49       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8031940305750005
[2018-06-08 13:18:50       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8339998280854705
[2018-06-08 13:18:51       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.7708899112456348
[2018-06-08 13:18:51       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8194943219787671
[2018-06-08 13:18:52       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.83675712000916
[2018-06-08 13:18:52       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8325209461327716
[2018-06-08 13:18:53       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.7895592419400367
[2018-06-08 13:18:54       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8110673476314999
[2018-06-08 13:18:54       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8118329968859215
[2018-06-08 13:18:55       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8310807490873013
[2018-06-08 13:18:55       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8428936080937242
[2018-06-08 13:18:56       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8302761166749165
[2018-06-08 13:18:57       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8490639658105227
[2018-06-08 13:18:57       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8320422713275595
[2018-06-08 13:18:58       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.851782692836698
[2018-06-08 13:18:58       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8556239827584003
[2018-06-08 13:18:59       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8525547853359029
[2018-06-08 13:19:00       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8487350099874924
[2018-06-08 13:19:00       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.841821485262527
[2018-06-08 13:19:01       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8595664762576841
[2018-06-08 13:19:02       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8336525854428526
[2018-06-08 13:19:02       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.83226078787391
[2018-06-08 13:19:03       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8450065226346716
[2018-06-08 13:19:03       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8609855989672114
[2018-06-08 13:19:04       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8291093811068202
[2018-06-08 13:19:05       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8622810594362535
[2018-06-08 13:19:05       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.842868806426452
[2018-06-08 13:19:06       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8607794967081789
[2018-06-08 13:19:07       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8604319680377496
[2018-06-08 13:19:07       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.85916748085052
[2018-06-08 13:19:08       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8501089642054334
[2018-06-08 13:19:08       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8584019426375942
[2018-06-08 13:19:09       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8596668424234705
[2018-06-08 13:19:10       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8650886059977613
[2018-06-08 13:19:10       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8399892494563419
[2018-06-08 13:19:11       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8638194309484005
[2018-06-08 13:19:11       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8344473190408165
[2018-06-08 13:19:12       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8569007867046737
[2018-06-08 13:19:13       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8577529627160433
[2018-06-08 13:19:13       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8646212297001243
[2018-06-08 13:19:14       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8545739413289981
[2018-06-08 13:19:14       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8514559209245708
[2018-06-08 13:19:15       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8605077204155895
[2018-06-08 13:19:15       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8631408363198354
[2018-06-08 13:19:16       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8604946555686879
[2018-06-08 13:19:17       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8607882036705881
[2018-06-08 13:19:17       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8408029012342665
[2018-06-08 13:19:18       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8535476985534864
[2018-06-08 13:19:18       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.857981036724066
[2018-06-08 13:19:19       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8633839265868608
[2018-06-08 13:19:19       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8497528688852652
[2018-06-08 13:19:20       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.856350323873541
[2018-06-08 13:19:21       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.861686539600301
[2018-06-08 13:19:21       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8641103627059511
[2018-06-08 13:19:22       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8498625821626565
[2018-06-08 13:19:22       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8674692017462097
[2018-06-08 13:19:23       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8673166309189287
[2018-06-08 13:19:23       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8531230904298893
[2018-06-08 13:19:24       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.867237501496124
[2018-06-08 13:19:25       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8586289538692014
[2018-06-08 13:19:25       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8667323367623518
[2018-06-08 13:19:26       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8631622484670816
[2018-06-08 13:19:26       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8626610172148385
[2018-06-08 13:19:27       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8666678784033058
[2018-06-08 13:19:27       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8474028947894611
[2018-06-08 13:19:28       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8662766799274574
[2018-06-08 13:19:29       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8633671639722832
[2018-06-08 13:19:29       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8666515490277504
[2018-06-08 13:19:30       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8518729195742842
[2018-06-08 13:19:30       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8677487875544583
[2018-06-08 13:19:31       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8601230146252461
[2018-06-08 13:19:31       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8541246516028791
[2018-06-08 13:19:32       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8585898303333773
[2018-06-08 13:19:33       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8688816274842539
[2018-06-08 13:19:33       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8644805798418125
[2018-06-08 13:19:34       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8668236451987724
[2018-06-08 13:19:35       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8673375452329786
[2018-06-08 13:19:35       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8625740401224009
[2018-06-08 13:19:36       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8643543454399486
[2018-06-08 13:19:37       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8578364002568248
[2018-06-08 13:19:37       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8554877429097257
[2018-06-08 13:19:38       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.866770371138518
[2018-06-08 13:19:38       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8687881799783601
[2018-06-08 13:19:39       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8694567841832525
[2018-06-08 13:19:39       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8653094891478308
[2018-06-08 13:19:40       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.859334307657203
[2018-06-08 13:19:41       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.861759604025241
[2018-06-08 13:19:41       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8597068784506005
[2018-06-08 13:19:42       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8637328943901917
[2018-06-08 13:19:42       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8604475637781328
[2018-06-08 13:19:43       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8681506812880894
[2018-06-08 13:19:44       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8662082699486439
[2018-06-08 13:19:44       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.864730619076077
[2018-06-08 13:19:45       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8652436090679047
[2018-06-08 13:19:45       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:19:45       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:19:45       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:19:45       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_22.pickle"
[2018-06-08 13:19:45  start_training.py:129 -                      main()] Fidelity obtained: 0.8650893317421975
[2018-06-08 13:19:47  start_training.py:101 -                      main()] Starting training no.23
[2018-06-08 13:19:47    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:19:47    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:19:47    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:19:47    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:19:47           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:19:47           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:19:47       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:19:47       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:19:47       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:19:47       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:19:47       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:19:47       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:19:47       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:19:47       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:19:47       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:19:47       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:19:51       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:19:52       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.18397129690167766
[2018-06-08 13:19:53       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7717701780124853
[2018-06-08 13:19:54       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.836968491755412
[2018-06-08 13:19:55       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8160988038756392
[2018-06-08 13:19:55       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7636562218415548
[2018-06-08 13:19:56       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8589309612382563
[2018-06-08 13:19:57       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8270567940700712
[2018-06-08 13:19:57       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8552164849805318
[2018-06-08 13:19:58       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8547524292462984
[2018-06-08 13:19:59       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8932080477868338
[2018-06-08 13:19:59       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8927505516551948
[2018-06-08 13:20:00       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8800920418470345
[2018-06-08 13:20:01       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8636995501970227
[2018-06-08 13:20:01       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8777550601131607
[2018-06-08 13:20:02       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8932253872306819
[2018-06-08 13:20:02       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8779318161333317
[2018-06-08 13:20:03       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8886696456032753
[2018-06-08 13:20:04       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8912853214247162
[2018-06-08 13:20:04       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8831812664342596
[2018-06-08 13:20:05       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8876015639568667
[2018-06-08 13:20:06       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.865510781247307
[2018-06-08 13:20:06       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8862530334667862
[2018-06-08 13:20:07       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8993683532887908
[2018-06-08 13:20:08       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9018983746966605
[2018-06-08 13:20:08       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8994275420534624
[2018-06-08 13:20:09       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8947713170893242
[2018-06-08 13:20:10       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8904038954402828
[2018-06-08 13:20:11       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8888801382926483
[2018-06-08 13:20:12       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8979691510076995
[2018-06-08 13:20:13       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8789832392498204
[2018-06-08 13:20:14       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9019166197646635
[2018-06-08 13:20:15       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8915250501101424
[2018-06-08 13:20:15       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8961273612829352
[2018-06-08 13:20:16       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8986075334806966
[2018-06-08 13:20:17       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8859989143461868
[2018-06-08 13:20:17       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9026044174663527
[2018-06-08 13:20:18       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8998564142364255
[2018-06-08 13:20:19       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9008951369352717
[2018-06-08 13:20:19       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8947774927593616
[2018-06-08 13:20:20       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8893425713392986
[2018-06-08 13:20:20       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8900750963891265
[2018-06-08 13:20:21       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9029148800284907
[2018-06-08 13:20:22       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8985372830151944
[2018-06-08 13:20:22       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9014342706102987
[2018-06-08 13:20:23       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9005247414812391
[2018-06-08 13:20:23       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9014436229665381
[2018-06-08 13:20:24       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8981958631172102
[2018-06-08 13:20:25       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8908145987731053
[2018-06-08 13:20:25       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8987902839224624
[2018-06-08 13:20:26       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8981536477514217
[2018-06-08 13:20:27       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.898714239123465
[2018-06-08 13:20:27       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8956680228500781
[2018-06-08 13:20:28       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9005108159145425
[2018-06-08 13:20:28       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.901225373297941
[2018-06-08 13:20:29       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8991356057887274
[2018-06-08 13:20:30       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.901547593252641
[2018-06-08 13:20:30       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8988355304753805
[2018-06-08 13:20:31       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8967261211720041
[2018-06-08 13:20:32       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9016153991643745
[2018-06-08 13:20:32       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8957776208269814
[2018-06-08 13:20:33       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8996222856593431
[2018-06-08 13:20:33       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9002549851388092
[2018-06-08 13:20:34       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9000696573265597
[2018-06-08 13:20:35       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9021671263786899
[2018-06-08 13:20:35       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8988514196239603
[2018-06-08 13:20:36       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9008560842599715
[2018-06-08 13:20:36       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8987081976409942
[2018-06-08 13:20:37       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9019610082260333
[2018-06-08 13:20:37       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9021071940311909
[2018-06-08 13:20:38       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9032996877214652
[2018-06-08 13:20:39       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9002249443691602
[2018-06-08 13:20:39       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9015256143432917
[2018-06-08 13:20:40       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8989269880743349
[2018-06-08 13:20:40       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9025506951587577
[2018-06-08 13:20:41       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8954954232748648
[2018-06-08 13:20:42       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9030992284489517
[2018-06-08 13:20:42       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9032879856538514
[2018-06-08 13:20:43       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9017308783449575
[2018-06-08 13:20:44       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9021040417537621
[2018-06-08 13:20:44       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8986599131621343
[2018-06-08 13:20:45       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9035212043724118
[2018-06-08 13:20:46       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9042680399140538
[2018-06-08 13:20:47       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9017279335590169
[2018-06-08 13:20:48       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9007804237746599
[2018-06-08 13:20:48       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9002338289074686
[2018-06-08 13:20:49       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9008914134809406
[2018-06-08 13:20:50       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9014275619336779
[2018-06-08 13:20:50       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9022167742220982
[2018-06-08 13:20:51       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8997430114211035
[2018-06-08 13:20:52       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9039442763225081
[2018-06-08 13:20:52       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8998747382749638
[2018-06-08 13:20:53       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9028664722780825
[2018-06-08 13:20:54       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9023717249543144
[2018-06-08 13:20:54       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9023854026947369
[2018-06-08 13:20:55       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9019271982508031
[2018-06-08 13:20:56       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8996924442701125
[2018-06-08 13:20:56       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9038050966800981
[2018-06-08 13:20:57       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9020520447792606
[2018-06-08 13:20:58       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9026873724818648
[2018-06-08 13:20:58       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9004810860013791
[2018-06-08 13:20:58       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:20:58       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:20:58       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:20:58       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_23.pickle"
[2018-06-08 13:20:58  start_training.py:129 -                      main()] Fidelity obtained: 0.9027715927735147
[2018-06-08 13:21:00  start_training.py:101 -                      main()] Starting training no.24
[2018-06-08 13:21:00    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:21:00    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:21:00    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:21:00    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:21:00           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:21:00           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:21:00       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:21:00       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:21:00       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:21:00       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:21:00       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:21:00       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:21:00       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:21:00       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:21:00       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:21:00       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:21:03       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:21:04       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.16541689285768688
[2018-06-08 13:21:05       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5933111987192844
[2018-06-08 13:21:06       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.28227167175165424
[2018-06-08 13:21:07       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.2651143029671948
[2018-06-08 13:21:07       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7408758280396289
[2018-06-08 13:21:08       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.7266808326227813
[2018-06-08 13:21:08       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.6393667774148067
[2018-06-08 13:21:09       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.5889773173945146
[2018-06-08 13:21:09       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.43538355179260696
[2018-06-08 13:21:10       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8566397821873969
[2018-06-08 13:21:10       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.6809255102075983
[2018-06-08 13:21:11       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8135530264378491
[2018-06-08 13:21:12       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8574863100463063
[2018-06-08 13:21:12       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.6553736810864769
[2018-06-08 13:21:13       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8111367812158017
[2018-06-08 13:21:13       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.7706467892456971
[2018-06-08 13:21:14       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.7998869722855388
[2018-06-08 13:21:14       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8078860148547774
[2018-06-08 13:21:15       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.7959758268382585
[2018-06-08 13:21:16       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.7891632775551638
[2018-06-08 13:21:16       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8410456106561175
[2018-06-08 13:21:17       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8417965148471405
[2018-06-08 13:21:17       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.7788515507935879
[2018-06-08 13:21:18       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.7739590256475555
[2018-06-08 13:21:18       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8610926219772458
[2018-06-08 13:21:19       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8126469726938226
[2018-06-08 13:21:19       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8251103387258829
[2018-06-08 13:21:20       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.811995604243092
[2018-06-08 13:21:21       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8593312193556086
[2018-06-08 13:21:21       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8584414973498572
[2018-06-08 13:21:22       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8443111182905377
[2018-06-08 13:21:22       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8606342268988044
[2018-06-08 13:21:23       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8637845126475008
[2018-06-08 13:21:23       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.7727642527424237
[2018-06-08 13:21:24       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8374159444475143
[2018-06-08 13:21:24       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8143541691884818
[2018-06-08 13:21:25       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8303015955185259
[2018-06-08 13:21:26       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.85715844939723
[2018-06-08 13:21:26       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8616925404013008
[2018-06-08 13:21:27       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.845010590471231
[2018-06-08 13:21:27       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.85272984948925
[2018-06-08 13:21:28       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8615911649435192
[2018-06-08 13:21:28       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8556013947771656
[2018-06-08 13:21:29       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8597324172753509
[2018-06-08 13:21:29       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8394070954170602
[2018-06-08 13:21:30       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8485420642988037
[2018-06-08 13:21:31       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8442076298422847
[2018-06-08 13:21:31       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8626889992744257
[2018-06-08 13:21:32       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8554661406011519
[2018-06-08 13:21:32       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8540570274623879
[2018-06-08 13:21:33       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.861799801496309
[2018-06-08 13:21:33       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8529411230102003
[2018-06-08 13:21:34       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8692409103415762
[2018-06-08 13:21:34       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8494143962185681
[2018-06-08 13:21:35       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8503020363427558
[2018-06-08 13:21:36       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8585226119149554
[2018-06-08 13:21:36       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8277805217062338
[2018-06-08 13:21:37       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8254226998105563
[2018-06-08 13:21:37       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.823196764635088
[2018-06-08 13:21:38       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.843347685671249
[2018-06-08 13:21:38       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8686078283565593
[2018-06-08 13:21:39       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8695414668461724
[2018-06-08 13:21:39       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8646370017599374
[2018-06-08 13:21:40       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8676541140096573
[2018-06-08 13:21:41       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8594776597560917
[2018-06-08 13:21:41       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8646071179560435
[2018-06-08 13:21:42       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8608138438002865
[2018-06-08 13:21:42       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8667293941777282
[2018-06-08 13:21:43       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8677768016207236
[2018-06-08 13:21:43       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8547305054694463
[2018-06-08 13:21:44       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8558372702114455
[2018-06-08 13:21:44       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8598755692665653
[2018-06-08 13:21:45       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8515937087203664
[2018-06-08 13:21:46       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.846827140699808
[2018-06-08 13:21:46       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8614983141636167
[2018-06-08 13:21:47       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8619183060698405
[2018-06-08 13:21:47       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8656876053906667
[2018-06-08 13:21:48       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8651122222355727
[2018-06-08 13:21:48       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.86899583453608
[2018-06-08 13:21:49       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8632753267636452
[2018-06-08 13:21:49       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8547223883842218
[2018-06-08 13:21:50       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8616740635515177
[2018-06-08 13:21:51       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8669384467036678
[2018-06-08 13:21:51       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8509213526379427
[2018-06-08 13:21:52       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8657188694112626
[2018-06-08 13:21:52       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8665208008461033
[2018-06-08 13:21:53       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8691953252594067
[2018-06-08 13:21:53       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8664047255024322
[2018-06-08 13:21:54       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8618621928291859
[2018-06-08 13:21:54       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8524553716637512
[2018-06-08 13:21:55       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8644249278211515
[2018-06-08 13:21:56       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8473373871018083
[2018-06-08 13:21:56       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.863776247211305
[2018-06-08 13:21:57       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8648823839447747
[2018-06-08 13:21:57       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8569652267650137
[2018-06-08 13:21:58       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8597062009197414
[2018-06-08 13:21:58       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8527401795146021
[2018-06-08 13:21:59       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.85764357978576
[2018-06-08 13:21:59       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8688999028276325
[2018-06-08 13:22:00       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8690397908349907
[2018-06-08 13:22:00       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:22:00       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:22:00       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:22:00       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_24.pickle"
[2018-06-08 13:22:00  start_training.py:129 -                      main()] Fidelity obtained: 0.8680444309249458
[2018-06-08 13:22:02  start_training.py:101 -                      main()] Starting training no.25
[2018-06-08 13:22:02    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:22:02    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:22:02    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:22:02    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:22:02           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:22:02           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:22:02       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:22:02       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:22:02       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:22:02       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:22:02       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:22:02       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:22:02       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:22:02       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:22:02       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:22:02       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:22:06       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:22:07       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7352298109636444
[2018-06-08 13:22:07       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6432970328562062
[2018-06-08 13:22:08       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8881271889173555
[2018-06-08 13:22:09       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.6169952502317378
[2018-06-08 13:22:09       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7826934076070217
[2018-06-08 13:22:10       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.7736089560648357
[2018-06-08 13:22:10       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8513222313815959
[2018-06-08 13:22:11       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.7529417629531817
[2018-06-08 13:22:12       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8696944967077941
[2018-06-08 13:22:12       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8333192393202381
[2018-06-08 13:22:13       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.879895542016194
[2018-06-08 13:22:14       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8184037354071603
[2018-06-08 13:22:14       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8919468452056027
[2018-06-08 13:22:15       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8920982616557239
[2018-06-08 13:22:16       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8731555434042333
[2018-06-08 13:22:16       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8846436174370447
[2018-06-08 13:22:17       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8864612794977
[2018-06-08 13:22:17       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.89438155917761
[2018-06-08 13:22:18       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8933117814247877
[2018-06-08 13:22:19       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8880895743160846
[2018-06-08 13:22:19       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9056748749666675
[2018-06-08 13:22:20       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.899714577482142
[2018-06-08 13:22:20       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8960133073054537
[2018-06-08 13:22:21       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8926433861473345
[2018-06-08 13:22:22       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8946533157999212
[2018-06-08 13:22:22       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8975045858068645
[2018-06-08 13:22:23       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8911813080185041
[2018-06-08 13:22:23       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8932002139333339
[2018-06-08 13:22:24       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9020817810101791
[2018-06-08 13:22:25       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8847689479908227
[2018-06-08 13:22:25       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9001084925656382
[2018-06-08 13:22:26       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9044305657844496
[2018-06-08 13:22:26       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8971449663754721
[2018-06-08 13:22:27       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9029983293037499
[2018-06-08 13:22:28       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9033426383775989
[2018-06-08 13:22:28       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9032285713450966
[2018-06-08 13:22:29       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8929272942490714
[2018-06-08 13:22:29       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8988987836693583
[2018-06-08 13:22:30       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.899490661214719
[2018-06-08 13:22:31       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8997409559263047
[2018-06-08 13:22:31       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9024176875827352
[2018-06-08 13:22:32       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8933019054731572
[2018-06-08 13:22:32       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8991215867078224
[2018-06-08 13:22:33       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9006089005901159
[2018-06-08 13:22:34       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9042595819530348
[2018-06-08 13:22:34       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8997930485180775
[2018-06-08 13:22:35       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.90099721920548
[2018-06-08 13:22:35       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9044501449584503
[2018-06-08 13:22:36       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9055355484052177
[2018-06-08 13:22:36       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9065446405301115
[2018-06-08 13:22:37       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.905091545308396
[2018-06-08 13:22:38       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9056558974834803
[2018-06-08 13:22:38       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8998447035125856
[2018-06-08 13:22:39       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9033260977286777
[2018-06-08 13:22:39       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9067597948246585
[2018-06-08 13:22:40       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9020514831923961
[2018-06-08 13:22:41       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9035422477659522
[2018-06-08 13:22:41       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9012562503452068
[2018-06-08 13:22:42       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9042447738299978
[2018-06-08 13:22:42       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9020024091329927
[2018-06-08 13:22:43       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9043465369507827
[2018-06-08 13:22:44       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9076283677165787
[2018-06-08 13:22:44       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9068043181991048
[2018-06-08 13:22:45       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9023796183242613
[2018-06-08 13:22:45       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9024803568273242
[2018-06-08 13:22:46       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.903791659571721
[2018-06-08 13:22:47       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9069214332172034
[2018-06-08 13:22:47       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9055594966004334
[2018-06-08 13:22:48       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9052703300908534
[2018-06-08 13:22:49       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9037096104520909
[2018-06-08 13:22:50       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9036371726908147
[2018-06-08 13:22:51       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9060179512153823
[2018-06-08 13:22:51       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9059495531473862
[2018-06-08 13:22:52       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9054736468225655
[2018-06-08 13:22:53       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9001542254401038
[2018-06-08 13:22:53       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8994557934856295
[2018-06-08 13:22:54       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9043536197316472
[2018-06-08 13:22:54       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9045212795448282
[2018-06-08 13:22:55       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8982007258402926
[2018-06-08 13:22:56       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9050669450682203
[2018-06-08 13:22:56       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9001958142554346
[2018-06-08 13:22:57       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9011529804060191
[2018-06-08 13:22:57       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9052971678974928
[2018-06-08 13:22:58       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9056357430292056
[2018-06-08 13:22:59       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8994373443308753
[2018-06-08 13:22:59       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9042210936635642
[2018-06-08 13:23:00       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9044024264285164
[2018-06-08 13:23:00       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9040157758084151
[2018-06-08 13:23:01       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9064079386852018
[2018-06-08 13:23:02       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.902638379699807
[2018-06-08 13:23:02       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9040145375225991
[2018-06-08 13:23:03       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9060638335143762
[2018-06-08 13:23:03       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9044700009536208
[2018-06-08 13:23:04       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9043654420132492
[2018-06-08 13:23:04       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9077518771398921
[2018-06-08 13:23:05       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9000204658314519
[2018-06-08 13:23:06       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9021768660339506
[2018-06-08 13:23:06       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9003932070125197
[2018-06-08 13:23:07       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9052422176485055
[2018-06-08 13:23:07       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9065748851282889
[2018-06-08 13:23:07       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:23:07       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:23:07       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:23:07       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_25.pickle"
[2018-06-08 13:23:08  start_training.py:129 -                      main()] Fidelity obtained: 0.905271906734806
[2018-06-08 13:23:09  start_training.py:101 -                      main()] Starting training no.26
[2018-06-08 13:23:09    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:23:09    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:23:09    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:23:09    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:23:09           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:23:09           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:23:09       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:23:09       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:23:09       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:23:09       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:23:09       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:23:09       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:23:09       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:23:10       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:23:10       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:23:10       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:23:13       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:23:14       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.44010043752471184
[2018-06-08 13:23:15       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.130551194016272
[2018-06-08 13:23:16       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.5220401154934095
[2018-06-08 13:23:17       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.857656429029711
[2018-06-08 13:23:18       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9979675428152127
[2018-06-08 13:23:18       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9974985175101259
[2018-06-08 13:23:19       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9996881101510602
[2018-06-08 13:23:20       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999803637727834
[2018-06-08 13:23:21       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.999983443437841
[2018-06-08 13:23:22       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999732453396781
[2018-06-08 13:23:23       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999861121184133
[2018-06-08 13:23:24       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.999984597861472
[2018-06-08 13:23:25       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999890631279454
[2018-06-08 13:23:26       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999868047526356
[2018-06-08 13:23:26       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999883780032115
[2018-06-08 13:23:27       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.999986305511537
[2018-06-08 13:23:28       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.999988335475885
[2018-06-08 13:23:29       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999913671952168
[2018-06-08 13:23:30       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999886706918576
[2018-06-08 13:23:31       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999903107047152
[2018-06-08 13:23:32       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999901250498335
[2018-06-08 13:23:33       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.999990671272788
[2018-06-08 13:23:34       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999919683892654
[2018-06-08 13:23:35       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999919133505791
[2018-06-08 13:23:35       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999927303156553
[2018-06-08 13:23:36       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999928942010453
[2018-06-08 13:23:36       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999916903704534
[2018-06-08 13:23:37       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999924631932554
[2018-06-08 13:23:38       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.999993355179154
[2018-06-08 13:23:38       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999933533823543
[2018-06-08 13:23:40       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999931518753594
[2018-06-08 13:23:41       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999934823250957
[2018-06-08 13:23:41       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999938863980076
[2018-06-08 13:23:42       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.999993991383809
[2018-06-08 13:23:43       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999941844018145
[2018-06-08 13:23:44       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999939586885149
[2018-06-08 13:23:44       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999940201074307
[2018-06-08 13:23:45       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999942205919419
[2018-06-08 13:23:46       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999944959211611
[2018-06-08 13:23:46       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999940767395882
[2018-06-08 13:23:47       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999944576802848
[2018-06-08 13:23:47       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999948617304315
[2018-06-08 13:23:48       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.999994661581942
[2018-06-08 13:23:49       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999940403809628
[2018-06-08 13:23:49       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999948775354158
[2018-06-08 13:23:50       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999950104668003
[2018-06-08 13:23:51       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999952075101288
[2018-06-08 13:23:51       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999947406047803
[2018-06-08 13:23:52       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999952009142588
[2018-06-08 13:23:52       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999953311096499
[2018-06-08 13:23:53       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999954559242379
[2018-06-08 13:23:54       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999952966240943
[2018-06-08 13:23:54       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.999995203958153
[2018-06-08 13:23:55       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.999995428610246
[2018-06-08 13:23:56       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999955228351333
[2018-06-08 13:23:57       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.999995483928176
[2018-06-08 13:23:57       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.999995678782267
[2018-06-08 13:23:58       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999955731716307
[2018-06-08 13:23:59       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999954563366196
[2018-06-08 13:23:59       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999957685889407
[2018-06-08 13:24:00       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999955161175653
[2018-06-08 13:24:01       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999958113186971
[2018-06-08 13:24:01       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999959294102507
[2018-06-08 13:24:02       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999950663185568
[2018-06-08 13:24:03       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999959699619869
[2018-06-08 13:24:03       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999959593801693
[2018-06-08 13:24:04       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999956071190553
[2018-06-08 13:24:04       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999961050858401
[2018-06-08 13:24:05       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999960153617536
[2018-06-08 13:24:06       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.999996126424858
[2018-06-08 13:24:06       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999958147162598
[2018-06-08 13:24:07       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999961827013399
[2018-06-08 13:24:08       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999962631108313
[2018-06-08 13:24:08       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999959443838128
[2018-06-08 13:24:09       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999962740495107
[2018-06-08 13:24:10       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999962795354983
[2018-06-08 13:24:11       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999962780655552
[2018-06-08 13:24:12       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999962835233555
[2018-06-08 13:24:12       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999963519436172
[2018-06-08 13:24:13       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.999996455280293
[2018-06-08 13:24:14       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999964639630272
[2018-06-08 13:24:14       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999961753311782
[2018-06-08 13:24:15       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999963989225452
[2018-06-08 13:24:16       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999964160649939
[2018-06-08 13:24:16       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999964992401027
[2018-06-08 13:24:17       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999965502568504
[2018-06-08 13:24:18       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999964782709964
[2018-06-08 13:24:18       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999966259984473
[2018-06-08 13:24:19       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999964197629245
[2018-06-08 13:24:20       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999966736754381
[2018-06-08 13:24:20       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999965460421112
[2018-06-08 13:24:21       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999966580316507
[2018-06-08 13:24:22       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.999996196581094
[2018-06-08 13:24:22       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999967073346658
[2018-06-08 13:24:23       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999966005350045
[2018-06-08 13:24:24       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999967362722478
[2018-06-08 13:24:24       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999967191332664
[2018-06-08 13:24:25       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999967202645383
[2018-06-08 13:24:26       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999968579971927
[2018-06-08 13:24:26       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999968283003144
[2018-06-08 13:24:26       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:24:26       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:24:26       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:24:26       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_26.pickle"
[2018-06-08 13:24:26  start_training.py:129 -                      main()] Fidelity obtained: 0.9999970300462309
[2018-06-08 13:24:28  start_training.py:101 -                      main()] Starting training no.27
[2018-06-08 13:24:28    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:24:28    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:24:28    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:24:28    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:24:28           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:24:28           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:24:28       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:24:28       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:24:28       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:24:28       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:24:28       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:24:28       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:24:28       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:24:28       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:24:28       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:24:29       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:24:31       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:24:32       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5838678686969826
[2018-06-08 13:24:33       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6491466318832019
[2018-06-08 13:24:33       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9171990761831438
[2018-06-08 13:24:34       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9432256698052021
[2018-06-08 13:24:34       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.983792211971845
[2018-06-08 13:24:35       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.957221267703234
[2018-06-08 13:24:36       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9603819645386931
[2018-06-08 13:24:36       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9846427320133302
[2018-06-08 13:24:37       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9918577670960531
[2018-06-08 13:24:38       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9853962859788303
[2018-06-08 13:24:38       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9818645117622965
[2018-06-08 13:24:39       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9865485143969608
[2018-06-08 13:24:40       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9917964430482853
[2018-06-08 13:24:40       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9773649391578254
[2018-06-08 13:24:41       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9924074513876413
[2018-06-08 13:24:41       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9895780966514888
[2018-06-08 13:24:42       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9906271544717565
[2018-06-08 13:24:43       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.991551682938455
[2018-06-08 13:24:43       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9921309982992035
[2018-06-08 13:24:44       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9910659422788061
[2018-06-08 13:24:45       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9914859440105888
[2018-06-08 13:24:45       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9920206019216099
[2018-06-08 13:24:46       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9910601619122614
[2018-06-08 13:24:46       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.989920298118135
[2018-06-08 13:24:47       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9907163946098446
[2018-06-08 13:24:48       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.992926569441016
[2018-06-08 13:24:48       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9914896433740056
[2018-06-08 13:24:49       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9929554400890008
[2018-06-08 13:24:50       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9928661069950637
[2018-06-08 13:24:50       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9928667350248424
[2018-06-08 13:24:51       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9931453239513504
[2018-06-08 13:24:52       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9932714615142824
[2018-06-08 13:24:52       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9912637800102071
[2018-06-08 13:24:53       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9929333094834024
[2018-06-08 13:24:54       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9893766202601836
[2018-06-08 13:24:54       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9931406759449233
[2018-06-08 13:24:55       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9929322070173424
[2018-06-08 13:24:55       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9909892329804424
[2018-06-08 13:24:56       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9926076622380919
[2018-06-08 13:24:57       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9926457538896458
[2018-06-08 13:24:57       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9919438085698417
[2018-06-08 13:24:58       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9919118087401467
[2018-06-08 13:24:59       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9929916077716505
[2018-06-08 13:24:59       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9931903290549673
[2018-06-08 13:25:00       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9929280706326735
[2018-06-08 13:25:00       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9932565931453908
[2018-06-08 13:25:01       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9931349691824539
[2018-06-08 13:25:02       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9933807750884968
[2018-06-08 13:25:03       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9934671090817108
[2018-06-08 13:25:03       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9924841106485475
[2018-06-08 13:25:04       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9932592327887374
[2018-06-08 13:25:05       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9930262602502462
[2018-06-08 13:25:05       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9935809273555063
[2018-06-08 13:25:06       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9934065052890856
[2018-06-08 13:25:07       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.993432572285993
[2018-06-08 13:25:07       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9933415396041209
[2018-06-08 13:25:08       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9927698715999584
[2018-06-08 13:25:09       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9931234306361365
[2018-06-08 13:25:09       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9934045387340552
[2018-06-08 13:25:10       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9923956952029905
[2018-06-08 13:25:11       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.993193757564264
[2018-06-08 13:25:12       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9923511385075804
[2018-06-08 13:25:12       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9932649347684129
[2018-06-08 13:25:13       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9933262629185734
[2018-06-08 13:25:14       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9923188403883267
[2018-06-08 13:25:15       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9932696949136841
[2018-06-08 13:25:15       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9933339580066095
[2018-06-08 13:25:16       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9930702108603663
[2018-06-08 13:25:17       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9935794579271082
[2018-06-08 13:25:17       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9933391421498935
[2018-06-08 13:25:18       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9931091604907804
[2018-06-08 13:25:19       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9936969536186825
[2018-06-08 13:25:19       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9928430912343542
[2018-06-08 13:25:20       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9927187302474294
[2018-06-08 13:25:20       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9930169259079022
[2018-06-08 13:25:21       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9931960431066691
[2018-06-08 13:25:22       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9935747318246473
[2018-06-08 13:25:22       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9932368548158746
[2018-06-08 13:25:23       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9924183053797186
[2018-06-08 13:25:24       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9934933376075641
[2018-06-08 13:25:25       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9929651639108629
[2018-06-08 13:25:26       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9927171153508128
[2018-06-08 13:25:27       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9930320096588158
[2018-06-08 13:25:27       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9930879540108595
[2018-06-08 13:25:28       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9929850768482561
[2018-06-08 13:25:29       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9930918691486099
[2018-06-08 13:25:30       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9936860748380029
[2018-06-08 13:25:31       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9929280611426574
[2018-06-08 13:25:32       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9929358954572247
[2018-06-08 13:25:32       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9926539049210862
[2018-06-08 13:25:33       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9925249431385723
[2018-06-08 13:25:34       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.993403313470273
[2018-06-08 13:25:35       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9930866312511274
[2018-06-08 13:25:35       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9930305933639529
[2018-06-08 13:25:36       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9935779611654668
[2018-06-08 13:25:37       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9933716704865909
[2018-06-08 13:25:37       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9926007350683399
[2018-06-08 13:25:38       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9931899889241244
[2018-06-08 13:25:38       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9936727046273919
[2018-06-08 13:25:39       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9925038615766664
[2018-06-08 13:25:39       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:25:39       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:25:39       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:25:39       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_27.pickle"
[2018-06-08 13:25:39  start_training.py:129 -                      main()] Fidelity obtained: 0.9926760553170828
[2018-06-08 13:25:41  start_training.py:101 -                      main()] Starting training no.28
[2018-06-08 13:25:41    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:25:41    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:25:41    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:25:41    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:25:41           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:25:41           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:25:41       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:25:41       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:25:41       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:25:41       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:25:41       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:25:41       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:25:41       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:25:42       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:25:42       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:25:42       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:25:45       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:25:46       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6224888211864696
[2018-06-08 13:25:46       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.609943769419338
[2018-06-08 13:25:47       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.4456952741236044
[2018-06-08 13:25:48       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7615288679201794
[2018-06-08 13:25:48       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.746204006083532
[2018-06-08 13:25:49       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.7340234643148843
[2018-06-08 13:25:49       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7498217128959955
[2018-06-08 13:25:50       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8349921473532308
[2018-06-08 13:25:51       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8272997071399059
[2018-06-08 13:25:51       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9466522399134373
[2018-06-08 13:25:52       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8323341620076523
[2018-06-08 13:25:53       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.927348076140025
[2018-06-08 13:25:53       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9254483457601299
[2018-06-08 13:25:54       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9389394233784558
[2018-06-08 13:25:55       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9186318606148413
[2018-06-08 13:25:55       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9438172854296509
[2018-06-08 13:25:56       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9505822706298045
[2018-06-08 13:25:56       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9369857834031514
[2018-06-08 13:25:57       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9406844111891044
[2018-06-08 13:25:58       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9506278336033263
[2018-06-08 13:25:58       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9407180832398012
[2018-06-08 13:25:59       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9411476331037363
[2018-06-08 13:26:00       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9463899291373457
[2018-06-08 13:26:00       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9500422680952052
[2018-06-08 13:26:01       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9518941331425055
[2018-06-08 13:26:01       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.944885314229101
[2018-06-08 13:26:02       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9442792907856713
[2018-06-08 13:26:03       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9493366871810691
[2018-06-08 13:26:03       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9464347152220459
[2018-06-08 13:26:04       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9424229640181371
[2018-06-08 13:26:04       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9336560392912503
[2018-06-08 13:26:05       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9479066796606946
[2018-06-08 13:26:06       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9509443054566334
[2018-06-08 13:26:06       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9484119842090835
[2018-06-08 13:26:07       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9487156208872948
[2018-06-08 13:26:08       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.951078349390216
[2018-06-08 13:26:08       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9521530153062955
[2018-06-08 13:26:09       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9532983854356886
[2018-06-08 13:26:09       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.952262681861088
[2018-06-08 13:26:10       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9478318396290797
[2018-06-08 13:26:11       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9467065618518667
[2018-06-08 13:26:11       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9508969695543993
[2018-06-08 13:26:12       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9384386511412763
[2018-06-08 13:26:12       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9420967421846801
[2018-06-08 13:26:13       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9455804791885124
[2018-06-08 13:26:14       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9484336013628372
[2018-06-08 13:26:14       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9447003957438568
[2018-06-08 13:26:15       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9506545839145456
[2018-06-08 13:26:16       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9416991660656165
[2018-06-08 13:26:16       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.94350235425786
[2018-06-08 13:26:17       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9502168827431955
[2018-06-08 13:26:17       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9518185905844888
[2018-06-08 13:26:18       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9505639340089957
[2018-06-08 13:26:19       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9543661214472777
[2018-06-08 13:26:19       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.947975939165091
[2018-06-08 13:26:20       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9454060887843495
[2018-06-08 13:26:20       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9534589985443317
[2018-06-08 13:26:21       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9521003815290864
[2018-06-08 13:26:22       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9554815615460938
[2018-06-08 13:26:22       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9504412220949553
[2018-06-08 13:26:23       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9432409219207303
[2018-06-08 13:26:24       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9529923012880857
[2018-06-08 13:26:24       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9536084249714836
[2018-06-08 13:26:25       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9482378635277775
[2018-06-08 13:26:25       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9386876514471993
[2018-06-08 13:26:26       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9537536674880353
[2018-06-08 13:26:27       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9512513273704144
[2018-06-08 13:26:27       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9521076193088007
[2018-06-08 13:26:28       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9533137933148599
[2018-06-08 13:26:28       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9528302205463242
[2018-06-08 13:26:29       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9471952425584007
[2018-06-08 13:26:30       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9547290643364542
[2018-06-08 13:26:30       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9450198208617694
[2018-06-08 13:26:31       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9506239472835014
[2018-06-08 13:26:32       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9523388658578904
[2018-06-08 13:26:32       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9548674771630772
[2018-06-08 13:26:33       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9519212996815366
[2018-06-08 13:26:34       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9530771949924987
[2018-06-08 13:26:34       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9532227152570091
[2018-06-08 13:26:35       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9541715502322526
[2018-06-08 13:26:36       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9540379113645453
[2018-06-08 13:26:36       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9529450658111073
[2018-06-08 13:26:37       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.953457552215415
[2018-06-08 13:26:38       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9539987212384899
[2018-06-08 13:26:38       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9533121114307883
[2018-06-08 13:26:39       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9533737399106311
[2018-06-08 13:26:40       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9552305450104478
[2018-06-08 13:26:40       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9536407387828101
[2018-06-08 13:26:41       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9515937416099685
[2018-06-08 13:26:42       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9546573780532925
[2018-06-08 13:26:43       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9491798343347242
[2018-06-08 13:26:43       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9533877003972439
[2018-06-08 13:26:44       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9543302990495478
[2018-06-08 13:26:44       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9544681492712007
[2018-06-08 13:26:45       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.952934554635936
[2018-06-08 13:26:46       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9549956273486724
[2018-06-08 13:26:47       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9549657734007679
[2018-06-08 13:26:48       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9496294380850132
[2018-06-08 13:26:48       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9523333113304573
[2018-06-08 13:26:49       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9521407535207583
[2018-06-08 13:26:49       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:26:49       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:26:49       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:26:49       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_28.pickle"
[2018-06-08 13:26:49  start_training.py:129 -                      main()] Fidelity obtained: 0.9492406876873082
[2018-06-08 13:26:52  start_training.py:101 -                      main()] Starting training no.29
[2018-06-08 13:26:52    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:26:52    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:26:52    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:26:52    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:26:52           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:26:52           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:26:52       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:26:52       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:26:52       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:26:52       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:26:52       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:26:52       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:26:52       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:26:52       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:26:52       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:26:52       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:26:56       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:26:57       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8082236434705878
[2018-06-08 13:26:58       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8962485675055126
[2018-06-08 13:26:59       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9998321267470587
[2018-06-08 13:26:59       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999971311449722
[2018-06-08 13:27:00       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.999999999981096
[2018-06-08 13:27:00       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0
[2018-06-08 13:27:00       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:27:00       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:27:00       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:27:00       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:27:00       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_29.pickle"
[2018-06-08 13:27:01  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:27:03  start_training.py:101 -                      main()] Starting training no.30
[2018-06-08 13:27:03    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:27:03    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:27:03    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:27:03    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:27:03           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:27:03           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:27:03       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:27:03       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:27:03       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:27:03       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:27:03       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:27:03       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:27:03       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:27:03       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:27:03       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:27:03       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:27:06       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:27:07       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6505797462222032
[2018-06-08 13:27:08       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6937240804076903
[2018-06-08 13:27:08       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6439353930017491
[2018-06-08 13:27:09       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9529721995384871
[2018-06-08 13:27:10       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9824041036358467
[2018-06-08 13:27:10       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9997570458833728
[2018-06-08 13:27:11       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9187890882992065
[2018-06-08 13:27:12       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9998860201826738
[2018-06-08 13:27:13       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999008725550391
[2018-06-08 13:27:13       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9998322184578541
[2018-06-08 13:27:14       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999564981990277
[2018-06-08 13:27:15       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999694695601095
[2018-06-08 13:27:15       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999681252986053
[2018-06-08 13:27:16       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999801570019494
[2018-06-08 13:27:17       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999815566792644
[2018-06-08 13:27:17       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999890827730841
[2018-06-08 13:27:18       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999923216868498
[2018-06-08 13:27:19       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.999993633254588
[2018-06-08 13:27:19       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999949634873627
[2018-06-08 13:27:20       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999951751188345
[2018-06-08 13:27:21       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999967247227595
[2018-06-08 13:27:21       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999974799116345
[2018-06-08 13:27:22       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999975955654756
[2018-06-08 13:27:22       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999980685604742
[2018-06-08 13:27:23       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999986041757433
[2018-06-08 13:27:24       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.999998654822076
[2018-06-08 13:27:24       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999988104606851
[2018-06-08 13:27:25       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999991269611871
[2018-06-08 13:27:26       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999993218957244
[2018-06-08 13:27:26       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999993190829383
[2018-06-08 13:27:27       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999995098261949
[2018-06-08 13:27:27       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999995360480969
[2018-06-08 13:27:28       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999996294251052
[2018-06-08 13:27:29       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999996657160866
[2018-06-08 13:27:29       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999997244033402
[2018-06-08 13:27:30       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.999999762488741
[2018-06-08 13:27:30       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999997999681802
[2018-06-08 13:27:31       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999998164153208
[2018-06-08 13:27:32       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999998489222913
[2018-06-08 13:27:32       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999998652748654
[2018-06-08 13:27:33       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999998804335796
[2018-06-08 13:27:34       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999998971096186
[2018-06-08 13:27:34       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999082575977
[2018-06-08 13:27:35       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999999204063947
[2018-06-08 13:27:35       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999999266573996
[2018-06-08 13:27:36       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999372005668
[2018-06-08 13:27:37       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999425706669
[2018-06-08 13:27:37       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999999500157638
[2018-06-08 13:27:38       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999999544544691
[2018-06-08 13:27:38       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.99999995956703
[2018-06-08 13:27:39       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.999999963531085
[2018-06-08 13:27:40       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999999642400484
[2018-06-08 13:27:40       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999999691888077
[2018-06-08 13:27:41       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999999727748056
[2018-06-08 13:27:42       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999999754609661
[2018-06-08 13:27:42       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999999781482876
[2018-06-08 13:27:43       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999806549584
[2018-06-08 13:27:43       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999999818745099
[2018-06-08 13:27:44       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999999840489179
[2018-06-08 13:27:45       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999999845160176
[2018-06-08 13:27:45       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.999999986804261
[2018-06-08 13:27:46       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999999880600686
[2018-06-08 13:27:47       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999999886738058
[2018-06-08 13:27:47       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999999894799783
[2018-06-08 13:27:48       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999999906820611
[2018-06-08 13:27:49       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999999917110896
[2018-06-08 13:27:49       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999999922393829
[2018-06-08 13:27:50       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999999927120234
[2018-06-08 13:27:51       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.999999993129307
[2018-06-08 13:27:51       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999999938623122
[2018-06-08 13:27:52       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999999942638741
[2018-06-08 13:27:53       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999999949170593
[2018-06-08 13:27:53       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999999952916957
[2018-06-08 13:27:54       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999999955093435
[2018-06-08 13:27:54       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999999959639877
[2018-06-08 13:27:55       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999999962394032
[2018-06-08 13:27:56       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999999964315918
[2018-06-08 13:27:56       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999999967434741
[2018-06-08 13:27:57       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999999970150109
[2018-06-08 13:27:58       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999999970966286
[2018-06-08 13:27:58       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999999973950482
[2018-06-08 13:27:59       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999999974928493
[2018-06-08 13:28:00       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.999999997719444
[2018-06-08 13:28:00       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999999978753225
[2018-06-08 13:28:01       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999999980070973
[2018-06-08 13:28:02       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999999981028606
[2018-06-08 13:28:02       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999999982609541
[2018-06-08 13:28:03       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.999999998366005
[2018-06-08 13:28:04       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999999984639888
[2018-06-08 13:28:04       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999999985667947
[2018-06-08 13:28:05       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999999986539979
[2018-06-08 13:28:06       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999999987152707
[2018-06-08 13:28:06       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999999988267764
[2018-06-08 13:28:07       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999999988407793
[2018-06-08 13:28:07       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999999989578566
[2018-06-08 13:28:08       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999999990101461
[2018-06-08 13:28:09       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999999990746659
[2018-06-08 13:28:09       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999999990995764
[2018-06-08 13:28:10       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999999991853039
[2018-06-08 13:28:11       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.999999999222824
[2018-06-08 13:28:11       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:28:11       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:28:11       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:28:11       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_30.pickle"
[2018-06-08 13:28:11  start_training.py:129 -                      main()] Fidelity obtained: 0.9999999991653377
[2018-06-08 13:28:13  start_training.py:101 -                      main()] Starting training no.31
[2018-06-08 13:28:13    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:28:13    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:28:13    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:28:13    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:28:13           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:28:13           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:28:13       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:28:13       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:28:13       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:28:13       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:28:13       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:28:13       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:28:13       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:28:13       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:28:13       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:28:13       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:28:16       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:28:17       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9444189322436738
[2018-06-08 13:28:18       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.541918575749006
[2018-06-08 13:28:19       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9055506375855146
[2018-06-08 13:28:19       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8613541471498739
[2018-06-08 13:28:20       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999509438271659
[2018-06-08 13:28:21       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999297687332
[2018-06-08 13:28:21       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999999945242
[2018-06-08 13:28:22       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999999605
[2018-06-08 13:28:23       Optimizer.py:490 -                      _run()]   Epoch no. 8: 1.0
[2018-06-08 13:28:23       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:28:23       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:28:23       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:28:23       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:28:23       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_31.pickle"
[2018-06-08 13:28:23  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:28:25  start_training.py:101 -                      main()] Starting training no.32
[2018-06-08 13:28:25    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:28:25    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:28:25    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:28:25    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:28:25           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:28:25           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:28:25       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:28:25       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:28:25       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:28:25       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:28:25       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:28:25       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:28:25       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:28:25       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:28:25       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:28:25       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:28:29       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:28:30       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6724087511768634
[2018-06-08 13:28:31       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.799955036810073
[2018-06-08 13:28:31       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9051202916835639
[2018-06-08 13:28:32       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.927710505461512
[2018-06-08 13:28:33       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8640897597939441
[2018-06-08 13:28:33       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.997280970811588
[2018-06-08 13:28:34       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9996191404620108
[2018-06-08 13:28:35       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9998537802857053
[2018-06-08 13:28:35       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999647127608986
[2018-06-08 13:28:36       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999910401081294
[2018-06-08 13:28:37       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.999995165760385
[2018-06-08 13:28:37       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999987583638815
[2018-06-08 13:28:38       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999997058321212
[2018-06-08 13:28:39       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999998783116933
[2018-06-08 13:28:39       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999732630811
[2018-06-08 13:28:40       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.999999985890856
[2018-06-08 13:28:41       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999947277594
[2018-06-08 13:28:41       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999979981056
[2018-06-08 13:28:42       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999989771615
[2018-06-08 13:28:43       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999996565235
[2018-06-08 13:28:43       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999997968361
[2018-06-08 13:28:44       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999999263776
[2018-06-08 13:28:44       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.999999999962246
[2018-06-08 13:28:45       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999999851411
[2018-06-08 13:28:46       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999999999916359
[2018-06-08 13:28:47       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999999999959513
[2018-06-08 13:28:47       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999999980943
[2018-06-08 13:28:48       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999999988094
[2018-06-08 13:28:49       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999999992962
[2018-06-08 13:28:49       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.999999999999686
[2018-06-08 13:28:50       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.999999999999835
[2018-06-08 13:28:51       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999999999071
[2018-06-08 13:28:51       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999999999999409
[2018-06-08 13:28:52       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999999999667
[2018-06-08 13:28:53       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999999999999813
[2018-06-08 13:28:54       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999999999885
[2018-06-08 13:28:54       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999999999929
[2018-06-08 13:28:55       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999999999999969
[2018-06-08 13:28:56       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999999999999984
[2018-06-08 13:28:56       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999999999994
[2018-06-08 13:28:57       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999999999999997
[2018-06-08 13:28:58       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999999999999999
[2018-06-08 13:28:59       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999999999999
[2018-06-08 13:28:59       Optimizer.py:490 -                      _run()]   Epoch no. 43: 1.0
[2018-06-08 13:28:59       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:28:59       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:28:59       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:28:59       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:28:59       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_32.pickle"
[2018-06-08 13:28:59  start_training.py:129 -                      main()] Fidelity obtained: 1.0000000000000002
[2018-06-08 13:29:02  start_training.py:101 -                      main()] Starting training no.33
[2018-06-08 13:29:02    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:29:02    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:29:02    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:29:02    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:29:02           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:29:02           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:29:02       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:29:02       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:29:02       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:29:02       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:29:02       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:29:02       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:29:02       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:29:02       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:29:02       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:29:02       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:29:06       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:29:07       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8192947762087911
[2018-06-08 13:29:08       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9126739718004852
[2018-06-08 13:29:08       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7991404825151376
[2018-06-08 13:29:09       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9367572949079226
[2018-06-08 13:29:10       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.910084233487874
[2018-06-08 13:29:11       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9785157060570794
[2018-06-08 13:29:11       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9716686288687063
[2018-06-08 13:29:12       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9766466608932525
[2018-06-08 13:29:13       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9802647828820703
[2018-06-08 13:29:13       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9072670552452271
[2018-06-08 13:29:14       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9649180295409117
[2018-06-08 13:29:15       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9687816568326345
[2018-06-08 13:29:15       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9709132862048567
[2018-06-08 13:29:16       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9735263117542908
[2018-06-08 13:29:17       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9652153285273418
[2018-06-08 13:29:17       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.976345425642015
[2018-06-08 13:29:18       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9742262845582692
[2018-06-08 13:29:19       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9760311117727373
[2018-06-08 13:29:19       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9757237299789291
[2018-06-08 13:29:20       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9788581654302778
[2018-06-08 13:29:21       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9788031008065371
[2018-06-08 13:29:21       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9809490659456253
[2018-06-08 13:29:22       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9734860862690425
[2018-06-08 13:29:23       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9755715750511424
[2018-06-08 13:29:23       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9794327668799859
[2018-06-08 13:29:24       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9799644611692641
[2018-06-08 13:29:24       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9825638318387091
[2018-06-08 13:29:25       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9821820888492977
[2018-06-08 13:29:26       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9833832293647837
[2018-06-08 13:29:27       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9807608898579636
[2018-06-08 13:29:27       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9774214042635162
[2018-06-08 13:29:28       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9807916801658653
[2018-06-08 13:29:29       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9798909396361664
[2018-06-08 13:29:30       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9828468088425995
[2018-06-08 13:29:31       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9824763235894263
[2018-06-08 13:29:31       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9769050572702933
[2018-06-08 13:29:32       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.981607435273263
[2018-06-08 13:29:33       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9810315922199945
[2018-06-08 13:29:33       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9791758119589451
[2018-06-08 13:29:34       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9828161177825798
[2018-06-08 13:29:34       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.980071050312091
[2018-06-08 13:29:35       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.981649869200787
[2018-06-08 13:29:36       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9817147905456425
[2018-06-08 13:29:36       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9816288979988685
[2018-06-08 13:29:37       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9820000335124665
[2018-06-08 13:29:38       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9801910820784666
[2018-06-08 13:29:38       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9813743017892139
[2018-06-08 13:29:39       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9774023697317022
[2018-06-08 13:29:40       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.983541475359123
[2018-06-08 13:29:40       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9819476491301063
[2018-06-08 13:29:41       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9812922632912773
[2018-06-08 13:29:41       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9816986216358191
[2018-06-08 13:29:42       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9831527934380366
[2018-06-08 13:29:43       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9831466981717638
[2018-06-08 13:29:43       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9829476007610893
[2018-06-08 13:29:44       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9800411156414033
[2018-06-08 13:29:45       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9811429892405613
[2018-06-08 13:29:45       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9813132122306495
[2018-06-08 13:29:46       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.982501517417236
[2018-06-08 13:29:47       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9822105973247406
[2018-06-08 13:29:47       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9832893880595883
[2018-06-08 13:29:48       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.982988720192858
[2018-06-08 13:29:49       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9830626128739988
[2018-06-08 13:29:49       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9817789279888993
[2018-06-08 13:29:50       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9833028677046387
[2018-06-08 13:29:50       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9828429812649846
[2018-06-08 13:29:51       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.983115514395533
[2018-06-08 13:29:52       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9829196951979549
[2018-06-08 13:29:52       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.983211174886141
[2018-06-08 13:29:53       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9830762673481422
[2018-06-08 13:29:54       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9822798010868753
[2018-06-08 13:29:54       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9827508040531314
[2018-06-08 13:29:55       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9827653032385102
[2018-06-08 13:29:55       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9829088264255716
[2018-06-08 13:29:56       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.98259821400068
[2018-06-08 13:29:57       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9825024996033023
[2018-06-08 13:29:57       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9828264669104785
[2018-06-08 13:29:58       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9824169240062202
[2018-06-08 13:29:59       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9833054950548424
[2018-06-08 13:29:59       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9818306448289725
[2018-06-08 13:30:00       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.983144729662463
[2018-06-08 13:30:00       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9831806624040712
[2018-06-08 13:30:01       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9821286269712439
[2018-06-08 13:30:02       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9826317802963374
[2018-06-08 13:30:02       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9830158707184231
[2018-06-08 13:30:03       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9818255932751847
[2018-06-08 13:30:04       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9825740054864623
[2018-06-08 13:30:05       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9834500335111329
[2018-06-08 13:30:05       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9831385049813064
[2018-06-08 13:30:06       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9828370214041469
[2018-06-08 13:30:07       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9820156130975655
[2018-06-08 13:30:07       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9831945007121159
[2018-06-08 13:30:08       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9830972498831373
[2018-06-08 13:30:09       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9826563886850357
[2018-06-08 13:30:09       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9825893722786389
[2018-06-08 13:30:10       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9829364995059501
[2018-06-08 13:30:11       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.982971389985447
[2018-06-08 13:30:12       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9828945102464653
[2018-06-08 13:30:12       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.982323091866284
[2018-06-08 13:30:13       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9825130366705457
[2018-06-08 13:30:13       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:30:13       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:30:13       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:30:13       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_33.pickle"
[2018-06-08 13:30:13  start_training.py:129 -                      main()] Fidelity obtained: 0.9826991980303905
[2018-06-08 13:30:15  start_training.py:101 -                      main()] Starting training no.34
[2018-06-08 13:30:15    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:30:15    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:30:15    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:30:15    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:30:15           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:30:15           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:30:15       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:30:15       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:30:15       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:30:15       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:30:15       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:30:15       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:30:15       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:30:15       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:30:15       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:30:15       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:30:19       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:30:20       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9521049471902192
[2018-06-08 13:30:21       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9725895180113662
[2018-06-08 13:30:22       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6731201206266355
[2018-06-08 13:30:23       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9408645783569386
[2018-06-08 13:30:23       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9513834540426663
[2018-06-08 13:30:24       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9982907439728165
[2018-06-08 13:30:25       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9774941171243006
[2018-06-08 13:30:25       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9992181794364547
[2018-06-08 13:30:26       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9926428993445836
[2018-06-08 13:30:27       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9991780180557537
[2018-06-08 13:30:28       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9990982149835955
[2018-06-08 13:30:28       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.999217164888202
[2018-06-08 13:30:29       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9990167969764854
[2018-06-08 13:30:30       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.999257088172014
[2018-06-08 13:30:30       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9987185231082332
[2018-06-08 13:30:31       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.999076732060224
[2018-06-08 13:30:32       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9988874277271903
[2018-06-08 13:30:32       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9992743608637129
[2018-06-08 13:30:33       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9993818892205601
[2018-06-08 13:30:34       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9992235372129133
[2018-06-08 13:30:34       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9991940090451054
[2018-06-08 13:30:35       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9992873579685696
[2018-06-08 13:30:36       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9993527847110802
[2018-06-08 13:30:36       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.999354766711086
[2018-06-08 13:30:37       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.999304821952299
[2018-06-08 13:30:38       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9993436456168614
[2018-06-08 13:30:38       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9993478789480043
[2018-06-08 13:30:39       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9994259275510315
[2018-06-08 13:30:40       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9993487644858208
[2018-06-08 13:30:41       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9992603215934335
[2018-06-08 13:30:41       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9993695719135003
[2018-06-08 13:30:42       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9993171050532136
[2018-06-08 13:30:43       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9993429095431895
[2018-06-08 13:30:43       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9993473427035907
[2018-06-08 13:30:44       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9994009274439098
[2018-06-08 13:30:45       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9992447200773457
[2018-06-08 13:30:46       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9994256259801199
[2018-06-08 13:30:46       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.999378747652607
[2018-06-08 13:30:47       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9994221138306167
[2018-06-08 13:30:48       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9992679335388881
[2018-06-08 13:30:49       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.999386135093353
[2018-06-08 13:30:49       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9994010763592074
[2018-06-08 13:30:50       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9994392564251368
[2018-06-08 13:30:51       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9993203889232406
[2018-06-08 13:30:51       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.999419899627399
[2018-06-08 13:30:52       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.999373321101845
[2018-06-08 13:30:53       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9992631061504254
[2018-06-08 13:30:53       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9993824305957213
[2018-06-08 13:30:54       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9994180729810788
[2018-06-08 13:30:54       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9993913260686537
[2018-06-08 13:30:55       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9994213279358636
[2018-06-08 13:30:56       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9994033324166319
[2018-06-08 13:30:56       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9994061169700729
[2018-06-08 13:30:57       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9993702076539358
[2018-06-08 13:30:58       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.999404313515492
[2018-06-08 13:30:58       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9993235784054719
[2018-06-08 13:30:59       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9994023783824468
[2018-06-08 13:30:59       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9993700588781159
[2018-06-08 13:31:00       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9993921344339409
[2018-06-08 13:31:01       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9993887344932233
[2018-06-08 13:31:01       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9994163680938862
[2018-06-08 13:31:02       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9994053352442408
[2018-06-08 13:31:03       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9994309971415144
[2018-06-08 13:31:03       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9993287938138375
[2018-06-08 13:31:04       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9994162045783515
[2018-06-08 13:31:04       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9994093580255509
[2018-06-08 13:31:05       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9994145605778845
[2018-06-08 13:31:06       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9994301468985353
[2018-06-08 13:31:06       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9994058076043707
[2018-06-08 13:31:07       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9994142481005939
[2018-06-08 13:31:08       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9994324047152706
[2018-06-08 13:31:08       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.999433238112849
[2018-06-08 13:31:09       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9993703497785598
[2018-06-08 13:31:09       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9994350122933326
[2018-06-08 13:31:10       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9994184924373777
[2018-06-08 13:31:11       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9993708928929521
[2018-06-08 13:31:11       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9994370463387099
[2018-06-08 13:31:12       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9994200643351127
[2018-06-08 13:31:13       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9994040971527532
[2018-06-08 13:31:13       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9994064161001274
[2018-06-08 13:31:14       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9994079682947087
[2018-06-08 13:31:15       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9993766252388134
[2018-06-08 13:31:15       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9994253395603384
[2018-06-08 13:31:16       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9994313804224663
[2018-06-08 13:31:17       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9994222960456244
[2018-06-08 13:31:17       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9994242469752525
[2018-06-08 13:31:18       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9993854168716819
[2018-06-08 13:31:19       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9994208405260357
[2018-06-08 13:31:20       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9994059792426355
[2018-06-08 13:31:20       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9994180563410353
[2018-06-08 13:31:21       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9994281538901924
[2018-06-08 13:31:22       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.999430654592674
[2018-06-08 13:31:22       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.999432618768917
[2018-06-08 13:31:23       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9994386739397426
[2018-06-08 13:31:24       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.999386477830206
[2018-06-08 13:31:24       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9994284690449856
[2018-06-08 13:31:25       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9994127996093496
[2018-06-08 13:31:26       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9994308606180831
[2018-06-08 13:31:26       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9994344010600988
[2018-06-08 13:31:27       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9994368920655031
[2018-06-08 13:31:27       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:31:27       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:31:27       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:31:27       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_34.pickle"
[2018-06-08 13:31:27  start_training.py:129 -                      main()] Fidelity obtained: 0.9994180426693106
[2018-06-08 13:31:29  start_training.py:101 -                      main()] Starting training no.35
[2018-06-08 13:31:29    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:31:29    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:31:29    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:31:29    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:31:29           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:31:29           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:31:29       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:31:29       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:31:29       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:31:29       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:31:29       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:31:29       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:31:29       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:31:29       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:31:29       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:31:29       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:31:32       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:31:33       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7065711751307197
[2018-06-08 13:31:34       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5330293061401451
[2018-06-08 13:31:35       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6809447355612182
[2018-06-08 13:31:36       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9078754085380834
[2018-06-08 13:31:37       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9109159180771681
[2018-06-08 13:31:38       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9078370669881478
[2018-06-08 13:31:39       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9124033173788714
[2018-06-08 13:31:39       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9287170753840587
[2018-06-08 13:31:40       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9364234080741037
[2018-06-08 13:31:40       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.919184893004848
[2018-06-08 13:31:41       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9363414488265905
[2018-06-08 13:31:42       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9087997205059369
[2018-06-08 13:31:42       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9422848471445431
[2018-06-08 13:31:43       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9228295267367286
[2018-06-08 13:31:43       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9360194754864921
[2018-06-08 13:31:44       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9491689800280619
[2018-06-08 13:31:45       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.942650542809668
[2018-06-08 13:31:45       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9499889018046719
[2018-06-08 13:31:46       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9338269646449624
[2018-06-08 13:31:46       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9474256580889423
[2018-06-08 13:31:47       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9515970219256641
[2018-06-08 13:31:48       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9320233092615475
[2018-06-08 13:31:48       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9534926772466004
[2018-06-08 13:31:49       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9508397342868552
[2018-06-08 13:31:50       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9521802633251335
[2018-06-08 13:31:50       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9451693156399754
[2018-06-08 13:31:51       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9447346117201398
[2018-06-08 13:31:52       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9512326583817082
[2018-06-08 13:31:53       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9531578264188956
[2018-06-08 13:31:54       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9512928458491656
[2018-06-08 13:31:55       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.949919679707652
[2018-06-08 13:31:56       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9542873758875252
[2018-06-08 13:31:56       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9509779947973734
[2018-06-08 13:31:57       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9289888271157402
[2018-06-08 13:31:57       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9502756632769811
[2018-06-08 13:31:58       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9455132458039359
[2018-06-08 13:31:59       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9541709707241565
[2018-06-08 13:31:59       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9498255269302017
[2018-06-08 13:32:00       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9490569419540517
[2018-06-08 13:32:01       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9517863950332317
[2018-06-08 13:32:01       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9521354719773594
[2018-06-08 13:32:02       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9479291755616468
[2018-06-08 13:32:03       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9544545383057533
[2018-06-08 13:32:03       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9490589474326084
[2018-06-08 13:32:04       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9511857527146421
[2018-06-08 13:32:05       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9510559213469735
[2018-06-08 13:32:05       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9420039484695891
[2018-06-08 13:32:06       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9543182761465566
[2018-06-08 13:32:07       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9525566853351088
[2018-06-08 13:32:07       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9540287634846962
[2018-06-08 13:32:08       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9541156875585035
[2018-06-08 13:32:09       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.953740481658424
[2018-06-08 13:32:10       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9532159421202618
[2018-06-08 13:32:11       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9423274833050609
[2018-06-08 13:32:12       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9524463699646833
[2018-06-08 13:32:13       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9487199896678953
[2018-06-08 13:32:13       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9518400047766344
[2018-06-08 13:32:14       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.954687102898617
[2018-06-08 13:32:15       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9532032247448455
[2018-06-08 13:32:15       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9532126058645852
[2018-06-08 13:32:16       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9531987428571708
[2018-06-08 13:32:17       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9529353119009001
[2018-06-08 13:32:18       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9530153205508937
[2018-06-08 13:32:19       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9533400956318588
[2018-06-08 13:32:20       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.949084814526934
[2018-06-08 13:32:20       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9487865193873358
[2018-06-08 13:32:21       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9530451833646612
[2018-06-08 13:32:22       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9508932382676346
[2018-06-08 13:32:22       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9480941333879395
[2018-06-08 13:32:23       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.955025238592307
[2018-06-08 13:32:24       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9456305939904168
[2018-06-08 13:32:24       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9450598031211453
[2018-06-08 13:32:25       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9538969274562413
[2018-06-08 13:32:25       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9516326495518634
[2018-06-08 13:32:26       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9547299553204037
[2018-06-08 13:32:27       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9540424167497967
[2018-06-08 13:32:27       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9426338371787334
[2018-06-08 13:32:28       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9491563351977195
[2018-06-08 13:32:28       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9538720799360833
[2018-06-08 13:32:29       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.951967188627884
[2018-06-08 13:32:29       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9541877891563724
[2018-06-08 13:32:30       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9510965472329435
[2018-06-08 13:32:31       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9522243740409573
[2018-06-08 13:32:31       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.951179047186035
[2018-06-08 13:32:32       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9526059419229282
[2018-06-08 13:32:33       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9525016475645798
[2018-06-08 13:32:33       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9539716413390862
[2018-06-08 13:32:34       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9540830427459226
[2018-06-08 13:32:34       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9538836250918652
[2018-06-08 13:32:35       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.950998807031292
[2018-06-08 13:32:36       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9540832216298162
[2018-06-08 13:32:36       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9516115444035517
[2018-06-08 13:32:37       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.951005326142715
[2018-06-08 13:32:37       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9533601233466095
[2018-06-08 13:32:38       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9513750386719324
[2018-06-08 13:32:39       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9543523290292805
[2018-06-08 13:32:40       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9520221331242606
[2018-06-08 13:32:41       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9546214142714736
[2018-06-08 13:32:42       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9533552736777111
[2018-06-08 13:32:43       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9546922851829769
[2018-06-08 13:32:43       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:32:43       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:32:43       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:32:43       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_35.pickle"
[2018-06-08 13:32:43  start_training.py:129 -                      main()] Fidelity obtained: 0.9550563593449117
[2018-06-08 13:32:46  start_training.py:101 -                      main()] Starting training no.36
[2018-06-08 13:32:46    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:32:46    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:32:46    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:32:46    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:32:46           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:32:46           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:32:46       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:32:46       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:32:46       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:32:46       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:32:46       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:32:46       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:32:46       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:32:46       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:32:46       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:32:46       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:32:50       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:32:51       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6998401992654749
[2018-06-08 13:32:52       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5614162424772132
[2018-06-08 13:32:53       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9473893251790441
[2018-06-08 13:32:54       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7337960697675142
[2018-06-08 13:32:55       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999974861500704
[2018-06-08 13:32:56       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999981719444
[2018-06-08 13:32:57       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999999981679
[2018-06-08 13:32:57       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.999999999999998
[2018-06-08 13:32:58       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999999999999
[2018-06-08 13:32:59       Optimizer.py:490 -                      _run()]   Epoch no. 9: 1.0
[2018-06-08 13:32:59       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:32:59       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:32:59       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:32:59       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:32:59       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_36.pickle"
[2018-06-08 13:32:59  start_training.py:129 -                      main()] Fidelity obtained: 1.0000000000000002
[2018-06-08 13:33:01  start_training.py:101 -                      main()] Starting training no.37
[2018-06-08 13:33:01    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:33:01    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:33:01    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:33:01    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:33:01           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:33:01           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:33:01       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:33:01       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:33:01       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:33:01       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:33:01       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:33:01       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:33:01       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:33:01       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:33:01       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:33:01       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:33:05       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:33:05       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8386552005802196
[2018-06-08 13:33:06       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.27316874799096086
[2018-06-08 13:33:07       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9348794735987164
[2018-06-08 13:33:07       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.990776345881179
[2018-06-08 13:33:08       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.964504512064098
[2018-06-08 13:33:09       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9947342863218301
[2018-06-08 13:33:09       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.990218187882154
[2018-06-08 13:33:10       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9955007922330096
[2018-06-08 13:33:11       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9906782366958269
[2018-06-08 13:33:11       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9949264149478698
[2018-06-08 13:33:12       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.990666294324622
[2018-06-08 13:33:13       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9955331325202156
[2018-06-08 13:33:13       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9922565182065956
[2018-06-08 13:33:14       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9952049650018523
[2018-06-08 13:33:15       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9960379957040023
[2018-06-08 13:33:15       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9961055298839827
[2018-06-08 13:33:16       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9971581654947866
[2018-06-08 13:33:17       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9949195454796752
[2018-06-08 13:33:17       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9960245793117164
[2018-06-08 13:33:18       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9969282427513997
[2018-06-08 13:33:19       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9975218741639817
[2018-06-08 13:33:19       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.996781943990586
[2018-06-08 13:33:20       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.997106486320222
[2018-06-08 13:33:21       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9974265906756828
[2018-06-08 13:33:21       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9971402667620728
[2018-06-08 13:33:22       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9979155048798549
[2018-06-08 13:33:23       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.998027305196166
[2018-06-08 13:33:23       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9979150602675796
[2018-06-08 13:33:24       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9979869953576364
[2018-06-08 13:33:24       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9981081806484597
[2018-06-08 13:33:25       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9981225810096448
[2018-06-08 13:33:26       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9984211332646628
[2018-06-08 13:33:26       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9982071955032866
[2018-06-08 13:33:27       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9976050892998173
[2018-06-08 13:33:28       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.998378215244819
[2018-06-08 13:33:28       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.998546007828117
[2018-06-08 13:33:29       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9986362063302255
[2018-06-08 13:33:30       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9987018006312407
[2018-06-08 13:33:30       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9986344281856984
[2018-06-08 13:33:31       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.99874628063204
[2018-06-08 13:33:32       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.998774290203108
[2018-06-08 13:33:32       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9987805852973085
[2018-06-08 13:33:33       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9987696867332457
[2018-06-08 13:33:34       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9984656173835396
[2018-06-08 13:33:34       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9989056022899573
[2018-06-08 13:33:35       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9990072338652228
[2018-06-08 13:33:36       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9988903880905576
[2018-06-08 13:33:37       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9990072781979635
[2018-06-08 13:33:38       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9990280444894222
[2018-06-08 13:33:39       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9989267724046978
[2018-06-08 13:33:40       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9990627330522228
[2018-06-08 13:33:41       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9992017687255561
[2018-06-08 13:33:41       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9991019796321967
[2018-06-08 13:33:42       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.999202268420234
[2018-06-08 13:33:43       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9991730217671341
[2018-06-08 13:33:44       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.999190755619031
[2018-06-08 13:33:44       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9992813904352515
[2018-06-08 13:33:45       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.999310942813701
[2018-06-08 13:33:46       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9992439124505207
[2018-06-08 13:33:46       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9994176906549138
[2018-06-08 13:33:47       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.999338664050979
[2018-06-08 13:33:48       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9994422209956003
[2018-06-08 13:33:48       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9994908864120822
[2018-06-08 13:33:49       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9994739744401524
[2018-06-08 13:33:50       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9995310171874918
[2018-06-08 13:33:50       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9995294106853511
[2018-06-08 13:33:51       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9995780851065263
[2018-06-08 13:33:52       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9995939070048795
[2018-06-08 13:33:52       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9995952967445771
[2018-06-08 13:33:53       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9996548235428753
[2018-06-08 13:33:54       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.999627497478215
[2018-06-08 13:33:54       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9996714427980712
[2018-06-08 13:33:55       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9996772961777752
[2018-06-08 13:33:55       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9997293736814228
[2018-06-08 13:33:56       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9997287291247772
[2018-06-08 13:33:57       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9997490677253331
[2018-06-08 13:33:57       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9997588549986476
[2018-06-08 13:33:58       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9997635966197125
[2018-06-08 13:33:59       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.999766454651385
[2018-06-08 13:33:59       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9997953698013791
[2018-06-08 13:34:00       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9998041939545612
[2018-06-08 13:34:01       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9998223454227445
[2018-06-08 13:34:01       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9998031297847256
[2018-06-08 13:34:02       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9998289958031249
[2018-06-08 13:34:03       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9998493754594416
[2018-06-08 13:34:03       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9998531585655571
[2018-06-08 13:34:04       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9998653243584588
[2018-06-08 13:34:04       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.999860379472271
[2018-06-08 13:34:05       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.999873813120601
[2018-06-08 13:34:06       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9998812428410048
[2018-06-08 13:34:06       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9998896133617101
[2018-06-08 13:34:07       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9998985649397334
[2018-06-08 13:34:08       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9998940946068204
[2018-06-08 13:34:08       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999049184450228
[2018-06-08 13:34:09       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999125618989294
[2018-06-08 13:34:10       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999140165504593
[2018-06-08 13:34:10       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999228116755522
[2018-06-08 13:34:11       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.999927213030394
[2018-06-08 13:34:12       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999258311103355
[2018-06-08 13:34:12       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.999934910574123
[2018-06-08 13:34:12       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:34:12       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:34:12       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:34:12       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_37.pickle"
[2018-06-08 13:34:12  start_training.py:129 -                      main()] Fidelity obtained: 0.9999355223962149
[2018-06-08 13:34:15  start_training.py:101 -                      main()] Starting training no.38
[2018-06-08 13:34:15    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:34:15    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:34:15    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:34:15    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:34:15           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:34:15           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:34:15       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:34:15       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:34:15       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:34:15       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:34:15       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:34:15       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:34:15       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:34:15       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:34:15       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:34:15       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:34:19       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:34:20       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9139191639603037
[2018-06-08 13:34:20       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7857588260004167
[2018-06-08 13:34:21       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.5540191395787065
[2018-06-08 13:34:22       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9771215385581116
[2018-06-08 13:34:22       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9890876918619574
[2018-06-08 13:34:23       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9917819342101132
[2018-06-08 13:34:24       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9954651712800904
[2018-06-08 13:34:24       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9947268942035086
[2018-06-08 13:34:25       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.992353575569848
[2018-06-08 13:34:26       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9958404437816688
[2018-06-08 13:34:26       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.995439174039082
[2018-06-08 13:34:27       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9971110852146728
[2018-06-08 13:34:28       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9951812864595615
[2018-06-08 13:34:29       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.996586716232037
[2018-06-08 13:34:30       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.996638723212319
[2018-06-08 13:34:31       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9966086631666825
[2018-06-08 13:34:32       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9968776998864826
[2018-06-08 13:34:33       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9947060829046159
[2018-06-08 13:34:33       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9976110337929391
[2018-06-08 13:34:34       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9979510892749812
[2018-06-08 13:34:35       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9981543450407976
[2018-06-08 13:34:36       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9981386533937373
[2018-06-08 13:34:37       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9980000943638809
[2018-06-08 13:34:38       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9976447618351818
[2018-06-08 13:34:39       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9981525688000226
[2018-06-08 13:34:40       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9984261060723465
[2018-06-08 13:34:41       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.998488739751133
[2018-06-08 13:34:41       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9982527961979677
[2018-06-08 13:34:42       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9983072142711669
[2018-06-08 13:34:43       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9982691637928524
[2018-06-08 13:34:44       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9984865725715163
[2018-06-08 13:34:45       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.998806770751358
[2018-06-08 13:34:46       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9987579655551535
[2018-06-08 13:34:46       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9982491652077062
[2018-06-08 13:34:47       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9988685126221633
[2018-06-08 13:34:48       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9988015972790872
[2018-06-08 13:34:48       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9989246661761056
[2018-06-08 13:34:49       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9983362262356218
[2018-06-08 13:34:50       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9988953309527682
[2018-06-08 13:34:50       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9988216609173064
[2018-06-08 13:34:51       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9989496064096176
[2018-06-08 13:34:52       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9990104120173774
[2018-06-08 13:34:52       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9990966642000068
[2018-06-08 13:34:53       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9991132007402929
[2018-06-08 13:34:54       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9992513099294417
[2018-06-08 13:34:55       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9992513292783669
[2018-06-08 13:34:56       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9992919292943011
[2018-06-08 13:34:57       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9993076001005581
[2018-06-08 13:34:57       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9993801534984386
[2018-06-08 13:34:58       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9993239678286325
[2018-06-08 13:34:59       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9994004552844429
[2018-06-08 13:34:59       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9994750639295594
[2018-06-08 13:35:00       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9994764997508314
[2018-06-08 13:35:01       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.999506419560448
[2018-06-08 13:35:01       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9995335132395886
[2018-06-08 13:35:02       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9994935644833077
[2018-06-08 13:35:03       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9996062894389434
[2018-06-08 13:35:03       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9995901965889686
[2018-06-08 13:35:04       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9995696493265033
[2018-06-08 13:35:05       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9996772400580172
[2018-06-08 13:35:06       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.99968857654676
[2018-06-08 13:35:07       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9997130178753255
[2018-06-08 13:35:07       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.999708829653618
[2018-06-08 13:35:08       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9996890145651492
[2018-06-08 13:35:09       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9997643364357469
[2018-06-08 13:35:09       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.999774264565866
[2018-06-08 13:35:10       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9997797396804387
[2018-06-08 13:35:11       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9997886219258004
[2018-06-08 13:35:12       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9998034800455686
[2018-06-08 13:35:13       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9998085154900646
[2018-06-08 13:35:14       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9998396385211934
[2018-06-08 13:35:15       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9998502097234326
[2018-06-08 13:35:15       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.999849327865194
[2018-06-08 13:35:16       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.99986814344071
[2018-06-08 13:35:17       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9998796594528213
[2018-06-08 13:35:17       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9998782882745354
[2018-06-08 13:35:18       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9998885045523142
[2018-06-08 13:35:19       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999030060505326
[2018-06-08 13:35:20       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999051358291893
[2018-06-08 13:35:20       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999076631893952
[2018-06-08 13:35:21       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999187849995949
[2018-06-08 13:35:22       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999227325720529
[2018-06-08 13:35:22       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999266237709884
[2018-06-08 13:35:23       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999306615602659
[2018-06-08 13:35:24       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999354298868157
[2018-06-08 13:35:24       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999391345978508
[2018-06-08 13:35:25       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999402953376868
[2018-06-08 13:35:26       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999467713552588
[2018-06-08 13:35:26       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999429292176248
[2018-06-08 13:35:27       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999454611681847
[2018-06-08 13:35:28       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999540115676008
[2018-06-08 13:35:28       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999562262058808
[2018-06-08 13:35:29       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999605753869354
[2018-06-08 13:35:30       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999585928445414
[2018-06-08 13:35:31       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999609190883666
[2018-06-08 13:35:31       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999640562104622
[2018-06-08 13:35:32       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999686686006964
[2018-06-08 13:35:33       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999692630796256
[2018-06-08 13:35:33       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999716958222921
[2018-06-08 13:35:34       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999731469551135
[2018-06-08 13:35:34       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:35:34       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:35:34       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:35:34       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_38.pickle"
[2018-06-08 13:35:34  start_training.py:129 -                      main()] Fidelity obtained: 0.9999723020558513
[2018-06-08 13:35:36  start_training.py:101 -                      main()] Starting training no.39
[2018-06-08 13:35:36    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:35:36    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:35:36    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:35:36    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:35:36           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:35:36           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:35:36       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:35:36       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:35:36       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:35:36       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:35:36       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:35:36       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:35:36       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:35:36       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:35:36       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:35:36       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:35:40       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:35:41       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.3292553272063879
[2018-06-08 13:35:41       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6834910693097985
[2018-06-08 13:35:42       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9540675404028116
[2018-06-08 13:35:42       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.842991454033438
[2018-06-08 13:35:43       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999973180476381
[2018-06-08 13:35:44       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999995538
[2018-06-08 13:35:45       Optimizer.py:490 -                      _run()]   Epoch no. 6: 1.0
[2018-06-08 13:35:45       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:35:45       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:35:45       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:35:45       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:35:45       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_39.pickle"
[2018-06-08 13:35:45  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:35:47  start_training.py:101 -                      main()] Starting training no.40
[2018-06-08 13:35:47    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:35:47    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:35:47    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:35:47    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:35:47           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:35:47           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:35:47       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:35:47       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:35:47       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:35:47       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:35:47       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:35:47       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:35:47       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:35:47       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:35:47       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:35:47       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:35:50       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:35:51       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8516681622644288
[2018-06-08 13:35:52       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9921963935104656
[2018-06-08 13:35:53       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.976268249756906
[2018-06-08 13:35:54       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999999244257549
[2018-06-08 13:35:55       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999848838479
[2018-06-08 13:35:56       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999999974
[2018-06-08 13:35:57       Optimizer.py:490 -                      _run()]   Epoch no. 6: 1.0
[2018-06-08 13:35:57       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:35:57       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:35:57       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:35:57       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:35:57       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_40.pickle"
[2018-06-08 13:35:57  start_training.py:129 -                      main()] Fidelity obtained: 0.9999999999999996
[2018-06-08 13:35:59  start_training.py:101 -                      main()] Starting training no.41
[2018-06-08 13:35:59    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:35:59    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:35:59    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:35:59    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:35:59           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:35:59           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:35:59       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:35:59       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:35:59       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:35:59       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:35:59       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:35:59       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:35:59       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:35:59       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:35:59       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:35:59       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:36:03       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:36:04       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9255254082124713
[2018-06-08 13:36:05       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6295175926135357
[2018-06-08 13:36:05       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8008905183479029
[2018-06-08 13:36:06       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999394720627602
[2018-06-08 13:36:07       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999996751217022
[2018-06-08 13:36:07       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999777465852
[2018-06-08 13:36:08       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999975633758
[2018-06-08 13:36:09       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999997309805
[2018-06-08 13:36:09       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.999999999955376
[2018-06-08 13:36:10       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999937912
[2018-06-08 13:36:11       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999992235
[2018-06-08 13:36:11       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999999999998623
[2018-06-08 13:36:12       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999999999661
[2018-06-08 13:36:13       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999999999943
[2018-06-08 13:36:13       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999999999996
[2018-06-08 13:36:14       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999999999999
[2018-06-08 13:36:15       Optimizer.py:490 -                      _run()]   Epoch no. 16: 1.0000000000000002
[2018-06-08 13:36:15       Optimizer.py:490 -                      _run()]   Epoch no. 17: 1.0000000000000002
[2018-06-08 13:36:16       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999999999999
[2018-06-08 13:36:16       Optimizer.py:490 -                      _run()]   Epoch no. 19: 1.0
[2018-06-08 13:36:16       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:36:16       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:36:16       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:36:16       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:36:16       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_41.pickle"
[2018-06-08 13:36:16  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:36:19  start_training.py:101 -                      main()] Starting training no.42
[2018-06-08 13:36:19    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:36:19    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:36:19    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:36:19    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:36:19           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:36:19           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:36:19       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:36:19       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:36:19       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:36:19       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:36:19       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:36:19       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:36:19       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:36:19       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:36:19       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:36:19       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:36:22       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:36:22       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8238161991877442
[2018-06-08 13:36:23       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7207933107698697
[2018-06-08 13:36:24       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9955871535669628
[2018-06-08 13:36:24       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9985921756159287
[2018-06-08 13:36:25       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999740629896562
[2018-06-08 13:36:26       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999828764863896
[2018-06-08 13:36:26       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999956201439539
[2018-06-08 13:36:27       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999963921535137
[2018-06-08 13:36:28       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999988372766793
[2018-06-08 13:36:28       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999994439114659
[2018-06-08 13:36:29       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999997462032755
[2018-06-08 13:36:30       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999998739766012
[2018-06-08 13:36:30       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999198694469
[2018-06-08 13:36:31       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999689372575
[2018-06-08 13:36:31       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999800037451
[2018-06-08 13:36:32       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999894015005
[2018-06-08 13:36:33       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999940117817
[2018-06-08 13:36:33       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999963760274
[2018-06-08 13:36:34       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999977644641
[2018-06-08 13:36:35       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999988032415
[2018-06-08 13:36:35       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999991412879
[2018-06-08 13:36:36       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999995175094
[2018-06-08 13:36:36       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999996800181
[2018-06-08 13:36:37       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999997699953
[2018-06-08 13:36:38       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999999998551806
[2018-06-08 13:36:38       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999999999145497
[2018-06-08 13:36:39       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999999356435
[2018-06-08 13:36:40       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999999594167
[2018-06-08 13:36:40       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999999709762
[2018-06-08 13:36:41       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.999999999980281
[2018-06-08 13:36:41       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999999999865931
[2018-06-08 13:36:42       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999999904061
[2018-06-08 13:36:43       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999999999932517
[2018-06-08 13:36:43       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999999946618
[2018-06-08 13:36:44       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999999999964512
[2018-06-08 13:36:45       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999999973406
[2018-06-08 13:36:45       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999999979113
[2018-06-08 13:36:46       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.99999999999859
[2018-06-08 13:36:46       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999999999988117
[2018-06-08 13:36:47       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999999990821
[2018-06-08 13:36:48       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999999999993939
[2018-06-08 13:36:48       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999999999995255
[2018-06-08 13:36:49       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999999996709
[2018-06-08 13:36:50       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999999999997126
[2018-06-08 13:36:50       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999999999997969
[2018-06-08 13:36:51       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999999998418
[2018-06-08 13:36:51       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999999998812
[2018-06-08 13:36:52       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999999999999011
[2018-06-08 13:36:53       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.999999999999928
[2018-06-08 13:36:53       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999999999999437
[2018-06-08 13:36:54       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999999999999543
[2018-06-08 13:36:55       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.999999999999965
[2018-06-08 13:36:55       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999999999999722
[2018-06-08 13:36:56       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999999999999765
[2018-06-08 13:36:57       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999999999999822
[2018-06-08 13:36:57       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999999999999852
[2018-06-08 13:36:58       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999999999865
[2018-06-08 13:36:58       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999999999999915
[2018-06-08 13:36:59       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.999999999999992
[2018-06-08 13:37:00       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999999999999916
[2018-06-08 13:37:00       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999999999999954
[2018-06-08 13:37:01       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.999999999999997
[2018-06-08 13:37:02       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999999999999981
[2018-06-08 13:37:02       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999999999999986
[2018-06-08 13:37:03       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999999999999994
[2018-06-08 13:37:04       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999999999999993
[2018-06-08 13:37:04       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999999999999994
[2018-06-08 13:37:05       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999999999999997
[2018-06-08 13:37:05       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999999999999996
[2018-06-08 13:37:06       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999999999999997
[2018-06-08 13:37:07       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999999999999997
[2018-06-08 13:37:07       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999999999999996
[2018-06-08 13:37:08       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999999999999997
[2018-06-08 13:37:09       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999999999999997
[2018-06-08 13:37:09       Optimizer.py:490 -                      _run()]   Epoch no. 74: 1.0
[2018-06-08 13:37:09       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:37:09       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:37:09       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:37:09       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:37:09       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_42.pickle"
[2018-06-08 13:37:09  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:37:11  start_training.py:101 -                      main()] Starting training no.43
[2018-06-08 13:37:11    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:37:11    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:37:11    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:37:11    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:37:11           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:37:11           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:37:11       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:37:11       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:37:11       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:37:11       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:37:11       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:37:11       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:37:11       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:37:11       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:37:11       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:37:11       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:37:14       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:37:15       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.23463277871999766
[2018-06-08 13:37:15       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7710275721030497
[2018-06-08 13:37:16       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8144622450134414
[2018-06-08 13:37:16       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999350831733157
[2018-06-08 13:37:17       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.999999007914306
[2018-06-08 13:37:18       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.999817901462155
[2018-06-08 13:37:18       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999998153609
[2018-06-08 13:37:19       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999976147
[2018-06-08 13:37:19       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.999999999999923
[2018-06-08 13:37:20       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999999979
[2018-06-08 13:37:21       Optimizer.py:490 -                      _run()]   Epoch no. 10: 1.0000000000000002
[2018-06-08 13:37:21       Optimizer.py:490 -                      _run()]   Epoch no. 11: 1.0
[2018-06-08 13:37:21       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:37:21       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:37:21       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:37:21       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:37:21       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_43.pickle"
[2018-06-08 13:37:21  start_training.py:129 -                      main()] Fidelity obtained: 0.9999999999999991
[2018-06-08 13:37:24  start_training.py:101 -                      main()] Starting training no.44
[2018-06-08 13:37:24    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:37:24    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:37:24    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:37:24    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:37:24           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:37:24           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:37:24       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:37:24       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:37:24       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:37:24       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:37:24       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:37:24       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:37:24       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:37:24       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:37:24       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:37:24       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:37:28       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:37:29       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9938934920215864
[2018-06-08 13:37:30       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9591303052053769
[2018-06-08 13:37:31       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9980083772361665
[2018-06-08 13:37:32       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9998620419077021
[2018-06-08 13:37:32       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999280441459635
[2018-06-08 13:37:33       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999760417922892
[2018-06-08 13:37:34       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999838481490582
[2018-06-08 13:37:34       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999941044470079
[2018-06-08 13:37:35       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.999996735617506
[2018-06-08 13:37:36       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999983926070134
[2018-06-08 13:37:36       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999990003492626
[2018-06-08 13:37:37       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999994410077448
[2018-06-08 13:37:37       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999996397214969
[2018-06-08 13:37:38       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999998070790808
[2018-06-08 13:37:39       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999998838856918
[2018-06-08 13:37:39       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999155920994
[2018-06-08 13:37:40       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999485257952
[2018-06-08 13:37:41       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999678256508
[2018-06-08 13:37:41       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999733494553
[2018-06-08 13:37:42       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999832359194
[2018-06-08 13:37:42       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999896807285
[2018-06-08 13:37:43       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999925374099
[2018-06-08 13:37:44       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999948532396
[2018-06-08 13:37:44       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999963649199
[2018-06-08 13:37:45       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999999971482063
[2018-06-08 13:37:46       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999999980493564
[2018-06-08 13:37:46       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999985686371
[2018-06-08 13:37:47       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999988392897
[2018-06-08 13:37:48       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999992215284
[2018-06-08 13:37:48       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999999992980694
[2018-06-08 13:37:49       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999999995562167
[2018-06-08 13:37:50       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999996673797
[2018-06-08 13:37:50       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999999997464357
[2018-06-08 13:37:51       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999997997863
[2018-06-08 13:37:51       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999999998393314
[2018-06-08 13:37:52       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999998854071
[2018-06-08 13:37:53       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999999117379
[2018-06-08 13:37:53       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999999999235227
[2018-06-08 13:37:54       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999999999413905
[2018-06-08 13:37:55       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999999558201
[2018-06-08 13:37:55       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999999999628609
[2018-06-08 13:37:56       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999999999714323
[2018-06-08 13:37:57       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.999999999977731
[2018-06-08 13:37:57       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999999999814448
[2018-06-08 13:37:58       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999999999831636
[2018-06-08 13:37:58       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999999879569
[2018-06-08 13:37:59       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999999898879
[2018-06-08 13:38:00       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.999999999992084
[2018-06-08 13:38:00       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999999999934346
[2018-06-08 13:38:01       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999999999944759
[2018-06-08 13:38:02       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999999999953759
[2018-06-08 13:38:02       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.99999999999616
[2018-06-08 13:38:03       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999999999967573
[2018-06-08 13:38:03       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999999999968294
[2018-06-08 13:38:04       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999999999976616
[2018-06-08 13:38:05       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.999999999998005
[2018-06-08 13:38:05       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999999983626
[2018-06-08 13:38:06       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999999999986019
[2018-06-08 13:38:07       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999999999988396
[2018-06-08 13:38:07       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.999999999999016
[2018-06-08 13:38:08       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999999999991606
[2018-06-08 13:38:09       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999999999992607
[2018-06-08 13:38:09       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999999999993809
[2018-06-08 13:38:10       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999999999994337
[2018-06-08 13:38:10       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999999999995333
[2018-06-08 13:38:11       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.999999999999567
[2018-06-08 13:38:12       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999999999996606
[2018-06-08 13:38:12       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.999999999999693
[2018-06-08 13:38:13       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999999999997365
[2018-06-08 13:38:14       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999999999997747
[2018-06-08 13:38:14       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999999999998009
[2018-06-08 13:38:15       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999999999998248
[2018-06-08 13:38:16       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999999999998493
[2018-06-08 13:38:16       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.999999999999863
[2018-06-08 13:38:17       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.999999999999872
[2018-06-08 13:38:18       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999999999998945
[2018-06-08 13:38:19       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999999999999101
[2018-06-08 13:38:20       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999999999999158
[2018-06-08 13:38:21       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999999999999284
[2018-06-08 13:38:22       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999999999999372
[2018-06-08 13:38:23       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999999999999416
[2018-06-08 13:38:24       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999999999999503
[2018-06-08 13:38:24       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999999999999521
[2018-06-08 13:38:25       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999999999999616
[2018-06-08 13:38:26       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999999999999655
[2018-06-08 13:38:26       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999999999999681
[2018-06-08 13:38:27       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999999999999732
[2018-06-08 13:38:28       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999999999999752
[2018-06-08 13:38:28       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999999999999778
[2018-06-08 13:38:29       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999999999999806
[2018-06-08 13:38:29       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999999999999798
[2018-06-08 13:38:30       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999999999999831
[2018-06-08 13:38:31       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999999999999857
[2018-06-08 13:38:31       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999999999999868
[2018-06-08 13:38:32       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999999999999887
[2018-06-08 13:38:32       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999999999999892
[2018-06-08 13:38:33       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999999999999903
[2018-06-08 13:38:34       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999999999999918
[2018-06-08 13:38:34       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999999999999936
[2018-06-08 13:38:35       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.999999999999993
[2018-06-08 13:38:35       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:38:35       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:38:35       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:38:35       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_44.pickle"
[2018-06-08 13:38:35  start_training.py:129 -                      main()] Fidelity obtained: 0.9999999999999942
[2018-06-08 13:38:37  start_training.py:101 -                      main()] Starting training no.45
[2018-06-08 13:38:37    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:38:37    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:38:37    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:38:37    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:38:37           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:38:37           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:38:37       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:38:37       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:38:37       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:38:37       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:38:37       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:38:37       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:38:37       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:38:37       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:38:37       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:38:37       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:38:41       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:38:41       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8284349374504097
[2018-06-08 13:38:42       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9954121537968524
[2018-06-08 13:38:43       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.993738312040302
[2018-06-08 13:38:43       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9982049191122129
[2018-06-08 13:38:44       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999996738821701
[2018-06-08 13:38:45       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999998464305943
[2018-06-08 13:38:45       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999939167572
[2018-06-08 13:38:46       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999986417474
[2018-06-08 13:38:47       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999997281941
[2018-06-08 13:38:47       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999998823814
[2018-06-08 13:38:48       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999729755
[2018-06-08 13:38:49       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999999999907574
[2018-06-08 13:38:49       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999999961013
[2018-06-08 13:38:50       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999999988932
[2018-06-08 13:38:50       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.999999999999698
[2018-06-08 13:38:51       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999999998909
[2018-06-08 13:38:52       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999999999545
[2018-06-08 13:38:53       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999999999807
[2018-06-08 13:38:53       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999999999915
[2018-06-08 13:38:54       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999999999971
[2018-06-08 13:38:55       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999999999996
[2018-06-08 13:38:55       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999999999997
[2018-06-08 13:38:56       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999999999999
[2018-06-08 13:38:56       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999999999999
[2018-06-08 13:38:57       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999999999999997
[2018-06-08 13:38:58       Optimizer.py:490 -                      _run()]   Epoch no. 25: 1.0
[2018-06-08 13:38:58       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:38:58       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:38:58       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:38:58       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:38:58       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_45.pickle"
[2018-06-08 13:38:58  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:39:00  start_training.py:101 -                      main()] Starting training no.46
[2018-06-08 13:39:00    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:39:00    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:39:00    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:39:00    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:39:00           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:39:00           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:39:00       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:39:00       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:39:00       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:39:00       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:39:00       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:39:00       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:39:00       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:39:00       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:39:00       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:39:00       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:39:04       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:39:05       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9755618097954658
[2018-06-08 13:39:05       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.982178849108117
[2018-06-08 13:39:06       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9999999996939133
[2018-06-08 13:39:07       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999999999999736
[2018-06-08 13:39:07       Optimizer.py:490 -                      _run()]   Epoch no. 4: 1.0000000000000002
[2018-06-08 13:39:08       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999999999
[2018-06-08 13:39:09       Optimizer.py:490 -                      _run()]   Epoch no. 6: 1.0
[2018-06-08 13:39:09       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:39:09       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:39:09       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:39:09       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:39:09       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_46.pickle"
[2018-06-08 13:39:09  start_training.py:129 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:39:11  start_training.py:101 -                      main()] Starting training no.47
[2018-06-08 13:39:11    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:39:11    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:39:11    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:39:11    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:39:11           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:39:11           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:39:11       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:39:11       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:39:11       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:39:11       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:39:11       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:39:11       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:39:11       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:39:11       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:39:11       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:39:11       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:39:14       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:39:15       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8392728242814914
[2018-06-08 13:39:16       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9996469087410421
[2018-06-08 13:39:17       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9999999903880014
[2018-06-08 13:39:18       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999999999998583
[2018-06-08 13:39:19       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999999999
[2018-06-08 13:39:20       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0
[2018-06-08 13:39:20       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:39:20       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:39:20       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:39:20       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:39:20       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_47.pickle"
[2018-06-08 13:39:20  start_training.py:129 -                      main()] Fidelity obtained: 0.9999999999999998
[2018-06-08 13:39:22  start_training.py:101 -                      main()] Starting training no.48
[2018-06-08 13:39:22    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:39:22    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:39:22    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:39:22    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:39:23           model.py:370 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:39:23           model.py:373 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:39:23       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:39:23       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:39:23       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:39:23       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:39:23       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:39:23       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:39:23       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:39:23       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:39:23       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:39:23       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:39:26       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:39:27       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5266673727503747
[2018-06-08 13:39:27       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9805342680462624
[2018-06-08 13:39:28       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9997665693048887
[2018-06-08 13:39:29       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.999900565962002
[2018-06-08 13:39:29       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9998207820106646
[2018-06-08 13:39:30       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999342326436816
[2018-06-08 13:39:31       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.999938376069499
[2018-06-08 13:39:31       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999470474852333
[2018-06-08 13:39:32       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999595678339456
[2018-06-08 13:39:32       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999681637007692
[2018-06-08 13:39:33       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999718160810701
[2018-06-08 13:39:34       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.999973845813746
[2018-06-08 13:39:34       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999718804217494
[2018-06-08 13:39:35       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999710697271857
[2018-06-08 13:39:35       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999760810427637
[2018-06-08 13:39:36       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999804152432061
[2018-06-08 13:39:37       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999784235331524
[2018-06-08 13:39:37       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999770035281967
[2018-06-08 13:39:38       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999811094718976
[2018-06-08 13:39:38       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999820810397807
[2018-06-08 13:39:39       Optimizer.py:524 -                       run()] Training manually interrupted
[2018-06-08 13:39:39       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:39:39       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:39:39       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:39:39       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_48.pickle"
[2018-06-08 13:39:39  start_training.py:129 -                      main()] Fidelity obtained: 0.9999836522572669
