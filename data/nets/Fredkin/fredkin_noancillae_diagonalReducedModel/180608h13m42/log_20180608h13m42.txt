[2018-06-08 13:42:17  start_training.py:140 -                  <module>()] Starting script
[2018-06-08 13:42:17  start_training.py: 73 -                      main()] We are going for a total of 50attempts.
[2018-06-08 13:42:17  start_training.py: 75 -                      main()] The following initial values will be used:[0, 1, 2, 3, 4].
[2018-06-08 13:42:20  start_training.py: 99 -                      main()] Starting training no.1
[2018-06-08 13:42:20  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 13:42:20    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:42:20    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:42:20    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:42:20    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:42:20           model.py:142 -       _set_initial_values()] Initial parameters values: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.].
[2018-06-08 13:42:20           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:42:20           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:42:20       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:42:20       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:42:20       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:42:20       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:42:20       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:42:20       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:42:20       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:42:20       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:42:20       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:42:20       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:42:33       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:42:33       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.2057865088257171
[2018-06-08 13:42:34       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.3755398742191414
[2018-06-08 13:42:35       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.27868940631089767
[2018-06-08 13:42:35       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.6528854343292181
[2018-06-08 13:42:36       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8521464915630649
[2018-06-08 13:42:37       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8486468275792476
[2018-06-08 13:42:37       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7758941033454118
[2018-06-08 13:42:38       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8131246134058884
[2018-06-08 13:42:39       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.7989164554830603
[2018-06-08 13:42:39       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.7357654092528948
[2018-06-08 13:42:40       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8342101226813388
[2018-06-08 13:42:41       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.7988271471059311
[2018-06-08 13:42:41       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8337655887455834
[2018-06-08 13:42:42       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8217691154586546
[2018-06-08 13:42:43       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.7099818860785007
[2018-06-08 13:42:43       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8052784914415926
[2018-06-08 13:42:44       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8665082108822787
[2018-06-08 13:42:45       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8386513315401413
[2018-06-08 13:42:45       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8495398873594611
[2018-06-08 13:42:46       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8121124883304042
[2018-06-08 13:42:46       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8580714858431436
[2018-06-08 13:42:47       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8683100766806058
[2018-06-08 13:42:48       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8600451398303035
[2018-06-08 13:42:48       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8599698993953254
[2018-06-08 13:42:49       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8518200144926676
[2018-06-08 13:42:50       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8305069280366649
[2018-06-08 13:42:50       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8150997115438033
[2018-06-08 13:42:51       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8506100632905249
[2018-06-08 13:42:52       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8479927260287846
[2018-06-08 13:42:53       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.863660348341805
[2018-06-08 13:42:54       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8345955999598245
[2018-06-08 13:42:55       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8591771166327756
[2018-06-08 13:42:56       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8555721966332382
[2018-06-08 13:42:57       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8371518470641461
[2018-06-08 13:42:57       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8615727583657394
[2018-06-08 13:42:58       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8609864979697066
[2018-06-08 13:42:59       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.861639238200739
[2018-06-08 13:42:59       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.870334250298934
[2018-06-08 13:43:00       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8607260336805825
[2018-06-08 13:43:01       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8573123538343046
[2018-06-08 13:43:01       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8581238756877148
[2018-06-08 13:43:02       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8674181678779099
[2018-06-08 13:43:03       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8682441563369254
[2018-06-08 13:43:03       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8662018101721458
[2018-06-08 13:43:04       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8673035230788757
[2018-06-08 13:43:05       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8648488542914321
[2018-06-08 13:43:05       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8474070946552851
[2018-06-08 13:43:06       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8709453252740665
[2018-06-08 13:43:07       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8696492752090986
[2018-06-08 13:43:08       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8572396681330221
[2018-06-08 13:43:08       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8665948509352767
[2018-06-08 13:43:09       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8657944263454764
[2018-06-08 13:43:10       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8675774665331517
[2018-06-08 13:43:10       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8620096088846442
[2018-06-08 13:43:11       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8613762429395685
[2018-06-08 13:43:12       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8669557796173857
[2018-06-08 13:43:12       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.851641518849557
[2018-06-08 13:43:13       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8651914147593057
[2018-06-08 13:43:14       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8648581962849556
[2018-06-08 13:43:14       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.871881580514888
[2018-06-08 13:43:15       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8501676672795138
[2018-06-08 13:43:15       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8680032464663254
[2018-06-08 13:43:16       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8599738961483644
[2018-06-08 13:43:17       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8609150240959695
[2018-06-08 13:43:17       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8603247703531145
[2018-06-08 13:43:18       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8718639658998957
[2018-06-08 13:43:19       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8518436331060388
[2018-06-08 13:43:19       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8676609111727802
[2018-06-08 13:43:20       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8526297647945964
[2018-06-08 13:43:20       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8655940091437998
[2018-06-08 13:43:21       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8692100650279913
[2018-06-08 13:43:22       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8614497944510685
[2018-06-08 13:43:22       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8684855009452643
[2018-06-08 13:43:23       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.85564402790279
[2018-06-08 13:43:24       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8604356780324597
[2018-06-08 13:43:24       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8600599430540388
[2018-06-08 13:43:25       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8673509747511373
[2018-06-08 13:43:26       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8691259131232494
[2018-06-08 13:43:26       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8664580340459413
[2018-06-08 13:43:27       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8611472848247019
[2018-06-08 13:43:27       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8636210082715909
[2018-06-08 13:43:28       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8673559332695331
[2018-06-08 13:43:29       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8575838905880256
[2018-06-08 13:43:29       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8608186502300584
[2018-06-08 13:43:30       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8710826749690687
[2018-06-08 13:43:31       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8684730077369643
[2018-06-08 13:43:31       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8703730958494081
[2018-06-08 13:43:32       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8724458849133402
[2018-06-08 13:43:32       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8708551893953268
[2018-06-08 13:43:33       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8673808759548224
[2018-06-08 13:43:34       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8702049904903945
[2018-06-08 13:43:34       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8567735421702666
[2018-06-08 13:43:35       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8644876854878286
[2018-06-08 13:43:36       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8672037336403204
[2018-06-08 13:43:36       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8708403169269804
[2018-06-08 13:43:37       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8669526896360756
[2018-06-08 13:43:37       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8687992453259082
[2018-06-08 13:43:38       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8689454425744688
[2018-06-08 13:43:39       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8718492495764284
[2018-06-08 13:43:39       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8598519069297956
[2018-06-08 13:43:39       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:43:39       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:43:39       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:43:39       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_1.pickle"
[2018-06-08 13:43:39  start_training.py:128 -                      main()] Fidelity obtained: 0.8586220016187563
[2018-06-08 13:43:41  start_training.py: 99 -                      main()] Starting training no.2
[2018-06-08 13:43:41  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 13:43:41    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:43:41    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:43:41    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:43:41    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:43:41           model.py:142 -       _set_initial_values()] Initial parameters values: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.].
[2018-06-08 13:43:41           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:43:41           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:43:41       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:43:41       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:43:41       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:43:41       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:43:41       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:43:41       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:43:41       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:43:41       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:43:41       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:43:42       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:43:45       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:43:46       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.49029224106604674
[2018-06-08 13:43:47       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.43804159863231135
[2018-06-08 13:43:48       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.41345851883094636
[2018-06-08 13:43:49       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7328841984067711
[2018-06-08 13:43:50       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8652870273208544
[2018-06-08 13:43:50       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.7835028428651603
[2018-06-08 13:43:51       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7225238935566237
[2018-06-08 13:43:52       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9973798036059252
[2018-06-08 13:43:52       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999898990164
[2018-06-08 13:43:53       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999999888
[2018-06-08 13:43:53       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999999999
[2018-06-08 13:43:54       Optimizer.py:490 -                      _run()]   Epoch no. 11: 1.0000000000000002
[2018-06-08 13:43:55       Optimizer.py:490 -                      _run()]   Epoch no. 12: 1.0
[2018-06-08 13:43:55       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:43:55       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:43:55       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:43:55       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:43:55       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_2.pickle"
[2018-06-08 13:43:55  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000002
[2018-06-08 13:43:58  start_training.py: 99 -                      main()] Starting training no.3
[2018-06-08 13:43:58  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 13:43:58    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:43:58    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:43:58    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:43:58    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:43:58           model.py:142 -       _set_initial_values()] Initial parameters values: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.].
[2018-06-08 13:43:58           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:43:58           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:43:58       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:43:58       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:43:58       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:43:58       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:43:58       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:43:58       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:43:58       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:43:58       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:43:58       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:43:58       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:44:02       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:44:03       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.4995594863171309
[2018-06-08 13:44:04       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.20537597341026723
[2018-06-08 13:44:05       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9651955634277372
[2018-06-08 13:44:06       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9934692147876123
[2018-06-08 13:44:07       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.988900834971766
[2018-06-08 13:44:07       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999938930343609
[2018-06-08 13:44:08       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999992006746811
[2018-06-08 13:44:09       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999997298021729
[2018-06-08 13:44:09       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999415156107
[2018-06-08 13:44:10       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999838448127
[2018-06-08 13:44:11       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999959010648
[2018-06-08 13:44:11       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.999999998735026
[2018-06-08 13:44:12       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999995801051
[2018-06-08 13:44:12       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999998339127
[2018-06-08 13:44:13       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.999999999932833
[2018-06-08 13:44:14       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999999779295
[2018-06-08 13:44:14       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999999874225
[2018-06-08 13:44:15       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999999956453
[2018-06-08 13:44:16       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999999976897
[2018-06-08 13:44:16       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999999990855
[2018-06-08 13:44:17       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999999994914
[2018-06-08 13:44:18       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999999997901
[2018-06-08 13:44:18       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999999998944
[2018-06-08 13:44:19       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999999999432
[2018-06-08 13:44:19       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.999999999999967
[2018-06-08 13:44:20       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999999999999843
[2018-06-08 13:44:21       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999999999925
[2018-06-08 13:44:21       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999999999961
[2018-06-08 13:44:22       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999999999984
[2018-06-08 13:44:22       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999999999999993
[2018-06-08 13:44:23       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999999999999999
[2018-06-08 13:44:24       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999999999999
[2018-06-08 13:44:24       Optimizer.py:490 -                      _run()]   Epoch no. 32: 1.0000000000000002
[2018-06-08 13:44:25       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999999999999
[2018-06-08 13:44:26       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999999999999999
[2018-06-08 13:44:26       Optimizer.py:490 -                      _run()]   Epoch no. 35: 1.0
[2018-06-08 13:44:26       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:44:26       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:44:26       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:44:26       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:44:26       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_3.pickle"
[2018-06-08 13:44:26  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:44:29  start_training.py: 99 -                      main()] Starting training no.4
[2018-06-08 13:44:29  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 13:44:29    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:44:29    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:44:29    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:44:29    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:44:29           model.py:142 -       _set_initial_values()] Initial parameters values: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.].
[2018-06-08 13:44:29           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:44:29           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:44:29       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:44:29       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:44:29       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:44:29       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:44:29       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:44:29       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:44:29       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:44:29       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:44:29       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:44:29       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:44:32       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:44:33       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.11592719768333097
[2018-06-08 13:44:34       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.24842239682315592
[2018-06-08 13:44:34       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9537148414787002
[2018-06-08 13:44:35       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999998495010898
[2018-06-08 13:44:36       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999999994
[2018-06-08 13:44:36       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999999999
[2018-06-08 13:44:37       Optimizer.py:490 -                      _run()]   Epoch no. 6: 1.0
[2018-06-08 13:44:37       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:44:37       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:44:37       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:44:37       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:44:37       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_4.pickle"
[2018-06-08 13:44:37  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:44:39  start_training.py: 99 -                      main()] Starting training no.5
[2018-06-08 13:44:39  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 13:44:39    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:44:39    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:44:39    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:44:39    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:44:39           model.py:142 -       _set_initial_values()] Initial parameters values: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.].
[2018-06-08 13:44:39           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:44:39           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:44:39       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:44:39       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:44:39       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:44:39       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:44:39       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:44:39       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:44:39       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:44:39       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:44:39       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:44:40       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:44:43       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:44:44       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.3106234743888503
[2018-06-08 13:44:45       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7282204704285989
[2018-06-08 13:44:45       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.5531445785909637
[2018-06-08 13:44:46       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.530194518646893
[2018-06-08 13:44:47       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9225170027206121
[2018-06-08 13:44:48       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9148181620614048
[2018-06-08 13:44:49       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9971759790675466
[2018-06-08 13:44:50       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9997196317626372
[2018-06-08 13:44:51       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9998313444528398
[2018-06-08 13:44:51       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999240123958946
[2018-06-08 13:44:52       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999712737139697
[2018-06-08 13:44:53       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999795569707297
[2018-06-08 13:44:53       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999754417607649
[2018-06-08 13:44:54       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999943253169795
[2018-06-08 13:44:54       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999969763365096
[2018-06-08 13:44:55       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999979443211435
[2018-06-08 13:44:56       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999978324739857
[2018-06-08 13:44:56       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999988653839076
[2018-06-08 13:44:57       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999994094586319
[2018-06-08 13:44:58       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999995770474466
[2018-06-08 13:44:58       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999997023963566
[2018-06-08 13:44:59       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.999999757668144
[2018-06-08 13:45:00       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999998032631554
[2018-06-08 13:45:00       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999998090098091
[2018-06-08 13:45:01       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999998804532352
[2018-06-08 13:45:02       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999999153868576
[2018-06-08 13:45:03       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999250595656
[2018-06-08 13:45:04       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999524477317
[2018-06-08 13:45:05       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999615367559
[2018-06-08 13:45:05       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999999694981756
[2018-06-08 13:45:06       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.999999972217847
[2018-06-08 13:45:07       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999804691491
[2018-06-08 13:45:07       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999999839769544
[2018-06-08 13:45:08       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999876586516
[2018-06-08 13:45:09       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999999895228214
[2018-06-08 13:45:10       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999904204132
[2018-06-08 13:45:10       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999920805042
[2018-06-08 13:45:11       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999999946166414
[2018-06-08 13:45:12       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999999945695827
[2018-06-08 13:45:12       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999961786727
[2018-06-08 13:45:13       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.999999996372211
[2018-06-08 13:45:14       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999999970676702
[2018-06-08 13:45:15       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999979206823
[2018-06-08 13:45:15       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999999982561909
[2018-06-08 13:45:16       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999999984316972
[2018-06-08 13:45:17       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999987996746
[2018-06-08 13:45:17       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999989723652
[2018-06-08 13:45:18       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999999990634035
[2018-06-08 13:45:19       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999999991938919
[2018-06-08 13:45:19       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999999993289274
[2018-06-08 13:45:20       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999999994377518
[2018-06-08 13:45:21       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999999994267216
[2018-06-08 13:45:21       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999999995124937
[2018-06-08 13:45:22       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.999999999624605
[2018-06-08 13:45:23       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999999996840022
[2018-06-08 13:45:24       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999999997238203
[2018-06-08 13:45:24       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999997590854
[2018-06-08 13:45:25       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999999997717357
[2018-06-08 13:45:26       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999999997986617
[2018-06-08 13:45:26       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999999998339321
[2018-06-08 13:45:27       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999999998611631
[2018-06-08 13:45:28       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999999998776442
[2018-06-08 13:45:28       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.999999999887307
[2018-06-08 13:45:29       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999999998939788
[2018-06-08 13:45:30       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.999999999906329
[2018-06-08 13:45:30       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999999999210659
[2018-06-08 13:45:31       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999999999306918
[2018-06-08 13:45:31       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999999999392147
[2018-06-08 13:45:32       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999999999451465
[2018-06-08 13:45:33       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999999999508817
[2018-06-08 13:45:33       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999999999543467
[2018-06-08 13:45:34       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999999999577109
[2018-06-08 13:45:35       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999999999658641
[2018-06-08 13:45:35       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.999999999965147
[2018-06-08 13:45:36       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999999999721995
[2018-06-08 13:45:37       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999999999737532
[2018-06-08 13:45:37       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999999999769575
[2018-06-08 13:45:38       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999999999790242
[2018-06-08 13:45:38       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999999999810602
[2018-06-08 13:45:39       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999999999823168
[2018-06-08 13:45:40       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999999999847451
[2018-06-08 13:45:40       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999999999864535
[2018-06-08 13:45:41       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999999999866648
[2018-06-08 13:45:42       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999999999882588
[2018-06-08 13:45:42       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999999999888028
[2018-06-08 13:45:43       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999999999901473
[2018-06-08 13:45:44       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999999999916674
[2018-06-08 13:45:44       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999999999921728
[2018-06-08 13:45:45       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999999999928646
[2018-06-08 13:45:46       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999999999929448
[2018-06-08 13:45:46       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999999999940087
[2018-06-08 13:45:47       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999999999946642
[2018-06-08 13:45:47       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999999999949716
[2018-06-08 13:45:48       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999999999954254
[2018-06-08 13:45:49       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999999999957406
[2018-06-08 13:45:49       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999999999958932
[2018-06-08 13:45:50       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999999999963869
[2018-06-08 13:45:51       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999999999965452
[2018-06-08 13:45:51       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999999999968882
[2018-06-08 13:45:52       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999999999971597
[2018-06-08 13:45:52       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:45:52       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:45:52       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:45:52       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_5.pickle"
[2018-06-08 13:45:52  start_training.py:128 -                      main()] Fidelity obtained: 0.9999999999972198
[2018-06-08 13:45:54  start_training.py: 99 -                      main()] Starting training no.6
[2018-06-08 13:45:54  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 13:45:54    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:45:54    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:45:54    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:45:54    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:45:54           model.py:142 -       _set_initial_values()] Initial parameters values: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.].
[2018-06-08 13:45:54           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:45:54           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:45:54       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:45:54       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:45:54       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:45:54       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:45:54       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:45:54       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:45:54       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:45:54       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:45:54       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:45:54       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:45:58       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:45:59       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.16264759337326018
[2018-06-08 13:46:00       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8829186052292971
[2018-06-08 13:46:01       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6893622495562797
[2018-06-08 13:46:02       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.898138147532275
[2018-06-08 13:46:03       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.6679747566747531
[2018-06-08 13:46:03       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8623537438090015
[2018-06-08 13:46:04       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.943262789555825
[2018-06-08 13:46:05       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9344492138787308
[2018-06-08 13:46:05       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9429443339258756
[2018-06-08 13:46:06       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8992764692181915
[2018-06-08 13:46:07       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9536430594965833
[2018-06-08 13:46:07       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9491492538449936
[2018-06-08 13:46:08       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9280440051150629
[2018-06-08 13:46:09       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9430736235377303
[2018-06-08 13:46:09       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9558506720457461
[2018-06-08 13:46:10       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9480834092421415
[2018-06-08 13:46:11       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9515638089412616
[2018-06-08 13:46:11       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.949970517754287
[2018-06-08 13:46:12       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9499628581447623
[2018-06-08 13:46:12       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9515969779978884
[2018-06-08 13:46:13       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9540793697346804
[2018-06-08 13:46:14       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9503330232526757
[2018-06-08 13:46:14       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9530229147480688
[2018-06-08 13:46:15       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9490644719028629
[2018-06-08 13:46:16       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9486367253339614
[2018-06-08 13:46:16       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9535132484655428
[2018-06-08 13:46:17       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.955288245124595
[2018-06-08 13:46:17       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9402815039259665
[2018-06-08 13:46:18       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9542100640484165
[2018-06-08 13:46:19       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9561197081941674
[2018-06-08 13:46:19       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9462275159618863
[2018-06-08 13:46:20       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9504409437714323
[2018-06-08 13:46:21       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9537277785428343
[2018-06-08 13:46:21       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9498709102638959
[2018-06-08 13:46:22       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9537123309566152
[2018-06-08 13:46:23       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9457445091605375
[2018-06-08 13:46:23       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9547890132040686
[2018-06-08 13:46:24       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9551577984196494
[2018-06-08 13:46:25       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9477681822326842
[2018-06-08 13:46:25       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9561675710912125
[2018-06-08 13:46:26       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9563962063427672
[2018-06-08 13:46:26       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9565581534382726
[2018-06-08 13:46:27       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9545656668383674
[2018-06-08 13:46:28       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9548015307895038
[2018-06-08 13:46:28       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9566300515242153
[2018-06-08 13:46:29       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.956602592600165
[2018-06-08 13:46:30       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9512883855024306
[2018-06-08 13:46:30       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9549512692619099
[2018-06-08 13:46:31       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9530614258924294
[2018-06-08 13:46:32       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9526813745135765
[2018-06-08 13:46:32       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9547187179162391
[2018-06-08 13:46:33       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9499517418276757
[2018-06-08 13:46:34       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9516306056567266
[2018-06-08 13:46:35       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9531784700564877
[2018-06-08 13:46:36       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.956587097207307
[2018-06-08 13:46:37       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9566442021088654
[2018-06-08 13:46:38       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.955888291362292
[2018-06-08 13:46:38       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9550962541250583
[2018-06-08 13:46:39       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9528506274310591
[2018-06-08 13:46:40       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9562517331869396
[2018-06-08 13:46:40       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9466381837043337
[2018-06-08 13:46:41       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9544344909770244
[2018-06-08 13:46:41       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9570950136215344
[2018-06-08 13:46:42       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9576693479964189
[2018-06-08 13:46:43       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9549007241115425
[2018-06-08 13:46:43       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9512200773425198
[2018-06-08 13:46:44       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9542473957845874
[2018-06-08 13:46:45       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9560735109099767
[2018-06-08 13:46:45       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9565421281622453
[2018-06-08 13:46:46       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9556449343898277
[2018-06-08 13:46:47       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9547800947405407
[2018-06-08 13:46:47       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9571719737766483
[2018-06-08 13:46:48       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9568959365058053
[2018-06-08 13:46:49       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9570387623591046
[2018-06-08 13:46:49       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9564522905962832
[2018-06-08 13:46:50       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9571581524389621
[2018-06-08 13:46:51       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9566888961679966
[2018-06-08 13:46:51       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9564204624245842
[2018-06-08 13:46:52       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9531969316891657
[2018-06-08 13:46:53       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9537619337500385
[2018-06-08 13:46:53       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9568397801702191
[2018-06-08 13:46:54       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.954661592665323
[2018-06-08 13:46:54       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9557273666568623
[2018-06-08 13:46:55       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9557899248264462
[2018-06-08 13:46:56       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9567104461661583
[2018-06-08 13:46:56       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9549701496052715
[2018-06-08 13:46:57       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9552279644560787
[2018-06-08 13:46:58       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9546333609918591
[2018-06-08 13:46:58       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9539304041278757
[2018-06-08 13:46:59       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.957446577294651
[2018-06-08 13:47:00       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9559767645865617
[2018-06-08 13:47:00       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9571786968655751
[2018-06-08 13:47:01       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9563613557190872
[2018-06-08 13:47:02       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9556097451351614
[2018-06-08 13:47:02       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9573000552989913
[2018-06-08 13:47:03       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9558942658594192
[2018-06-08 13:47:04       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9548259317128814
[2018-06-08 13:47:04       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9533840765375494
[2018-06-08 13:47:05       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.957244688816444
[2018-06-08 13:47:06       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9560108724125594
[2018-06-08 13:47:06       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:47:06       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:47:06       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:47:06       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_6.pickle"
[2018-06-08 13:47:06  start_training.py:128 -                      main()] Fidelity obtained: 0.9543335520357008
[2018-06-08 13:47:08  start_training.py: 99 -                      main()] Starting training no.7
[2018-06-08 13:47:08  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 13:47:08    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:47:08    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:47:08    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:47:08    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:47:08           model.py:142 -       _set_initial_values()] Initial parameters values: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.].
[2018-06-08 13:47:08           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:47:08           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:47:08       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:47:08       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:47:08       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:47:08       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:47:08       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:47:08       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:47:08       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:47:08       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:47:08       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:47:08       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:47:11       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:47:11       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.4208742998971246
[2018-06-08 13:47:12       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6131425714521174
[2018-06-08 13:47:13       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.32464051536299493
[2018-06-08 13:47:13       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.1283036280420665
[2018-06-08 13:47:14       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.11199297905302524
[2018-06-08 13:47:15       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.51058486656141
[2018-06-08 13:47:15       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.17779573579185282
[2018-06-08 13:47:16       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.7962101201680511
[2018-06-08 13:47:17       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9236683597958683
[2018-06-08 13:47:17       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9651821487354547
[2018-06-08 13:47:18       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.999985029884098
[2018-06-08 13:47:18       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9929617982244611
[2018-06-08 13:47:19       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999627824701552
[2018-06-08 13:47:20       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999525692951
[2018-06-08 13:47:20       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999999999205
[2018-06-08 13:47:21       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999999999996
[2018-06-08 13:47:21       Optimizer.py:490 -                      _run()]   Epoch no. 16: 1.0000000000000004
[2018-06-08 13:47:22       Optimizer.py:490 -                      _run()]   Epoch no. 17: 1.0
[2018-06-08 13:47:22       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:47:22       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:47:22       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:47:22       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:47:22       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_7.pickle"
[2018-06-08 13:47:22  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000004
[2018-06-08 13:47:24  start_training.py: 99 -                      main()] Starting training no.8
[2018-06-08 13:47:24  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 13:47:24    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:47:24    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:47:24    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:47:24    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:47:24           model.py:142 -       _set_initial_values()] Initial parameters values: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.].
[2018-06-08 13:47:24           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:47:24           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:47:24       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:47:24       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:47:24       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:47:24       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:47:24       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:47:24       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:47:24       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:47:24       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:47:24       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:47:24       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:47:27       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:47:28       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7996310637655634
[2018-06-08 13:47:29       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7378141475662132
[2018-06-08 13:47:29       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7206237118457212
[2018-06-08 13:47:30       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.3238056407037339
[2018-06-08 13:47:30       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.6758385792016962
[2018-06-08 13:47:31       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.7892729172365212
[2018-06-08 13:47:32       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7831458715696565
[2018-06-08 13:47:32       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8420254785311969
[2018-06-08 13:47:33       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.7772676219447742
[2018-06-08 13:47:33       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8550845418948606
[2018-06-08 13:47:34       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.832613064944648
[2018-06-08 13:47:35       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.7741787008870235
[2018-06-08 13:47:35       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.863884940055807
[2018-06-08 13:47:36       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8584095698825114
[2018-06-08 13:47:36       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.848697897640847
[2018-06-08 13:47:37       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8546212473281602
[2018-06-08 13:47:37       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8375991570320699
[2018-06-08 13:47:38       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8435638157551649
[2018-06-08 13:47:39       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8577516149049538
[2018-06-08 13:47:39       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8472632059681725
[2018-06-08 13:47:40       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8441274919214483
[2018-06-08 13:47:41       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8629354960110076
[2018-06-08 13:47:41       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8622472005674487
[2018-06-08 13:47:42       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8615499467310072
[2018-06-08 13:47:43       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8432306844923398
[2018-06-08 13:47:43       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8573456567609701
[2018-06-08 13:47:44       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8500428637253311
[2018-06-08 13:47:44       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8582427514541793
[2018-06-08 13:47:45       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8460746036111785
[2018-06-08 13:47:46       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8499697641368564
[2018-06-08 13:47:46       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8549087040848087
[2018-06-08 13:47:47       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8300801087196906
[2018-06-08 13:47:48       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8674175861351376
[2018-06-08 13:47:48       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8559222331789698
[2018-06-08 13:47:49       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8569481197944044
[2018-06-08 13:47:49       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8680172694146522
[2018-06-08 13:47:50       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8556814174186854
[2018-06-08 13:47:51       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8473543352420502
[2018-06-08 13:47:51       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8591827044757108
[2018-06-08 13:47:52       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8662355022442604
[2018-06-08 13:47:53       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8667926444856938
[2018-06-08 13:47:53       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8624341162929748
[2018-06-08 13:47:54       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8672547138456269
[2018-06-08 13:47:55       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8629928128125173
[2018-06-08 13:47:55       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8705571374552394
[2018-06-08 13:47:56       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8644925377003974
[2018-06-08 13:47:56       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8578619090166449
[2018-06-08 13:47:57       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8640076320833079
[2018-06-08 13:47:58       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8621250865787463
[2018-06-08 13:47:58       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8702883878619696
[2018-06-08 13:47:59       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8678862431139016
[2018-06-08 13:48:00       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8622384485737737
[2018-06-08 13:48:00       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8647215974620681
[2018-06-08 13:48:01       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8687156469061658
[2018-06-08 13:48:02       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8677851174539178
[2018-06-08 13:48:02       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8657248159856152
[2018-06-08 13:48:03       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.859960996897308
[2018-06-08 13:48:04       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.86631056027704
[2018-06-08 13:48:04       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8653959469218635
[2018-06-08 13:48:05       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8626485659929759
[2018-06-08 13:48:05       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8704670082553632
[2018-06-08 13:48:06       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8628088752780794
[2018-06-08 13:48:07       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8691776012928081
[2018-06-08 13:48:07       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8682021901990666
[2018-06-08 13:48:08       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8621838608091826
[2018-06-08 13:48:09       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8617596317755009
[2018-06-08 13:48:09       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8581568295858196
[2018-06-08 13:48:10       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8672104714116006
[2018-06-08 13:48:11       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8557866775792766
[2018-06-08 13:48:11       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8698416366469957
[2018-06-08 13:48:12       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8667299894854028
[2018-06-08 13:48:13       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8630113036818711
[2018-06-08 13:48:13       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8679911510821462
[2018-06-08 13:48:14       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8699059974543798
[2018-06-08 13:48:15       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8661058793083002
[2018-06-08 13:48:15       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8693343399123253
[2018-06-08 13:48:16       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8647123643926862
[2018-06-08 13:48:16       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8641420652812474
[2018-06-08 13:48:17       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8623532672719688
[2018-06-08 13:48:18       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8682617008216017
[2018-06-08 13:48:18       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8677648787234179
[2018-06-08 13:48:19       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8658922993065211
[2018-06-08 13:48:20       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8544981765983745
[2018-06-08 13:48:20       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.865279386451015
[2018-06-08 13:48:21       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8648722171846984
[2018-06-08 13:48:22       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8636325334017724
[2018-06-08 13:48:22       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8682477094052874
[2018-06-08 13:48:23       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8696258902582338
[2018-06-08 13:48:23       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8660902806952813
[2018-06-08 13:48:24       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8686270050770932
[2018-06-08 13:48:25       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8537482775171253
[2018-06-08 13:48:25       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8674916573058902
[2018-06-08 13:48:26       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8695971908778514
[2018-06-08 13:48:27       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8697385951723478
[2018-06-08 13:48:27       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8701810904870679
[2018-06-08 13:48:28       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8674647205278503
[2018-06-08 13:48:28       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8703463547396743
[2018-06-08 13:48:29       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8679986802492337
[2018-06-08 13:48:30       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8697517294341378
[2018-06-08 13:48:30       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8651741186958758
[2018-06-08 13:48:30       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:48:30       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:48:30       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:48:30       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_8.pickle"
[2018-06-08 13:48:30  start_training.py:128 -                      main()] Fidelity obtained: 0.8639698915261906
[2018-06-08 13:48:32  start_training.py: 99 -                      main()] Starting training no.9
[2018-06-08 13:48:32  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 13:48:32    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:48:32    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:48:32    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:48:32    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:48:32           model.py:142 -       _set_initial_values()] Initial parameters values: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.].
[2018-06-08 13:48:32           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:48:32           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:48:32       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:48:32       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:48:32       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:48:32       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:48:32       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:48:32       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:48:32       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:48:32       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:48:32       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:48:33       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:48:36       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:48:37       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7409334394633362
[2018-06-08 13:48:38       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.727369920158657
[2018-06-08 13:48:39       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7093499555040067
[2018-06-08 13:48:40       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8147001628268568
[2018-06-08 13:48:41       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7945307683529146
[2018-06-08 13:48:42       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.5846272323785743
[2018-06-08 13:48:42       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7638605069814887
[2018-06-08 13:48:43       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8121463566623178
[2018-06-08 13:48:44       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.7266632972342717
[2018-06-08 13:48:44       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8380973404136328
[2018-06-08 13:48:45       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8287927331455492
[2018-06-08 13:48:46       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.798324012069599
[2018-06-08 13:48:46       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8165957701229248
[2018-06-08 13:48:47       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8243363362718332
[2018-06-08 13:48:47       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8475718097654453
[2018-06-08 13:48:48       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.789721164603128
[2018-06-08 13:48:49       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8367123975164915
[2018-06-08 13:48:49       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8439946177033114
[2018-06-08 13:48:50       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.840150124302435
[2018-06-08 13:48:50       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8576394813102769
[2018-06-08 13:48:51       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8344586013571016
[2018-06-08 13:48:51       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8428957375045488
[2018-06-08 13:48:52       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8323948215673314
[2018-06-08 13:48:53       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8278653545396043
[2018-06-08 13:48:53       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8476077175692031
[2018-06-08 13:48:54       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8474778741800233
[2018-06-08 13:48:54       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8519297589103003
[2018-06-08 13:48:55       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8540745515544821
[2018-06-08 13:48:56       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8347142652175205
[2018-06-08 13:48:56       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8553541935534562
[2018-06-08 13:48:57       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8485545201554947
[2018-06-08 13:48:57       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8211652111330555
[2018-06-08 13:48:58       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8141311811961855
[2018-06-08 13:48:58       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.855042519771911
[2018-06-08 13:48:59       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8351844575586029
[2018-06-08 13:49:00       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8372070942228221
[2018-06-08 13:49:00       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8406475681727348
[2018-06-08 13:49:01       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8588395850107159
[2018-06-08 13:49:01       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8375494133895645
[2018-06-08 13:49:02       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8513299722047517
[2018-06-08 13:49:02       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8662892577724527
[2018-06-08 13:49:03       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.851382417650204
[2018-06-08 13:49:04       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8477713444515595
[2018-06-08 13:49:04       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8465179231125624
[2018-06-08 13:49:05       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8613622458805977
[2018-06-08 13:49:05       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8442327159399862
[2018-06-08 13:49:06       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8532174313722942
[2018-06-08 13:49:07       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8470323243837871
[2018-06-08 13:49:07       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8510199844306345
[2018-06-08 13:49:08       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8517357066721751
[2018-06-08 13:49:08       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8550249223410057
[2018-06-08 13:49:09       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8606555250464651
[2018-06-08 13:49:10       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8655077862104664
[2018-06-08 13:49:10       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8555600423386075
[2018-06-08 13:49:11       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.86398456728854
[2018-06-08 13:49:12       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8560270694875762
[2018-06-08 13:49:12       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8605934757063474
[2018-06-08 13:49:13       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8535327445815513
[2018-06-08 13:49:13       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8599972686136309
[2018-06-08 13:49:14       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8480973274540388
[2018-06-08 13:49:15       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8581004921148377
[2018-06-08 13:49:15       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8541658111508089
[2018-06-08 13:49:16       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8657335182508105
[2018-06-08 13:49:17       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8529656911466652
[2018-06-08 13:49:17       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8578072172968308
[2018-06-08 13:49:18       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.858024344110886
[2018-06-08 13:49:18       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8533878174562481
[2018-06-08 13:49:19       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8468579427102024
[2018-06-08 13:49:20       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8550600680292016
[2018-06-08 13:49:20       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8626247425611626
[2018-06-08 13:49:21       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8456444404540093
[2018-06-08 13:49:22       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.845985278637631
[2018-06-08 13:49:22       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8583749322808453
[2018-06-08 13:49:23       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8540114467562918
[2018-06-08 13:49:23       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8475446993680097
[2018-06-08 13:49:24       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8626365161304393
[2018-06-08 13:49:25       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8644488359969315
[2018-06-08 13:49:25       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8572757197993452
[2018-06-08 13:49:26       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8610756118534626
[2018-06-08 13:49:27       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8362460971046292
[2018-06-08 13:49:27       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8519353792375584
[2018-06-08 13:49:28       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8638213212036693
[2018-06-08 13:49:28       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.862114566239232
[2018-06-08 13:49:29       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8608152896913372
[2018-06-08 13:49:30       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8511670316783363
[2018-06-08 13:49:30       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8615719503401589
[2018-06-08 13:49:31       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8611774153143742
[2018-06-08 13:49:32       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8627891059514421
[2018-06-08 13:49:32       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8588478623044584
[2018-06-08 13:49:33       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8598822947599597
[2018-06-08 13:49:34       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8625773980148936
[2018-06-08 13:49:34       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8619107272796905
[2018-06-08 13:49:35       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8481939115574572
[2018-06-08 13:49:36       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.8618349633889426
[2018-06-08 13:49:36       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8612809217262327
[2018-06-08 13:49:37       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8546611335539027
[2018-06-08 13:49:37       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8634154123836776
[2018-06-08 13:49:38       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8595101594152785
[2018-06-08 13:49:39       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8580466788287581
[2018-06-08 13:49:39       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8593232692146799
[2018-06-08 13:49:39       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:49:39       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:49:39       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:49:39       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_9.pickle"
[2018-06-08 13:49:39  start_training.py:128 -                      main()] Fidelity obtained: 0.8606579730472529
[2018-06-08 13:49:41  start_training.py: 99 -                      main()] Starting training no.10
[2018-06-08 13:49:41  start_training.py:100 -                      main()] Initial values: 0.
[2018-06-08 13:49:41    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:49:41    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:49:41    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:49:41    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:49:41           model.py:142 -       _set_initial_values()] Initial parameters values: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.].
[2018-06-08 13:49:41           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:49:41           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:49:41       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:49:41       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:49:41       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:49:41       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:49:41       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:49:41       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:49:41       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:49:41       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:49:41       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:49:42       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:49:45       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:49:46       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.19192470702450837
[2018-06-08 13:49:46       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.3325112996168071
[2018-06-08 13:49:47       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.529110435633387
[2018-06-08 13:49:48       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.6964668216492887
[2018-06-08 13:49:48       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.1562331742806366
[2018-06-08 13:49:49       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.6685251981859389
[2018-06-08 13:49:50       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8340677023806071
[2018-06-08 13:49:50       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.34555989394540404
[2018-06-08 13:49:51       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.617744239370707
[2018-06-08 13:49:51       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.680138190717205
[2018-06-08 13:49:52       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.6908758984551662
[2018-06-08 13:49:53       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.7421394233480855
[2018-06-08 13:49:53       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8060474210979116
[2018-06-08 13:49:54       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8337173376493361
[2018-06-08 13:49:54       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.979144083456847
[2018-06-08 13:49:55       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9961814625970729
[2018-06-08 13:49:56       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.999999998030017
[2018-06-08 13:49:56       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999999999732
[2018-06-08 13:49:57       Optimizer.py:490 -                      _run()]   Epoch no. 18: 1.0000000000000007
[2018-06-08 13:49:57       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999999999999
[2018-06-08 13:49:58       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999999999999
[2018-06-08 13:49:58       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999999999999
[2018-06-08 13:49:59       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999999999999
[2018-06-08 13:50:00       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999999999999
[2018-06-08 13:50:00       Optimizer.py:490 -                      _run()]   Epoch no. 24: 1.0
[2018-06-08 13:50:00       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:50:00       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:50:00       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:50:00       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:50:00       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_10.pickle"
[2018-06-08 13:50:00  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000004
[2018-06-08 13:50:02  start_training.py: 99 -                      main()] Starting training no.11
[2018-06-08 13:50:02  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 13:50:02    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:50:02    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:50:02    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:50:02    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:50:03           model.py:142 -       _set_initial_values()] Initial parameters values: [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.].
[2018-06-08 13:50:03           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:50:03           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:50:03       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:50:03       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:50:03       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:50:03       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:50:03       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:50:03       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:50:03       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:50:03       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:50:03       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:50:03       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:50:06       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:50:07       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7694960579305523
[2018-06-08 13:50:07       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7063364186232222
[2018-06-08 13:50:08       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9239770888486954
[2018-06-08 13:50:09       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9964235240413835
[2018-06-08 13:50:09       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999182257461178
[2018-06-08 13:50:10       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999670270343941
[2018-06-08 13:50:11       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999840211283173
[2018-06-08 13:50:11       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999791887716687
[2018-06-08 13:50:12       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999749999393778
[2018-06-08 13:50:13       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.999985994165023
[2018-06-08 13:50:13       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999882376487205
[2018-06-08 13:50:14       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999893672675069
[2018-06-08 13:50:15       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999896458864661
[2018-06-08 13:50:15       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999893889233856
[2018-06-08 13:50:16       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999908893922586
[2018-06-08 13:50:17       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999916536219328
[2018-06-08 13:50:17       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999916704241766
[2018-06-08 13:50:18       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999918615840593
[2018-06-08 13:50:19       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999927303331059
[2018-06-08 13:50:19       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.999992674328088
[2018-06-08 13:50:20       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999932089615797
[2018-06-08 13:50:21       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.999992952005046
[2018-06-08 13:50:21       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999941969015436
[2018-06-08 13:50:22       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999940818118739
[2018-06-08 13:50:23       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999945139305672
[2018-06-08 13:50:23       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999947042872916
[2018-06-08 13:50:24       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999947360663057
[2018-06-08 13:50:24       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999946487385294
[2018-06-08 13:50:25       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999951044092069
[2018-06-08 13:50:26       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999952134249765
[2018-06-08 13:50:26       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999957552118792
[2018-06-08 13:50:27       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999955818134042
[2018-06-08 13:50:28       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999959416628021
[2018-06-08 13:50:28       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.99999604200074
[2018-06-08 13:50:29       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999961953458544
[2018-06-08 13:50:29       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999964054332818
[2018-06-08 13:50:30       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999960791840031
[2018-06-08 13:50:31       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999965977567927
[2018-06-08 13:50:31       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999965063749805
[2018-06-08 13:50:32       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999967330564629
[2018-06-08 13:50:32       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999968484887611
[2018-06-08 13:50:33       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.999996512614003
[2018-06-08 13:50:34       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999965827661162
[2018-06-08 13:50:34       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999971152305044
[2018-06-08 13:50:35       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999965339695187
[2018-06-08 13:50:36       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999972829639749
[2018-06-08 13:50:36       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999972918419385
[2018-06-08 13:50:37       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999972982515507
[2018-06-08 13:50:38       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999973779994674
[2018-06-08 13:50:38       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999975876612538
[2018-06-08 13:50:39       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999973249212739
[2018-06-08 13:50:40       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999976389685971
[2018-06-08 13:50:41       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999977547939168
[2018-06-08 13:50:42       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999977866682802
[2018-06-08 13:50:43       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999978113676522
[2018-06-08 13:50:43       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999978188521625
[2018-06-08 13:50:44       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999978745806429
[2018-06-08 13:50:44       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999979486432902
[2018-06-08 13:50:45       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999980194863763
[2018-06-08 13:50:46       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999979569716656
[2018-06-08 13:50:46       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999980263092394
[2018-06-08 13:50:47       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999981636541739
[2018-06-08 13:50:47       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999982165625855
[2018-06-08 13:50:48       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999982439074541
[2018-06-08 13:50:49       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999982467868205
[2018-06-08 13:50:49       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999983174696658
[2018-06-08 13:50:50       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999983127642771
[2018-06-08 13:50:50       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999983037168653
[2018-06-08 13:50:51       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999984076653025
[2018-06-08 13:50:52       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999984512634055
[2018-06-08 13:50:53       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999984793488715
[2018-06-08 13:50:53       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999983305254304
[2018-06-08 13:50:54       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.999998537717895
[2018-06-08 13:50:54       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999985146264527
[2018-06-08 13:50:55       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999985626825443
[2018-06-08 13:50:56       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999986033601473
[2018-06-08 13:50:56       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999986076678415
[2018-06-08 13:50:57       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999986749646484
[2018-06-08 13:50:57       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999986796697412
[2018-06-08 13:50:58       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.99999870739476
[2018-06-08 13:50:59       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999986934066031
[2018-06-08 13:50:59       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.999998696653703
[2018-06-08 13:51:00       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999987653299182
[2018-06-08 13:51:01       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999988012887584
[2018-06-08 13:51:01       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999988232112632
[2018-06-08 13:51:02       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999988253831834
[2018-06-08 13:51:02       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999988314122562
[2018-06-08 13:51:03       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999988606304758
[2018-06-08 13:51:04       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999988905795263
[2018-06-08 13:51:04       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999988867466761
[2018-06-08 13:51:05       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999989075511421
[2018-06-08 13:51:05       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999989342380116
[2018-06-08 13:51:06       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999989014947623
[2018-06-08 13:51:07       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999989083451681
[2018-06-08 13:51:07       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999989418497832
[2018-06-08 13:51:08       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999990092777695
[2018-06-08 13:51:09       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999989733961614
[2018-06-08 13:51:09       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999990387210052
[2018-06-08 13:51:10       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999990394669743
[2018-06-08 13:51:10       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999990337697899
[2018-06-08 13:51:10       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:51:10       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:51:10       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:51:10       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_11.pickle"
[2018-06-08 13:51:10  start_training.py:128 -                      main()] Fidelity obtained: 0.9999990459071699
[2018-06-08 13:51:12  start_training.py: 99 -                      main()] Starting training no.12
[2018-06-08 13:51:12  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 13:51:12    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:51:12    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:51:12    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:51:12    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:51:12           model.py:142 -       _set_initial_values()] Initial parameters values: [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.].
[2018-06-08 13:51:12           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:51:12           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:51:12       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:51:12       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:51:12       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:51:12       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:51:12       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:51:12       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:51:12       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:51:13       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:51:13       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:51:13       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:51:16       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:51:17       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5222285968390321
[2018-06-08 13:51:18       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.21032383550731162
[2018-06-08 13:51:18       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.15449850642930552
[2018-06-08 13:51:19       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.3485090027342694
[2018-06-08 13:51:19       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.1545414346555758
[2018-06-08 13:51:20       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8754378194982535
[2018-06-08 13:51:21       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9072600763267487
[2018-06-08 13:51:21       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9788319606708914
[2018-06-08 13:51:22       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9998313214264439
[2018-06-08 13:51:23       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999910368754
[2018-06-08 13:51:23       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999999999
[2018-06-08 13:51:24       Optimizer.py:490 -                      _run()]   Epoch no. 11: 1.0
[2018-06-08 13:51:24       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:51:24       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:51:24       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:51:24       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:51:24       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_12.pickle"
[2018-06-08 13:51:24  start_training.py:128 -                      main()] Fidelity obtained: 0.999999999999999
[2018-06-08 13:51:27  start_training.py: 99 -                      main()] Starting training no.13
[2018-06-08 13:51:27  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 13:51:27    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:51:27    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:51:27    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:51:27    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:51:27           model.py:142 -       _set_initial_values()] Initial parameters values: [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.].
[2018-06-08 13:51:27           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:51:27           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:51:27       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:51:27       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:51:27       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:51:27       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:51:27       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:51:27       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:51:27       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:51:28       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:51:28       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:51:28       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:51:32       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:51:33       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8262810187316048
[2018-06-08 13:51:33       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6466380189828529
[2018-06-08 13:51:34       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.754911417079261
[2018-06-08 13:51:35       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8155852266720583
[2018-06-08 13:51:36       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7913673872426642
[2018-06-08 13:51:36       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8285552795890466
[2018-06-08 13:51:37       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.8813807512378914
[2018-06-08 13:51:37       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8673108759762806
[2018-06-08 13:51:38       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8821905858862245
[2018-06-08 13:51:39       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8827075416672769
[2018-06-08 13:51:39       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8618096862690267
[2018-06-08 13:51:40       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8902722870454712
[2018-06-08 13:51:40       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8986451530866425
[2018-06-08 13:51:41       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8662787258754945
[2018-06-08 13:51:42       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9000878935297907
[2018-06-08 13:51:43       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8959953217174204
[2018-06-08 13:51:44       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.886309457722015
[2018-06-08 13:51:45       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8879169061119024
[2018-06-08 13:51:46       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.886057874673637
[2018-06-08 13:51:47       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.896321038087282
[2018-06-08 13:51:48       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8932793653045108
[2018-06-08 13:51:48       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.884549265848029
[2018-06-08 13:51:49       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8904688605981624
[2018-06-08 13:51:50       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8836201860106508
[2018-06-08 13:51:50       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.902394561039777
[2018-06-08 13:51:51       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8948025983687043
[2018-06-08 13:51:52       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8742499476284848
[2018-06-08 13:51:52       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8978914962538456
[2018-06-08 13:51:53       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9012016185791357
[2018-06-08 13:51:53       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9043261770805764
[2018-06-08 13:51:54       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8757859859991508
[2018-06-08 13:51:55       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8943728292910821
[2018-06-08 13:51:55       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8982139062816965
[2018-06-08 13:51:56       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.896055847946185
[2018-06-08 13:51:57       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8942868147145595
[2018-06-08 13:51:57       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8966695571963846
[2018-06-08 13:51:58       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8930220455691152
[2018-06-08 13:51:59       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9010160748207476
[2018-06-08 13:51:59       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9037131819250444
[2018-06-08 13:52:00       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8967956688669604
[2018-06-08 13:52:01       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.89844573014217
[2018-06-08 13:52:01       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9046826831872941
[2018-06-08 13:52:02       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9038698719678747
[2018-06-08 13:52:03       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8987914963169371
[2018-06-08 13:52:03       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8959299945377996
[2018-06-08 13:52:04       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9024179195837837
[2018-06-08 13:52:05       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9034732856176971
[2018-06-08 13:52:05       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8968879746341691
[2018-06-08 13:52:06       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9041077435246706
[2018-06-08 13:52:07       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8993440084300335
[2018-06-08 13:52:07       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.894039340724889
[2018-06-08 13:52:08       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9024338177866601
[2018-06-08 13:52:09       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9064082407569007
[2018-06-08 13:52:09       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8939737747614296
[2018-06-08 13:52:10       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9027735968790309
[2018-06-08 13:52:10       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9021266235524176
[2018-06-08 13:52:11       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.905819381420494
[2018-06-08 13:52:12       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.903132034794935
[2018-06-08 13:52:12       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9029576434298899
[2018-06-08 13:52:13       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9002596971191744
[2018-06-08 13:52:13       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8957828445481664
[2018-06-08 13:52:14       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8979688634239897
[2018-06-08 13:52:15       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9026462123842157
[2018-06-08 13:52:15       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.898201801769587
[2018-06-08 13:52:16       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9052328674279819
[2018-06-08 13:52:17       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8888432813998037
[2018-06-08 13:52:17       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9059016915702263
[2018-06-08 13:52:18       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9026109869630708
[2018-06-08 13:52:18       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9056756221727308
[2018-06-08 13:52:19       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9049315021591616
[2018-06-08 13:52:20       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9031064533490891
[2018-06-08 13:52:20       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8939122232865977
[2018-06-08 13:52:21       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9007255972608028
[2018-06-08 13:52:22       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9015274154663103
[2018-06-08 13:52:22       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9016686481380667
[2018-06-08 13:52:23       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.901303313119831
[2018-06-08 13:52:24       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9022919761111023
[2018-06-08 13:52:24       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8996541018030686
[2018-06-08 13:52:25       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9056521083488718
[2018-06-08 13:52:25       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9043104301896644
[2018-06-08 13:52:26       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9059113060911858
[2018-06-08 13:52:27       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9056416067400073
[2018-06-08 13:52:27       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9003836724212895
[2018-06-08 13:52:28       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9020695436457964
[2018-06-08 13:52:29       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9039513353054162
[2018-06-08 13:52:29       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8960799409564533
[2018-06-08 13:52:30       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9055480550287441
[2018-06-08 13:52:30       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9013903271270516
[2018-06-08 13:52:31       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9054735869071803
[2018-06-08 13:52:32       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8990502731568752
[2018-06-08 13:52:32       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9047393752119666
[2018-06-08 13:52:33       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9035599435661242
[2018-06-08 13:52:34       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9042222093145902
[2018-06-08 13:52:35       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9045798239460993
[2018-06-08 13:52:35       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9009530737009819
[2018-06-08 13:52:36       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9041910721683962
[2018-06-08 13:52:37       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9036627065021321
[2018-06-08 13:52:37       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9058490448033308
[2018-06-08 13:52:38       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9037926690070265
[2018-06-08 13:52:38       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9063403335290654
[2018-06-08 13:52:38       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:52:38       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:52:38       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:52:38       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_13.pickle"
[2018-06-08 13:52:38  start_training.py:128 -                      main()] Fidelity obtained: 0.9061182825613568
[2018-06-08 13:52:40  start_training.py: 99 -                      main()] Starting training no.14
[2018-06-08 13:52:40  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 13:52:40    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:52:40    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:52:40    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:52:40    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:52:40           model.py:142 -       _set_initial_values()] Initial parameters values: [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.].
[2018-06-08 13:52:41           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:52:41           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:52:41       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:52:41       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:52:41       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:52:41       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:52:41       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:52:41       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:52:41       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:52:41       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:52:41       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:52:41       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:52:45       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:52:45       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5968980986209685
[2018-06-08 13:52:46       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7997094221332778
[2018-06-08 13:52:47       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9592427074074077
[2018-06-08 13:52:48       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.44479922283847545
[2018-06-08 13:52:48       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9906595239776357
[2018-06-08 13:52:49       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.996760753598102
[2018-06-08 13:52:49       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9979501816666708
[2018-06-08 13:52:50       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9956482935832749
[2018-06-08 13:52:51       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9977158892387459
[2018-06-08 13:52:51       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9977410155891516
[2018-06-08 13:52:52       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9987825964206662
[2018-06-08 13:52:53       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9989979680581383
[2018-06-08 13:52:53       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9988109651080572
[2018-06-08 13:52:54       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9986424527636931
[2018-06-08 13:52:55       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9983791150724189
[2018-06-08 13:52:55       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.998951372681372
[2018-06-08 13:52:56       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9990905633156217
[2018-06-08 13:52:57       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9988493389224838
[2018-06-08 13:52:57       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.998892710226097
[2018-06-08 13:52:58       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9985321837510555
[2018-06-08 13:52:59       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9988645500461079
[2018-06-08 13:53:00       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9989430068734005
[2018-06-08 13:53:00       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.99904897046779
[2018-06-08 13:53:01       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9991811113334623
[2018-06-08 13:53:01       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9991456022897657
[2018-06-08 13:53:02       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9991395442981456
[2018-06-08 13:53:03       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9990901637002119
[2018-06-08 13:53:03       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9988619101472378
[2018-06-08 13:53:04       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9991151003547887
[2018-06-08 13:53:05       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9991714889311837
[2018-06-08 13:53:05       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.999104967458259
[2018-06-08 13:53:06       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9988746780812106
[2018-06-08 13:53:07       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9989484617950997
[2018-06-08 13:53:07       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9990274481647939
[2018-06-08 13:53:08       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9991253321949519
[2018-06-08 13:53:09       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9991235411291933
[2018-06-08 13:53:09       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9991514602628055
[2018-06-08 13:53:10       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9991077736630993
[2018-06-08 13:53:11       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9991275510962565
[2018-06-08 13:53:11       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9991534869545617
[2018-06-08 13:53:12       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9989856736886417
[2018-06-08 13:53:13       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9991378496742097
[2018-06-08 13:53:13       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9991132677522633
[2018-06-08 13:53:14       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9991151844265886
[2018-06-08 13:53:15       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9991819317046855
[2018-06-08 13:53:15       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9990084014899415
[2018-06-08 13:53:16       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9991672968816515
[2018-06-08 13:53:16       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9989961121418018
[2018-06-08 13:53:17       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9989826582016942
[2018-06-08 13:53:18       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9991032622862683
[2018-06-08 13:53:18       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9990466545909514
[2018-06-08 13:53:19       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9990962540939478
[2018-06-08 13:53:20       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9991211103036401
[2018-06-08 13:53:20       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9990325995706724
[2018-06-08 13:53:21       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9990610307625398
[2018-06-08 13:53:21       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9990690823483719
[2018-06-08 13:53:22       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9989734861659398
[2018-06-08 13:53:23       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9991401742708378
[2018-06-08 13:53:23       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9991496007650631
[2018-06-08 13:53:24       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9991200117685082
[2018-06-08 13:53:25       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9991574925944127
[2018-06-08 13:53:25       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9991505948592946
[2018-06-08 13:53:26       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9990865146760551
[2018-06-08 13:53:26       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9991162253528435
[2018-06-08 13:53:27       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.999145239585771
[2018-06-08 13:53:28       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9991652573593156
[2018-06-08 13:53:28       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9991294726811152
[2018-06-08 13:53:29       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.999104133729782
[2018-06-08 13:53:30       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9990838918471557
[2018-06-08 13:53:30       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9991287639717855
[2018-06-08 13:53:31       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9991775495843165
[2018-06-08 13:53:31       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9991005546937237
[2018-06-08 13:53:32       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.999105967768595
[2018-06-08 13:53:33       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9990939900149539
[2018-06-08 13:53:33       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.999048451699002
[2018-06-08 13:53:34       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9991541257890095
[2018-06-08 13:53:35       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9991772426234966
[2018-06-08 13:53:35       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9991818954772107
[2018-06-08 13:53:36       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9991207547529022
[2018-06-08 13:53:36       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9991362480143223
[2018-06-08 13:53:37       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9991758560375997
[2018-06-08 13:53:38       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9991640056303794
[2018-06-08 13:53:38       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9991663862048321
[2018-06-08 13:53:39       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9991666390736593
[2018-06-08 13:53:40       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9991494148944318
[2018-06-08 13:53:40       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9991618235341043
[2018-06-08 13:53:41       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9991823540977554
[2018-06-08 13:53:41       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9991222474766182
[2018-06-08 13:53:42       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9991893365715916
[2018-06-08 13:53:43       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.999161702635382
[2018-06-08 13:53:43       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9991524837227103
[2018-06-08 13:53:44       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9991671941164103
[2018-06-08 13:53:45       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9990672578550249
[2018-06-08 13:53:45       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9991520406962222
[2018-06-08 13:53:46       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9991766681691137
[2018-06-08 13:53:47       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9991570121839116
[2018-06-08 13:53:47       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9991347161663272
[2018-06-08 13:53:48       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9991860096925593
[2018-06-08 13:53:49       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9991178510787374
[2018-06-08 13:53:50       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9991798169981142
[2018-06-08 13:53:50       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:53:50       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:53:50       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:53:50       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_14.pickle"
[2018-06-08 13:53:50  start_training.py:128 -                      main()] Fidelity obtained: 0.9991544600908536
[2018-06-08 13:53:52  start_training.py: 99 -                      main()] Starting training no.15
[2018-06-08 13:53:52  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 13:53:52    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:53:52    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:53:52    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:53:52    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:53:52           model.py:142 -       _set_initial_values()] Initial parameters values: [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.].
[2018-06-08 13:53:52           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:53:52           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:53:52       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:53:52       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:53:52       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:53:52       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:53:52       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:53:52       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:53:52       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:53:52       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:53:52       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:53:52       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:53:56       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:53:57       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.681216951701566
[2018-06-08 13:53:58       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.22614424203492095
[2018-06-08 13:53:59       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6891869294651467
[2018-06-08 13:54:00       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.6093258073288927
[2018-06-08 13:54:00       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7607293065098297
[2018-06-08 13:54:01       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.7433550400956854
[2018-06-08 13:54:02       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7810947961506122
[2018-06-08 13:54:02       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8259418226305811
[2018-06-08 13:54:03       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.829263815657459
[2018-06-08 13:54:04       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8125079128296078
[2018-06-08 13:54:04       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8317875639773215
[2018-06-08 13:54:05       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8427386745002763
[2018-06-08 13:54:06       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.857960954695201
[2018-06-08 13:54:06       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.832018547635064
[2018-06-08 13:54:07       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.7826778348383822
[2018-06-08 13:54:08       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.8603236522740686
[2018-06-08 13:54:09       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.8406826608645395
[2018-06-08 13:54:09       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8211298587489994
[2018-06-08 13:54:10       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.861283055530579
[2018-06-08 13:54:11       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8320123778140001
[2018-06-08 13:54:11       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8591059947798425
[2018-06-08 13:54:12       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8537824185240147
[2018-06-08 13:54:13       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8604618314696783
[2018-06-08 13:54:13       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8512995585412767
[2018-06-08 13:54:14       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8536636987426018
[2018-06-08 13:54:15       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.8498006885949596
[2018-06-08 13:54:16       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8590592539494881
[2018-06-08 13:54:16       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8311686799954616
[2018-06-08 13:54:17       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8655879770680943
[2018-06-08 13:54:18       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8690896159011962
[2018-06-08 13:54:18       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8652436920632337
[2018-06-08 13:54:19       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8546369446698101
[2018-06-08 13:54:20       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8566311868793158
[2018-06-08 13:54:21       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.8650238318244854
[2018-06-08 13:54:21       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8419261593718228
[2018-06-08 13:54:22       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.841663015104224
[2018-06-08 13:54:23       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8464722616850534
[2018-06-08 13:54:23       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8567331892314393
[2018-06-08 13:54:24       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8618412994791366
[2018-06-08 13:54:25       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8574011676963957
[2018-06-08 13:54:25       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.8551233607733159
[2018-06-08 13:54:26       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8603965970986907
[2018-06-08 13:54:27       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8677143895271332
[2018-06-08 13:54:27       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8613640220593571
[2018-06-08 13:54:28       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.8506783335700406
[2018-06-08 13:54:29       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8621584888663011
[2018-06-08 13:54:29       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8711559960202497
[2018-06-08 13:54:30       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8628328391828163
[2018-06-08 13:54:30       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.858686945467035
[2018-06-08 13:54:31       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8469936322301395
[2018-06-08 13:54:32       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.8695064947414781
[2018-06-08 13:54:32       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8478494641327167
[2018-06-08 13:54:33       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8656772998032334
[2018-06-08 13:54:34       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.863770299497262
[2018-06-08 13:54:34       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8701370243493386
[2018-06-08 13:54:35       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.8628073112647767
[2018-06-08 13:54:36       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8573914276334148
[2018-06-08 13:54:36       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8641669742209434
[2018-06-08 13:54:37       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8629265722268606
[2018-06-08 13:54:37       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8666514527241396
[2018-06-08 13:54:38       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.8622117826177309
[2018-06-08 13:54:39       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8573287669456555
[2018-06-08 13:54:40       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.8459216561292271
[2018-06-08 13:54:41       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8678961175648316
[2018-06-08 13:54:42       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8572688929857933
[2018-06-08 13:54:42       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8647152690137816
[2018-06-08 13:54:43       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8688915787705929
[2018-06-08 13:54:44       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8643983666333898
[2018-06-08 13:54:44       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8700891141341093
[2018-06-08 13:54:45       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8625434293643027
[2018-06-08 13:54:46       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8668775085569206
[2018-06-08 13:54:46       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8660508597031749
[2018-06-08 13:54:47       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.8619593318365881
[2018-06-08 13:54:48       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8689959103686169
[2018-06-08 13:54:48       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8706165855565774
[2018-06-08 13:54:49       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8662035194284036
[2018-06-08 13:54:49       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8627382141014647
[2018-06-08 13:54:50       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.866028431786427
[2018-06-08 13:54:51       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.8594909928675708
[2018-06-08 13:54:51       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8706518927196859
[2018-06-08 13:54:52       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8671625098202236
[2018-06-08 13:54:53       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.8656161898638048
[2018-06-08 13:54:53       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8668900650215008
[2018-06-08 13:54:54       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.870389110051867
[2018-06-08 13:54:55       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8649674094964166
[2018-06-08 13:54:55       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8682246442382501
[2018-06-08 13:54:56       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.87105438008848
[2018-06-08 13:54:56       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8689400065674303
[2018-06-08 13:54:57       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.867595938777617
[2018-06-08 13:54:58       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8709210895067112
[2018-06-08 13:54:58       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8685238256917962
[2018-06-08 13:54:59       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.8629819184035884
[2018-06-08 13:55:00       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8603965065243259
[2018-06-08 13:55:00       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.871139073397145
[2018-06-08 13:55:01       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8683771694498944
[2018-06-08 13:55:02       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.865125714097197
[2018-06-08 13:55:02       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.869962726735269
[2018-06-08 13:55:03       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8705366118300278
[2018-06-08 13:55:04       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.8619431796392573
[2018-06-08 13:55:05       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8692836516951806
[2018-06-08 13:55:05       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:55:05       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:55:05       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:55:05       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_15.pickle"
[2018-06-08 13:55:05  start_training.py:128 -                      main()] Fidelity obtained: 0.867150626352478
[2018-06-08 13:55:07  start_training.py: 99 -                      main()] Starting training no.16
[2018-06-08 13:55:07  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 13:55:07    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:55:07    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:55:07    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:55:07    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:55:07           model.py:142 -       _set_initial_values()] Initial parameters values: [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.].
[2018-06-08 13:55:07           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:55:07           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:55:07       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:55:07       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:55:07       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:55:07       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:55:07       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:55:07       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:55:07       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:55:07       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:55:07       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:55:08       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:55:10       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:55:11       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7971379254576331
[2018-06-08 13:55:12       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8335564769307301
[2018-06-08 13:55:13       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.34892405674554217
[2018-06-08 13:55:13       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9807860351350572
[2018-06-08 13:55:14       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9742558106369544
[2018-06-08 13:55:15       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9786145842262792
[2018-06-08 13:55:15       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9577263873637284
[2018-06-08 13:55:16       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9904389440096655
[2018-06-08 13:55:17       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.984906030376408
[2018-06-08 13:55:17       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9851986860223679
[2018-06-08 13:55:18       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9873015694589103
[2018-06-08 13:55:19       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9865299611207936
[2018-06-08 13:55:19       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9892887044976054
[2018-06-08 13:55:20       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9892345039703164
[2018-06-08 13:55:20       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9919867627746293
[2018-06-08 13:55:21       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9915818679083251
[2018-06-08 13:55:22       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9845353376301728
[2018-06-08 13:55:22       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9886618107099625
[2018-06-08 13:55:23       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9914959938928033
[2018-06-08 13:55:24       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9910973583268846
[2018-06-08 13:55:24       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.990646386287162
[2018-06-08 13:55:25       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9905210675571997
[2018-06-08 13:55:25       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9928082181462523
[2018-06-08 13:55:26       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9909317387664851
[2018-06-08 13:55:27       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9891509126842081
[2018-06-08 13:55:27       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9927386348924645
[2018-06-08 13:55:28       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9915826601346269
[2018-06-08 13:55:29       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9923799344767399
[2018-06-08 13:55:29       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9909634277186066
[2018-06-08 13:55:30       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9911343667660069
[2018-06-08 13:55:31       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9924462422464179
[2018-06-08 13:55:32       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9925095668087992
[2018-06-08 13:55:33       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9916398130535592
[2018-06-08 13:55:34       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9926291202794718
[2018-06-08 13:55:35       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9930406065102784
[2018-06-08 13:55:35       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9918860147435521
[2018-06-08 13:55:36       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9929418037032944
[2018-06-08 13:55:37       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9910439599358217
[2018-06-08 13:55:37       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9922829020877737
[2018-06-08 13:55:38       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9933362126804738
[2018-06-08 13:55:39       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.99188061432426
[2018-06-08 13:55:39       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9917932737762295
[2018-06-08 13:55:40       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9913951139203633
[2018-06-08 13:55:41       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9919898516109882
[2018-06-08 13:55:41       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9929796512624857
[2018-06-08 13:55:42       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.992598553226741
[2018-06-08 13:55:43       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.99328232180816
[2018-06-08 13:55:43       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9922624014481363
[2018-06-08 13:55:44       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9927455855672497
[2018-06-08 13:55:45       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9931515067180914
[2018-06-08 13:55:46       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9924855827397608
[2018-06-08 13:55:47       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9926996661538441
[2018-06-08 13:55:47       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9925341806827497
[2018-06-08 13:55:48       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9925794528694822
[2018-06-08 13:55:49       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9929234160491538
[2018-06-08 13:55:50       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9921426813212125
[2018-06-08 13:55:51       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9918787836795668
[2018-06-08 13:55:52       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9927839165455992
[2018-06-08 13:55:52       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9933565522633026
[2018-06-08 13:55:53       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9928990934198048
[2018-06-08 13:55:54       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9926707957995999
[2018-06-08 13:55:55       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9929343613591491
[2018-06-08 13:55:56       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9929045396257997
[2018-06-08 13:55:56       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9931584721702404
[2018-06-08 13:55:57       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9929058638265693
[2018-06-08 13:55:58       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9929016306012902
[2018-06-08 13:55:58       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9929600978040151
[2018-06-08 13:55:59       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9932470604772499
[2018-06-08 13:56:00       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9926749241063105
[2018-06-08 13:56:00       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9927853685167173
[2018-06-08 13:56:01       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9926535844571052
[2018-06-08 13:56:02       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9932568444789258
[2018-06-08 13:56:02       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9931166562269539
[2018-06-08 13:56:03       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9930602166152345
[2018-06-08 13:56:04       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.993196751971286
[2018-06-08 13:56:04       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9930032866662095
[2018-06-08 13:56:05       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9918794743909671
[2018-06-08 13:56:06       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9933688904805478
[2018-06-08 13:56:07       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9931127897831479
[2018-06-08 13:56:07       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.993149604728417
[2018-06-08 13:56:08       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9932217289260982
[2018-06-08 13:56:09       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9933813332134386
[2018-06-08 13:56:09       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9924409247934052
[2018-06-08 13:56:10       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9928811655406016
[2018-06-08 13:56:11       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9932295309828635
[2018-06-08 13:56:11       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9931338565750372
[2018-06-08 13:56:12       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9924379819896029
[2018-06-08 13:56:12       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9929959678336117
[2018-06-08 13:56:13       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9923270633754683
[2018-06-08 13:56:14       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9931779846896801
[2018-06-08 13:56:14       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9928986369665341
[2018-06-08 13:56:15       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9930998300430263
[2018-06-08 13:56:16       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9933719523618249
[2018-06-08 13:56:16       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9933681991019683
[2018-06-08 13:56:17       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.993108041121658
[2018-06-08 13:56:18       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9926087374201547
[2018-06-08 13:56:18       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9931491773450395
[2018-06-08 13:56:19       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9931726268299961
[2018-06-08 13:56:20       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9927078942488582
[2018-06-08 13:56:20       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9930985885194745
[2018-06-08 13:56:20       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:56:20       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:56:20       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:56:20       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_16.pickle"
[2018-06-08 13:56:20  start_training.py:128 -                      main()] Fidelity obtained: 0.9933844361417259
[2018-06-08 13:56:23  start_training.py: 99 -                      main()] Starting training no.17
[2018-06-08 13:56:23  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 13:56:23    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:56:23    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:56:23    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:56:23    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:56:23           model.py:142 -       _set_initial_values()] Initial parameters values: [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.].
[2018-06-08 13:56:23           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:56:23           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:56:23       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:56:23       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:56:23       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:56:23       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:56:23       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:56:23       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:56:23       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:56:23       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:56:23       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:56:23       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:56:26       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:56:26       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6616673515135473
[2018-06-08 13:56:27       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.4893307228813629
[2018-06-08 13:56:28       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.949998123485218
[2018-06-08 13:56:28       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9841601995814458
[2018-06-08 13:56:29       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9901094785623978
[2018-06-08 13:56:30       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9909908760571365
[2018-06-08 13:56:30       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9943425755829814
[2018-06-08 13:56:31       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9953289424816658
[2018-06-08 13:56:31       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9970227255916579
[2018-06-08 13:56:32       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9858430534894538
[2018-06-08 13:56:33       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9909844461253279
[2018-06-08 13:56:33       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9961818977567153
[2018-06-08 13:56:34       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9963537817212458
[2018-06-08 13:56:35       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9968178725684171
[2018-06-08 13:56:35       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9967535849424941
[2018-06-08 13:56:36       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9953000018716084
[2018-06-08 13:56:37       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9969994406436075
[2018-06-08 13:56:37       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9970202569105874
[2018-06-08 13:56:38       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9971074071406888
[2018-06-08 13:56:39       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9972706847737619
[2018-06-08 13:56:39       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9969767442345643
[2018-06-08 13:56:40       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9970091317986477
[2018-06-08 13:56:41       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9971385037708381
[2018-06-08 13:56:41       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9972780670474868
[2018-06-08 13:56:42       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9967537469713079
[2018-06-08 13:56:43       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9973421579719655
[2018-06-08 13:56:43       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9967332264734597
[2018-06-08 13:56:44       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9965628512482989
[2018-06-08 13:56:45       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9953574690236161
[2018-06-08 13:56:45       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9971538224917778
[2018-06-08 13:56:46       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9973381566363417
[2018-06-08 13:56:47       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9968115873455483
[2018-06-08 13:56:47       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9972755756542306
[2018-06-08 13:56:48       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9967623016064086
[2018-06-08 13:56:49       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.997150979112208
[2018-06-08 13:56:49       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9972343132748551
[2018-06-08 13:56:50       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9970048888135102
[2018-06-08 13:56:51       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9967722047594857
[2018-06-08 13:56:51       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.996963680555356
[2018-06-08 13:56:52       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9971546235637672
[2018-06-08 13:56:53       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9971734410291125
[2018-06-08 13:56:53       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9973191731466616
[2018-06-08 13:56:54       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9965354268236425
[2018-06-08 13:56:55       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9972332449368253
[2018-06-08 13:56:55       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9966347631769658
[2018-06-08 13:56:56       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9973625371045952
[2018-06-08 13:56:57       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9972245251694638
[2018-06-08 13:56:57       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9972782169792589
[2018-06-08 13:56:58       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9972245422467235
[2018-06-08 13:56:59       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9972950006321425
[2018-06-08 13:56:59       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9972177412689895
[2018-06-08 13:57:00       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9973711090957387
[2018-06-08 13:57:01       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9969210843266514
[2018-06-08 13:57:01       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9972642671598799
[2018-06-08 13:57:02       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9971343491427997
[2018-06-08 13:57:03       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.997122027824542
[2018-06-08 13:57:04       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9970625887175649
[2018-06-08 13:57:04       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9972999322191821
[2018-06-08 13:57:05       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9972476203731041
[2018-06-08 13:57:06       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9973832415996762
[2018-06-08 13:57:06       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9969125960175614
[2018-06-08 13:57:07       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9972882909172262
[2018-06-08 13:57:08       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9969882822907213
[2018-06-08 13:57:08       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9973398160731634
[2018-06-08 13:57:09       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9973549417475523
[2018-06-08 13:57:10       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9973239203460761
[2018-06-08 13:57:10       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9973507583832796
[2018-06-08 13:57:11       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.997271815100641
[2018-06-08 13:57:12       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.997343455856885
[2018-06-08 13:57:12       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9971208823157842
[2018-06-08 13:57:13       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9972700635871735
[2018-06-08 13:57:14       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9969885377578811
[2018-06-08 13:57:14       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9973412423678591
[2018-06-08 13:57:15       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.996769498481611
[2018-06-08 13:57:16       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9973261805511435
[2018-06-08 13:57:16       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9972815128645185
[2018-06-08 13:57:17       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9973369396353798
[2018-06-08 13:57:18       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9973473846658834
[2018-06-08 13:57:18       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9973458385135864
[2018-06-08 13:57:19       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9972414673992277
[2018-06-08 13:57:20       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9973701352956195
[2018-06-08 13:57:20       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9972771233317652
[2018-06-08 13:57:21       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9970665950511257
[2018-06-08 13:57:22       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9972174083963098
[2018-06-08 13:57:22       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9973891955148553
[2018-06-08 13:57:23       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9973270429990747
[2018-06-08 13:57:24       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9973374734805616
[2018-06-08 13:57:24       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9973299367645089
[2018-06-08 13:57:25       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9972913222464787
[2018-06-08 13:57:26       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9973074384767664
[2018-06-08 13:57:26       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9973353799131357
[2018-06-08 13:57:27       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.997282974321094
[2018-06-08 13:57:28       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9973171322602584
[2018-06-08 13:57:28       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9972457145797164
[2018-06-08 13:57:29       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.997319330365065
[2018-06-08 13:57:30       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9971965596257335
[2018-06-08 13:57:30       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9973484441707207
[2018-06-08 13:57:31       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9972919666231514
[2018-06-08 13:57:32       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9973696482181532
[2018-06-08 13:57:33       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9970809623190132
[2018-06-08 13:57:33       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:57:33       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:57:33       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:57:33       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_17.pickle"
[2018-06-08 13:57:33  start_training.py:128 -                      main()] Fidelity obtained: 0.9971669049116466
[2018-06-08 13:57:35  start_training.py: 99 -                      main()] Starting training no.18
[2018-06-08 13:57:35  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 13:57:35    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:57:35    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:57:35    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:57:35    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:57:35           model.py:142 -       _set_initial_values()] Initial parameters values: [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.].
[2018-06-08 13:57:35           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:57:35           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:57:35       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:57:35       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:57:35       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:57:35       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:57:35       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:57:35       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:57:35       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:57:35       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:57:35       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:57:35       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:57:39       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:57:40       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9896161411748602
[2018-06-08 13:57:41       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8067443999736963
[2018-06-08 13:57:41       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9647238468928916
[2018-06-08 13:57:42       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9905127699820879
[2018-06-08 13:57:43       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9995573951202872
[2018-06-08 13:57:43       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999735750127425
[2018-06-08 13:57:44       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999846383989544
[2018-06-08 13:57:45       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999953165786815
[2018-06-08 13:57:45       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.999997888337734
[2018-06-08 13:57:46       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999992856872929
[2018-06-08 13:57:47       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999997526411629
[2018-06-08 13:57:47       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999998548193915
[2018-06-08 13:57:48       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999117593652
[2018-06-08 13:57:49       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999634891378
[2018-06-08 13:57:49       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999772558938
[2018-06-08 13:57:50       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999885478007
[2018-06-08 13:57:51       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999924512951
[2018-06-08 13:57:51       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999956834804
[2018-06-08 13:57:52       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.999999997192862
[2018-06-08 13:57:53       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999979292988
[2018-06-08 13:57:53       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999989059354
[2018-06-08 13:57:54       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999987974125
[2018-06-08 13:57:55       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999995252957
[2018-06-08 13:57:55       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999996970409
[2018-06-08 13:57:56       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.999999999798176
[2018-06-08 13:57:57       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999999998021478
[2018-06-08 13:57:57       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999999046567
[2018-06-08 13:57:58       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999999296486
[2018-06-08 13:57:59       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.999999999955387
[2018-06-08 13:57:59       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.999999999968957
[2018-06-08 13:58:00       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999999999776
[2018-06-08 13:58:01       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.999999999983546
[2018-06-08 13:58:01       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999999999874224
[2018-06-08 13:58:02       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999999914913
[2018-06-08 13:58:02       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999999999931266
[2018-06-08 13:58:03       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999999950456
[2018-06-08 13:58:04       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999999962563
[2018-06-08 13:58:04       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.999999999997124
[2018-06-08 13:58:05       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.999999999997852
[2018-06-08 13:58:05       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999999982988
[2018-06-08 13:58:06       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999999999985385
[2018-06-08 13:58:07       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999999999989407
[2018-06-08 13:58:07       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999999991356
[2018-06-08 13:58:08       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999999999994088
[2018-06-08 13:58:08       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999999999994159
[2018-06-08 13:58:09       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999999996038
[2018-06-08 13:58:10       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999999997286
[2018-06-08 13:58:10       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999999999997464
[2018-06-08 13:58:11       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999999999997717
[2018-06-08 13:58:11       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999999999998628
[2018-06-08 13:58:12       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999999999998785
[2018-06-08 13:58:13       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999999999999097
[2018-06-08 13:58:13       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999999999999309
[2018-06-08 13:58:14       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999999999999324
[2018-06-08 13:58:15       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999999999999555
[2018-06-08 13:58:16       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999999999999616
[2018-06-08 13:58:16       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999999999667
[2018-06-08 13:58:17       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999999999999748
[2018-06-08 13:58:17       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999999999999798
[2018-06-08 13:58:18       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999999999999817
[2018-06-08 13:58:19       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999999999999855
[2018-06-08 13:58:19       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999999999999878
[2018-06-08 13:58:20       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999999999999899
[2018-06-08 13:58:21       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999999999999923
[2018-06-08 13:58:21       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999999999999938
[2018-06-08 13:58:22       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999999999999944
[2018-06-08 13:58:22       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999999999999956
[2018-06-08 13:58:23       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999999999999971
[2018-06-08 13:58:24       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999999999999979
[2018-06-08 13:58:24       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999999999999981
[2018-06-08 13:58:25       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999999999999989
[2018-06-08 13:58:25       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.999999999999999
[2018-06-08 13:58:26       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999999999999991
[2018-06-08 13:58:27       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999999999999994
[2018-06-08 13:58:27       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999999999999994
[2018-06-08 13:58:28       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999999999999997
[2018-06-08 13:58:28       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999999999999994
[2018-06-08 13:58:29       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999999999999997
[2018-06-08 13:58:30       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999999999999997
[2018-06-08 13:58:30       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999999999999999
[2018-06-08 13:58:31       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999999999999999
[2018-06-08 13:58:31       Optimizer.py:490 -                      _run()]   Epoch no. 81: 1.0
[2018-06-08 13:58:31       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:58:31       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:58:31       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:58:31       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:58:31       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_18.pickle"
[2018-06-08 13:58:31  start_training.py:128 -                      main()] Fidelity obtained: 0.9999999999999998
[2018-06-08 13:58:33  start_training.py: 99 -                      main()] Starting training no.19
[2018-06-08 13:58:33  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 13:58:33    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:58:33    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:58:33    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:58:33    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:58:33           model.py:142 -       _set_initial_values()] Initial parameters values: [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.].
[2018-06-08 13:58:33           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:58:33           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:58:33       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:58:33       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:58:33       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:58:33       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:58:33       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:58:33       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:58:33       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:58:34       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:58:34       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:58:34       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:58:37       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:58:38       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8417837676819007
[2018-06-08 13:58:38       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9682818703487743
[2018-06-08 13:58:39       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.999221616900271
[2018-06-08 13:58:40       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999999999986054
[2018-06-08 13:58:41       Optimizer.py:490 -                      _run()]   Epoch no. 4: 1.0
[2018-06-08 13:58:41       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 13:58:41       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:58:41       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:58:41       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:58:41       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_19.pickle"
[2018-06-08 13:58:41  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 13:58:44  start_training.py: 99 -                      main()] Starting training no.20
[2018-06-08 13:58:44  start_training.py:100 -                      main()] Initial values: 1.
[2018-06-08 13:58:44    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:58:44    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:58:44    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:58:44    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:58:44           model.py:142 -       _set_initial_values()] Initial parameters values: [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.].
[2018-06-08 13:58:44           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:58:44           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:58:44       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:58:44       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:58:44       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:58:44       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:58:44       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:58:44       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:58:44       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:58:44       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:58:44       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:58:44       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 13:58:47       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 13:58:48       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.38997774557375287
[2018-06-08 13:58:49       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6502992415490794
[2018-06-08 13:58:50       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9604216906344667
[2018-06-08 13:58:51       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9641371943852445
[2018-06-08 13:58:51       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9421418397423753
[2018-06-08 13:58:52       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9920372395070219
[2018-06-08 13:58:53       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9325667840093058
[2018-06-08 13:58:53       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9736025945933346
[2018-06-08 13:58:54       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9842610276909096
[2018-06-08 13:58:55       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9904548601037196
[2018-06-08 13:58:55       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9892705641881399
[2018-06-08 13:58:56       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9817362089993432
[2018-06-08 13:58:56       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9871153939315609
[2018-06-08 13:58:57       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9912083745176755
[2018-06-08 13:58:58       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9901718394765515
[2018-06-08 13:58:58       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9929323115341363
[2018-06-08 13:58:59       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9813284662689401
[2018-06-08 13:59:00       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9917447415007159
[2018-06-08 13:59:00       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9916351869086424
[2018-06-08 13:59:01       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.992308487874029
[2018-06-08 13:59:01       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9920732480301492
[2018-06-08 13:59:02       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9919120924219851
[2018-06-08 13:59:03       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9914954610443577
[2018-06-08 13:59:03       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9896946171057509
[2018-06-08 13:59:04       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9928682721538139
[2018-06-08 13:59:05       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9900576981617228
[2018-06-08 13:59:05       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9924798864976697
[2018-06-08 13:59:06       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9925990450394011
[2018-06-08 13:59:07       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9921369669223548
[2018-06-08 13:59:07       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9926005859554908
[2018-06-08 13:59:08       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9910399016072781
[2018-06-08 13:59:08       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9906855820196745
[2018-06-08 13:59:09       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9911438132012504
[2018-06-08 13:59:10       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9938865042175519
[2018-06-08 13:59:10       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9936484389068699
[2018-06-08 13:59:11       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9934465499041886
[2018-06-08 13:59:12       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9935977010889258
[2018-06-08 13:59:12       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9937554241304762
[2018-06-08 13:59:13       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9923313587209186
[2018-06-08 13:59:13       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9928918788960531
[2018-06-08 13:59:14       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9935246445048669
[2018-06-08 13:59:15       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9933026644815334
[2018-06-08 13:59:16       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9926202530510697
[2018-06-08 13:59:17       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9917335522905343
[2018-06-08 13:59:17       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9924598620913341
[2018-06-08 13:59:18       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9928448183217934
[2018-06-08 13:59:19       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9934639259959128
[2018-06-08 13:59:19       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9926214307303344
[2018-06-08 13:59:20       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.99335524722508
[2018-06-08 13:59:21       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9918392798896873
[2018-06-08 13:59:21       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.993653302410174
[2018-06-08 13:59:22       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9936123371683321
[2018-06-08 13:59:22       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9937651918604637
[2018-06-08 13:59:23       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9932075033393124
[2018-06-08 13:59:24       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9933444352599635
[2018-06-08 13:59:24       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9930290278044747
[2018-06-08 13:59:25       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9931075099554075
[2018-06-08 13:59:26       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9923775267393988
[2018-06-08 13:59:26       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9926078165211496
[2018-06-08 13:59:27       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9932229779237489
[2018-06-08 13:59:27       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9932598547801694
[2018-06-08 13:59:28       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9935378883032776
[2018-06-08 13:59:29       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9935853824604343
[2018-06-08 13:59:29       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9933592280540583
[2018-06-08 13:59:30       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9933323366877674
[2018-06-08 13:59:31       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9933487933910182
[2018-06-08 13:59:31       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9940079577131491
[2018-06-08 13:59:32       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9937895950482407
[2018-06-08 13:59:33       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.993823354791723
[2018-06-08 13:59:33       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9937123402202508
[2018-06-08 13:59:34       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9930452356224098
[2018-06-08 13:59:35       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9931950088901276
[2018-06-08 13:59:36       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9939041703784148
[2018-06-08 13:59:36       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9937372396140286
[2018-06-08 13:59:37       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9940808979767659
[2018-06-08 13:59:38       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9934440055080597
[2018-06-08 13:59:38       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9931783655585399
[2018-06-08 13:59:39       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9937377634570466
[2018-06-08 13:59:40       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9935757757960103
[2018-06-08 13:59:40       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9940543977922961
[2018-06-08 13:59:41       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9934539124241075
[2018-06-08 13:59:42       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.99356179761635
[2018-06-08 13:59:42       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9935506569034603
[2018-06-08 13:59:43       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.993539092478559
[2018-06-08 13:59:44       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9935329089627533
[2018-06-08 13:59:44       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9934697795060581
[2018-06-08 13:59:45       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.993973559184969
[2018-06-08 13:59:46       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.993364137714432
[2018-06-08 13:59:47       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9934202666485733
[2018-06-08 13:59:47       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9940305358639896
[2018-06-08 13:59:48       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9937054667225691
[2018-06-08 13:59:49       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9936385343816238
[2018-06-08 13:59:49       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9937209514640526
[2018-06-08 13:59:50       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9939403923227067
[2018-06-08 13:59:51       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9938132076006977
[2018-06-08 13:59:51       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9937756914309915
[2018-06-08 13:59:52       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9934957206858681
[2018-06-08 13:59:53       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.993544607973375
[2018-06-08 13:59:53       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9940836875984546
[2018-06-08 13:59:54       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.993225626903814
[2018-06-08 13:59:54       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 13:59:54       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 13:59:54       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 13:59:54       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_20.pickle"
[2018-06-08 13:59:54  start_training.py:128 -                      main()] Fidelity obtained: 0.9925773291236082
[2018-06-08 13:59:56  start_training.py: 99 -                      main()] Starting training no.21
[2018-06-08 13:59:56  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 13:59:56    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 13:59:56    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 13:59:56    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 13:59:56    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 13:59:56           model.py:142 -       _set_initial_values()] Initial parameters values: [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.].
[2018-06-08 13:59:56           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 13:59:56           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 13:59:56       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 13:59:56       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 13:59:56       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 13:59:56       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 13:59:56       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 13:59:56       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 13:59:56       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 13:59:57       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 13:59:57       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 13:59:57       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:00:01       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:00:01       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6306689503137252
[2018-06-08 14:00:02       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5196645522626312
[2018-06-08 14:00:02       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9408874538285938
[2018-06-08 14:00:03       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9544329617227845
[2018-06-08 14:00:04       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9429183125580739
[2018-06-08 14:00:05       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9537756653986146
[2018-06-08 14:00:05       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9763187785428775
[2018-06-08 14:00:06       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9589395907211571
[2018-06-08 14:00:07       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9713468910988295
[2018-06-08 14:00:08       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9754680633442018
[2018-06-08 14:00:09       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9589686330252521
[2018-06-08 14:00:09       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9787444314447843
[2018-06-08 14:00:10       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9728571430786065
[2018-06-08 14:00:11       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9812518520755386
[2018-06-08 14:00:12       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9773465874409167
[2018-06-08 14:00:13       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9701634313741481
[2018-06-08 14:00:14       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9806573587097149
[2018-06-08 14:00:15       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9792497033837693
[2018-06-08 14:00:16       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9825226508659384
[2018-06-08 14:00:16       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9818629915490777
[2018-06-08 14:00:17       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9757398710435221
[2018-06-08 14:00:18       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.975135999611362
[2018-06-08 14:00:19       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9811618614676383
[2018-06-08 14:00:19       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9780798148229864
[2018-06-08 14:00:20       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.982693441876881
[2018-06-08 14:00:21       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9809581706251831
[2018-06-08 14:00:21       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.981275276731385
[2018-06-08 14:00:22       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.979060754284715
[2018-06-08 14:00:23       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9801821167166564
[2018-06-08 14:00:23       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9826780552592237
[2018-06-08 14:00:24       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9817676673091804
[2018-06-08 14:00:25       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9819167166691488
[2018-06-08 14:00:25       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9786930830329229
[2018-06-08 14:00:26       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9826775767926447
[2018-06-08 14:00:27       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9803195398769263
[2018-06-08 14:00:27       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9804883856809978
[2018-06-08 14:00:28       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9829887095227494
[2018-06-08 14:00:29       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9820796402495481
[2018-06-08 14:00:29       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9818804472917971
[2018-06-08 14:00:30       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9826052829765131
[2018-06-08 14:00:31       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9777836073612605
[2018-06-08 14:00:31       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9817246975252486
[2018-06-08 14:00:32       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9829924009676667
[2018-06-08 14:00:33       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9804662581828616
[2018-06-08 14:00:34       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9824210720847562
[2018-06-08 14:00:34       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.982092640362749
[2018-06-08 14:00:35       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.98217676571677
[2018-06-08 14:00:36       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9804493097287618
[2018-06-08 14:00:37       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9817477292219219
[2018-06-08 14:00:38       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9824295579906774
[2018-06-08 14:00:39       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9828075294976172
[2018-06-08 14:00:40       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9813350421302758
[2018-06-08 14:00:41       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.980035761360496
[2018-06-08 14:00:42       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9819960361735858
[2018-06-08 14:00:43       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9825766230814957
[2018-06-08 14:00:43       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9816870800459339
[2018-06-08 14:00:44       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9828108727010975
[2018-06-08 14:00:45       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9817710955748623
[2018-06-08 14:00:45       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9824635420818235
[2018-06-08 14:00:46       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9799104649892891
[2018-06-08 14:00:47       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.981681479889546
[2018-06-08 14:00:47       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9829095518072748
[2018-06-08 14:00:48       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9825356247221368
[2018-06-08 14:00:49       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9821938557543561
[2018-06-08 14:00:49       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9805680236395728
[2018-06-08 14:00:50       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9830801585615174
[2018-06-08 14:00:50       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9819459633075192
[2018-06-08 14:00:51       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9819871020691656
[2018-06-08 14:00:52       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9828377751386084
[2018-06-08 14:00:52       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9825050826998113
[2018-06-08 14:00:53       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9823652506463119
[2018-06-08 14:00:54       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9816970445319619
[2018-06-08 14:00:55       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9827409279445715
[2018-06-08 14:00:56       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9828554448468921
[2018-06-08 14:00:56       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9824913771058392
[2018-06-08 14:00:57       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9830324369134474
[2018-06-08 14:00:57       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9826009844435935
[2018-06-08 14:00:58       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9829266898201412
[2018-06-08 14:00:59       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9828247858725261
[2018-06-08 14:00:59       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9831224132828461
[2018-06-08 14:01:00       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9830759038266733
[2018-06-08 14:01:01       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9829628151048307
[2018-06-08 14:01:01       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9831132566986653
[2018-06-08 14:01:02       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9829070062893811
[2018-06-08 14:01:02       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.982492326612796
[2018-06-08 14:01:03       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9829711113498568
[2018-06-08 14:01:04       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9827835153925668
[2018-06-08 14:01:04       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9824315292187922
[2018-06-08 14:01:05       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9825899229200905
[2018-06-08 14:01:06       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9814622853625266
[2018-06-08 14:01:06       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9827021796132889
[2018-06-08 14:01:07       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9826991561156838
[2018-06-08 14:01:07       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9814236306511872
[2018-06-08 14:01:08       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9818755444202112
[2018-06-08 14:01:09       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9826134327479541
[2018-06-08 14:01:09       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9809926728859145
[2018-06-08 14:01:10       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9822429173340183
[2018-06-08 14:01:11       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9830815949979762
[2018-06-08 14:01:11       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9825110321393068
[2018-06-08 14:01:12       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9821165707950663
[2018-06-08 14:01:12       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:01:12       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:01:12       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:01:12       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_21.pickle"
[2018-06-08 14:01:12  start_training.py:128 -                      main()] Fidelity obtained: 0.9825675997937592
[2018-06-08 14:01:15  start_training.py: 99 -                      main()] Starting training no.22
[2018-06-08 14:01:15  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 14:01:15    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:01:15    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:01:15    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:01:15    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:01:15           model.py:142 -       _set_initial_values()] Initial parameters values: [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.].
[2018-06-08 14:01:15           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:01:15           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:01:15       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:01:15       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:01:15       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:01:15       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:01:15       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:01:15       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:01:15       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:01:15       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:01:15       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:01:16       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:01:19       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:01:20       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.36592931715253096
[2018-06-08 14:01:21       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6329459236309568
[2018-06-08 14:01:22       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9398454047026952
[2018-06-08 14:01:23       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9998819101099321
[2018-06-08 14:01:24       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999999973
[2018-06-08 14:01:25       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0
[2018-06-08 14:01:25       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:01:25       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:01:25       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:01:25       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:01:25       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_22.pickle"
[2018-06-08 14:01:25  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000004
[2018-06-08 14:01:27  start_training.py: 99 -                      main()] Starting training no.23
[2018-06-08 14:01:27  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 14:01:27    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:01:27    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:01:27    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:01:27    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:01:27           model.py:142 -       _set_initial_values()] Initial parameters values: [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.].
[2018-06-08 14:01:27           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:01:27           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:01:27       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:01:27       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:01:27       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:01:27       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:01:27       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:01:27       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:01:27       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:01:27       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:01:27       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:01:27       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:01:31       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:01:32       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9604653994307456
[2018-06-08 14:01:33       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8538378008253354
[2018-06-08 14:01:34       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9999955573197539
[2018-06-08 14:01:35       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.999999999999603
[2018-06-08 14:01:36       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999999999
[2018-06-08 14:01:37       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0
[2018-06-08 14:01:37       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:01:37       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:01:37       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:01:37       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:01:37       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_23.pickle"
[2018-06-08 14:01:37  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:01:39  start_training.py: 99 -                      main()] Starting training no.24
[2018-06-08 14:01:39  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 14:01:39    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:01:39    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:01:39    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:01:39    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:01:39           model.py:142 -       _set_initial_values()] Initial parameters values: [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.].
[2018-06-08 14:01:39           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:01:39           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:01:39       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:01:39       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:01:39       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:01:39       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:01:39       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:01:39       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:01:39       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:01:39       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:01:39       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:01:39       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:01:43       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:01:44       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5687486738310927
[2018-06-08 14:01:45       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7962040171962755
[2018-06-08 14:01:45       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9736608248845876
[2018-06-08 14:01:46       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8370570667595216
[2018-06-08 14:01:47       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9344409422900862
[2018-06-08 14:01:47       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9505715991216875
[2018-06-08 14:01:48       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7983312857462077
[2018-06-08 14:01:49       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9868315949011591
[2018-06-08 14:01:49       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9895217400282472
[2018-06-08 14:01:50       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9851448416975398
[2018-06-08 14:01:51       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.987105418922668
[2018-06-08 14:01:52       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9902030579780149
[2018-06-08 14:01:52       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9856142047593965
[2018-06-08 14:01:53       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9906176021084534
[2018-06-08 14:01:54       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9857855850643326
[2018-06-08 14:01:54       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9909278245865814
[2018-06-08 14:01:55       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.993124069951581
[2018-06-08 14:01:56       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9913203550535081
[2018-06-08 14:01:56       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9915780987518137
[2018-06-08 14:01:57       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9904733204999424
[2018-06-08 14:01:58       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9920845167133304
[2018-06-08 14:01:58       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9911594472513585
[2018-06-08 14:01:59       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9917460486048545
[2018-06-08 14:01:59       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9930507988257729
[2018-06-08 14:02:00       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.990230650918579
[2018-06-08 14:02:01       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9907119223769023
[2018-06-08 14:02:01       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9911419632141997
[2018-06-08 14:02:02       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9934722246835512
[2018-06-08 14:02:03       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9928160901618321
[2018-06-08 14:02:03       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.991026085277502
[2018-06-08 14:02:04       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9921350640404928
[2018-06-08 14:02:04       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.992388575610966
[2018-06-08 14:02:05       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9916762486143041
[2018-06-08 14:02:06       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9933752001800322
[2018-06-08 14:02:06       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9919304762147337
[2018-06-08 14:02:07       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9913748271187525
[2018-06-08 14:02:08       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9923653538329718
[2018-06-08 14:02:08       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9925671586848839
[2018-06-08 14:02:09       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9927955237192159
[2018-06-08 14:02:10       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9931819474329635
[2018-06-08 14:02:10       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9902412468507464
[2018-06-08 14:02:11       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9915071985677482
[2018-06-08 14:02:11       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9914779474213872
[2018-06-08 14:02:12       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9931211197097285
[2018-06-08 14:02:13       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9931798750625647
[2018-06-08 14:02:13       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9931292761846601
[2018-06-08 14:02:14       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9927608348376447
[2018-06-08 14:02:15       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.992059783520845
[2018-06-08 14:02:15       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9916833162521188
[2018-06-08 14:02:16       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9934007586113367
[2018-06-08 14:02:16       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9932496701555532
[2018-06-08 14:02:17       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9930986979584857
[2018-06-08 14:02:18       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9931197565478681
[2018-06-08 14:02:18       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.992273302306591
[2018-06-08 14:02:19       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9927986769796395
[2018-06-08 14:02:20       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9927101253622723
[2018-06-08 14:02:20       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9935435719561958
[2018-06-08 14:02:21       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.993186411468177
[2018-06-08 14:02:22       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9931972922023405
[2018-06-08 14:02:22       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9934243026572297
[2018-06-08 14:02:23       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9930582507381289
[2018-06-08 14:02:23       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9931795428989694
[2018-06-08 14:02:24       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9934901819105584
[2018-06-08 14:02:25       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.993009847458963
[2018-06-08 14:02:25       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9933456224802442
[2018-06-08 14:02:26       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.992758418817962
[2018-06-08 14:02:27       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9928112897480829
[2018-06-08 14:02:27       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9928458265532732
[2018-06-08 14:02:28       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.992743817425975
[2018-06-08 14:02:28       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9925848357980184
[2018-06-08 14:02:29       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9932619883467066
[2018-06-08 14:02:30       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9927003974541263
[2018-06-08 14:02:31       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9932367188988631
[2018-06-08 14:02:31       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9929773392898629
[2018-06-08 14:02:32       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9931000612961838
[2018-06-08 14:02:33       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9929412005498716
[2018-06-08 14:02:33       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9930779987987983
[2018-06-08 14:02:34       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9932989020096973
[2018-06-08 14:02:35       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9934630406973555
[2018-06-08 14:02:35       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9932553755855179
[2018-06-08 14:02:36       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9928417625592142
[2018-06-08 14:02:37       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9934750633768686
[2018-06-08 14:02:37       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9928487673461184
[2018-06-08 14:02:38       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9929161441711761
[2018-06-08 14:02:39       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9933127192645628
[2018-06-08 14:02:40       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9932354016827819
[2018-06-08 14:02:41       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9932705926016796
[2018-06-08 14:02:42       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9935507029483495
[2018-06-08 14:02:43       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9930240248052371
[2018-06-08 14:02:44       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9929589457434328
[2018-06-08 14:02:44       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9930917858253336
[2018-06-08 14:02:45       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9929800527695971
[2018-06-08 14:02:46       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9931433107234185
[2018-06-08 14:02:46       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9932418601112316
[2018-06-08 14:02:47       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9934210566260113
[2018-06-08 14:02:48       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9933745538284022
[2018-06-08 14:02:48       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9931250390690587
[2018-06-08 14:02:49       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9931195549728388
[2018-06-08 14:02:50       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9929762413382387
[2018-06-08 14:02:51       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9929189147461319
[2018-06-08 14:02:51       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:02:51       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:02:51       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:02:51       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_24.pickle"
[2018-06-08 14:02:51  start_training.py:128 -                      main()] Fidelity obtained: 0.9928669159006358
[2018-06-08 14:02:53  start_training.py: 99 -                      main()] Starting training no.25
[2018-06-08 14:02:53  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 14:02:53    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:02:53    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:02:53    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:02:53    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:02:53           model.py:142 -       _set_initial_values()] Initial parameters values: [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.].
[2018-06-08 14:02:53           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:02:53           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:02:53       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:02:53       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:02:53       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:02:53       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:02:53       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:02:53       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:02:53       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:02:53       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:02:53       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:02:53       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:02:57       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:02:58       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.841882623491184
[2018-06-08 14:02:59       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.4587859881701798
[2018-06-08 14:03:00       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.5013737148586346
[2018-06-08 14:03:01       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9935254673384374
[2018-06-08 14:03:02       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999518905511
[2018-06-08 14:03:03       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999999996
[2018-06-08 14:03:03       Optimizer.py:490 -                      _run()]   Epoch no. 6: 1.0
[2018-06-08 14:03:03       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:03:03       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:03:03       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:03:03       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:03:03       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_25.pickle"
[2018-06-08 14:03:04  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000002
[2018-06-08 14:03:06  start_training.py: 99 -                      main()] Starting training no.26
[2018-06-08 14:03:06  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 14:03:06    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:03:06    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:03:06    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:03:06    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:03:06           model.py:142 -       _set_initial_values()] Initial parameters values: [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.].
[2018-06-08 14:03:06           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:03:06           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:03:06       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:03:06       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:03:06       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:03:06       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:03:06       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:03:06       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:03:06       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:03:06       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:03:06       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:03:06       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:03:10       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:03:11       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.743438950781292
[2018-06-08 14:03:12       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8439377222069971
[2018-06-08 14:03:13       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.8101720988789333
[2018-06-08 14:03:14       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.5115592283734185
[2018-06-08 14:03:14       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8587279472015712
[2018-06-08 14:03:15       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.8478576893500204
[2018-06-08 14:03:15       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.7153560009417245
[2018-06-08 14:03:16       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.8618132246813481
[2018-06-08 14:03:17       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8993182407650395
[2018-06-08 14:03:17       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9383919549313385
[2018-06-08 14:03:18       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9431226839667134
[2018-06-08 14:03:19       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9459298511340559
[2018-06-08 14:03:19       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9105690960674057
[2018-06-08 14:03:20       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9450467263717175
[2018-06-08 14:03:20       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9111641028688827
[2018-06-08 14:03:21       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9464858664104828
[2018-06-08 14:03:22       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9460217918327382
[2018-06-08 14:03:22       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9268145409720268
[2018-06-08 14:03:23       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9548077841745684
[2018-06-08 14:03:23       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9456607460384882
[2018-06-08 14:03:24       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9505542439695486
[2018-06-08 14:03:25       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9366648280726626
[2018-06-08 14:03:25       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9461806110938906
[2018-06-08 14:03:26       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9467149325433986
[2018-06-08 14:03:26       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.951185185687454
[2018-06-08 14:03:27       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.949879210461462
[2018-06-08 14:03:28       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9498349641241134
[2018-06-08 14:03:29       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9507889714746979
[2018-06-08 14:03:30       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9497284912333386
[2018-06-08 14:03:31       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9520611132543253
[2018-06-08 14:03:32       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.954832422309722
[2018-06-08 14:03:32       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9538789872658892
[2018-06-08 14:03:33       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9511699671141125
[2018-06-08 14:03:34       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9516597571708147
[2018-06-08 14:03:34       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9525648770655286
[2018-06-08 14:03:35       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9535169980623226
[2018-06-08 14:03:35       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9549324805172739
[2018-06-08 14:03:36       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9424390139154966
[2018-06-08 14:03:37       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9476833428363953
[2018-06-08 14:03:37       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.956493949412432
[2018-06-08 14:03:38       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9540392054910274
[2018-06-08 14:03:38       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.951896382733286
[2018-06-08 14:03:39       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9562409200454745
[2018-06-08 14:03:40       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9525590304062367
[2018-06-08 14:03:40       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9574797960936298
[2018-06-08 14:03:41       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9564538811576672
[2018-06-08 14:03:42       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9537138406358043
[2018-06-08 14:03:42       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9497641541879092
[2018-06-08 14:03:43       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9535327748039684
[2018-06-08 14:03:44       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.955749272312748
[2018-06-08 14:03:44       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.957358186867297
[2018-06-08 14:03:45       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9566959527360627
[2018-06-08 14:03:46       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9590046244911434
[2018-06-08 14:03:46       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9575365692989073
[2018-06-08 14:03:47       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.949863492564177
[2018-06-08 14:03:48       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9559869333041945
[2018-06-08 14:03:48       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9558058982164019
[2018-06-08 14:03:49       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.953845224051159
[2018-06-08 14:03:49       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9561641399958059
[2018-06-08 14:03:50       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9572828580847335
[2018-06-08 14:03:51       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9548024449074924
[2018-06-08 14:03:52       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9545371383594728
[2018-06-08 14:03:53       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9559497998218631
[2018-06-08 14:03:54       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9558804317392241
[2018-06-08 14:03:55       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9516521037759549
[2018-06-08 14:03:56       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9571690087173369
[2018-06-08 14:03:56       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9553626929133823
[2018-06-08 14:03:57       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9584860734936926
[2018-06-08 14:03:58       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9550375449702532
[2018-06-08 14:03:59       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9535860074972803
[2018-06-08 14:04:00       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9542976589499989
[2018-06-08 14:04:01       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9555501215239721
[2018-06-08 14:04:02       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9567435983047651
[2018-06-08 14:04:03       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.956560959196394
[2018-06-08 14:04:03       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.956057439122594
[2018-06-08 14:04:04       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9559615283852608
[2018-06-08 14:04:05       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9574170115335546
[2018-06-08 14:04:06       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9576156818374687
[2018-06-08 14:04:06       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9552635539087071
[2018-06-08 14:04:07       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9531120462791932
[2018-06-08 14:04:07       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9554840478989752
[2018-06-08 14:04:08       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.957003551551891
[2018-06-08 14:04:09       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9572109068443589
[2018-06-08 14:04:09       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9569436127876688
[2018-06-08 14:04:10       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9550220916660567
[2018-06-08 14:04:11       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9566177996506414
[2018-06-08 14:04:11       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9570282046003575
[2018-06-08 14:04:12       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.955389228108476
[2018-06-08 14:04:13       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.958422458246898
[2018-06-08 14:04:13       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9586106365151243
[2018-06-08 14:04:14       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9578146217043039
[2018-06-08 14:04:14       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9576942923045252
[2018-06-08 14:04:15       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9578487889912708
[2018-06-08 14:04:16       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9581367168191579
[2018-06-08 14:04:16       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9575421158834159
[2018-06-08 14:04:17       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9567433126006845
[2018-06-08 14:04:17       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9584969145887352
[2018-06-08 14:04:18       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9565810023274258
[2018-06-08 14:04:19       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9558738627643804
[2018-06-08 14:04:19       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9567660297754383
[2018-06-08 14:04:19       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:04:19       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:04:19       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:04:19       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_26.pickle"
[2018-06-08 14:04:19  start_training.py:128 -                      main()] Fidelity obtained: 0.9564916127186917
[2018-06-08 14:04:21  start_training.py: 99 -                      main()] Starting training no.27
[2018-06-08 14:04:21  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 14:04:21    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:04:21    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:04:21    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:04:21    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:04:21           model.py:142 -       _set_initial_values()] Initial parameters values: [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.].
[2018-06-08 14:04:21           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:04:21           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:04:21       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:04:21       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:04:21       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:04:21       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:04:21       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:04:21       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:04:21       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:04:21       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:04:21       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:04:21       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:04:25       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:04:26       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7065353529976954
[2018-06-08 14:04:27       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.6798091576602056
[2018-06-08 14:04:28       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.588363308210289
[2018-06-08 14:04:29       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9880026845161316
[2018-06-08 14:04:30       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9967530290985485
[2018-06-08 14:04:31       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9997469902317946
[2018-06-08 14:04:31       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999910973575
[2018-06-08 14:04:32       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999041327
[2018-06-08 14:04:33       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999999975663
[2018-06-08 14:04:33       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999996677
[2018-06-08 14:04:34       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999999756
[2018-06-08 14:04:35       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999999999999999
[2018-06-08 14:04:36       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999999999999
[2018-06-08 14:04:36       Optimizer.py:490 -                      _run()]   Epoch no. 13: 1.0
[2018-06-08 14:04:36       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:04:36       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:04:36       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:04:36       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:04:36       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_27.pickle"
[2018-06-08 14:04:36  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:04:38  start_training.py: 99 -                      main()] Starting training no.28
[2018-06-08 14:04:38  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 14:04:38    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:04:38    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:04:38    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:04:38    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:04:38           model.py:142 -       _set_initial_values()] Initial parameters values: [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.].
[2018-06-08 14:04:38           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:04:38           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:04:38       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:04:38       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:04:38       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:04:38       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:04:38       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:04:38       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:04:38       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:04:39       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:04:39       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:04:39       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:04:43       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:04:44       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9124538441099657
[2018-06-08 14:04:45       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.4914331129857596
[2018-06-08 14:04:46       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9958851300829289
[2018-06-08 14:04:47       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9989939967478441
[2018-06-08 14:04:48       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999395932221
[2018-06-08 14:04:49       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999953587
[2018-06-08 14:04:49       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999999999996
[2018-06-08 14:04:50       Optimizer.py:490 -                      _run()]   Epoch no. 7: 1.0
[2018-06-08 14:04:50       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:04:50       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:04:50       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:04:50       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:04:50       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_28.pickle"
[2018-06-08 14:04:50  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:04:52  start_training.py: 99 -                      main()] Starting training no.29
[2018-06-08 14:04:52  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 14:04:52    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:04:52    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:04:52    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:04:52    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:04:52           model.py:142 -       _set_initial_values()] Initial parameters values: [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.].
[2018-06-08 14:04:52           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:04:52           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:04:52       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:04:52       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:04:52       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:04:52       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:04:52       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:04:52       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:04:52       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:04:52       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:04:52       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:04:52       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:04:56       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:04:57       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7130230704315479
[2018-06-08 14:04:58       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8440417387193747
[2018-06-08 14:04:58       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9869970368068098
[2018-06-08 14:04:59       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9877077563018848
[2018-06-08 14:05:00       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9775013294397157
[2018-06-08 14:05:00       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9835265568664076
[2018-06-08 14:05:01       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9886231176148894
[2018-06-08 14:05:02       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.994064928333236
[2018-06-08 14:05:03       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9914966539487884
[2018-06-08 14:05:03       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9949134869141872
[2018-06-08 14:05:04       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9952356022848783
[2018-06-08 14:05:05       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9956132230803554
[2018-06-08 14:05:06       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9935509949922168
[2018-06-08 14:05:06       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9945577474297796
[2018-06-08 14:05:07       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9962530984438235
[2018-06-08 14:05:08       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.997155918756993
[2018-06-08 14:05:08       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9961375009398752
[2018-06-08 14:05:09       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9956627222518911
[2018-06-08 14:05:10       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9948373237079583
[2018-06-08 14:05:10       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9972691678569903
[2018-06-08 14:05:11       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9975871137548422
[2018-06-08 14:05:12       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9973911231209195
[2018-06-08 14:05:12       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9974240421669454
[2018-06-08 14:05:13       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.997967114071197
[2018-06-08 14:05:14       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9980183316581084
[2018-06-08 14:05:15       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9980862978782598
[2018-06-08 14:05:15       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9982892582266331
[2018-06-08 14:05:16       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.997954065075922
[2018-06-08 14:05:17       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9976755113245166
[2018-06-08 14:05:17       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9980968592836815
[2018-06-08 14:05:18       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9984162828569257
[2018-06-08 14:05:19       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9980546573179158
[2018-06-08 14:05:19       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9981945499506537
[2018-06-08 14:05:20       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9985527103359024
[2018-06-08 14:05:21       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.998410332583665
[2018-06-08 14:05:21       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9985414320128307
[2018-06-08 14:05:22       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9986353576408006
[2018-06-08 14:05:23       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9987029042796539
[2018-06-08 14:05:23       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9985728645862403
[2018-06-08 14:05:24       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9987721753115372
[2018-06-08 14:05:25       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9986478198758512
[2018-06-08 14:05:26       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9986733640710205
[2018-06-08 14:05:26       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9988694329372245
[2018-06-08 14:05:27       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9989229370405194
[2018-06-08 14:05:28       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9989336232189093
[2018-06-08 14:05:28       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9988725508086356
[2018-06-08 14:05:29       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.99892217904186
[2018-06-08 14:05:30       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9990647031242986
[2018-06-08 14:05:31       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9989578955986725
[2018-06-08 14:05:31       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.99911742712318
[2018-06-08 14:05:32       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9991054069853567
[2018-06-08 14:05:33       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9991547556965737
[2018-06-08 14:05:33       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9992155497522242
[2018-06-08 14:05:34       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.999236654097366
[2018-06-08 14:05:35       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9992777321644546
[2018-06-08 14:05:35       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.999252181895305
[2018-06-08 14:05:36       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9992613471173699
[2018-06-08 14:05:37       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9991515708334721
[2018-06-08 14:05:37       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.999293858945414
[2018-06-08 14:05:38       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9993222400939762
[2018-06-08 14:05:39       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9994056691316221
[2018-06-08 14:05:39       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9994539613022403
[2018-06-08 14:05:40       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9994906190195672
[2018-06-08 14:05:41       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9994796637125272
[2018-06-08 14:05:42       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9995482692259885
[2018-06-08 14:05:42       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9995671979313149
[2018-06-08 14:05:43       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9995964745673485
[2018-06-08 14:05:44       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9995624514486886
[2018-06-08 14:05:45       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9995875824921441
[2018-06-08 14:05:46       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.999643897608691
[2018-06-08 14:05:47       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9996690595580836
[2018-06-08 14:05:48       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9996912509457914
[2018-06-08 14:05:49       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9996979337105514
[2018-06-08 14:05:50       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9997163004564099
[2018-06-08 14:05:51       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.999740694961147
[2018-06-08 14:05:51       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9997355683992901
[2018-06-08 14:05:52       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9997347423463733
[2018-06-08 14:05:53       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9997804324297414
[2018-06-08 14:05:54       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9997812535033119
[2018-06-08 14:05:54       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.999790402855183
[2018-06-08 14:05:55       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9998037169169356
[2018-06-08 14:05:56       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9998017939184939
[2018-06-08 14:05:56       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.999822229650726
[2018-06-08 14:05:57       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9998367467613621
[2018-06-08 14:05:58       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9998493255409363
[2018-06-08 14:05:58       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9998561882336934
[2018-06-08 14:05:59       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.999863168255477
[2018-06-08 14:06:00       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9998675747343063
[2018-06-08 14:06:00       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9998609263981801
[2018-06-08 14:06:01       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9998852128970629
[2018-06-08 14:06:02       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9998852214078815
[2018-06-08 14:06:02       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9998947982179448
[2018-06-08 14:06:03       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9998976344019768
[2018-06-08 14:06:04       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9998902808405784
[2018-06-08 14:06:04       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999128634525049
[2018-06-08 14:06:05       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999123367135718
[2018-06-08 14:06:06       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.9999231679185593
[2018-06-08 14:06:06       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999207199594524
[2018-06-08 14:06:07       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999316274037915
[2018-06-08 14:06:08       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999341057583748
[2018-06-08 14:06:08       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:06:08       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:06:08       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:06:08       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_29.pickle"
[2018-06-08 14:06:08  start_training.py:128 -                      main()] Fidelity obtained: 0.9999329427860795
[2018-06-08 14:06:10  start_training.py: 99 -                      main()] Starting training no.30
[2018-06-08 14:06:10  start_training.py:100 -                      main()] Initial values: 2.
[2018-06-08 14:06:10    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:06:10    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:06:10    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:06:10    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:06:10           model.py:142 -       _set_initial_values()] Initial parameters values: [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.].
[2018-06-08 14:06:10           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:06:10           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:06:10       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:06:10       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:06:10       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:06:10       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:06:10       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:06:10       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:06:10       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:06:10       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:06:10       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:06:10       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:06:14       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:06:15       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9970989321223845
[2018-06-08 14:06:16       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9762449095512018
[2018-06-08 14:06:16       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9998671979352839
[2018-06-08 14:06:17       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999999999809319
[2018-06-08 14:06:18       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999999997
[2018-06-08 14:06:18       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0
[2018-06-08 14:06:18       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:06:18       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:06:18       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:06:18       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:06:18       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_30.pickle"
[2018-06-08 14:06:18  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:06:22  start_training.py: 99 -                      main()] Starting training no.31
[2018-06-08 14:06:22  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 14:06:22    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:06:22    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:06:22    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:06:22    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:06:22           model.py:142 -       _set_initial_values()] Initial parameters values: [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.].
[2018-06-08 14:06:22           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:06:22           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:06:22       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:06:22       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:06:22       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:06:22       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:06:22       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:06:22       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:06:22       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:06:22       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:06:22       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:06:22       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:06:26       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:06:26       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5654270646685614
[2018-06-08 14:06:27       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9739727885232594
[2018-06-08 14:06:28       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9383102246707348
[2018-06-08 14:06:28       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999994232672647
[2018-06-08 14:06:29       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999999437
[2018-06-08 14:06:30       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0
[2018-06-08 14:06:30       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:06:30       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:06:30       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:06:30       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:06:30       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_31.pickle"
[2018-06-08 14:06:30  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000002
[2018-06-08 14:06:32  start_training.py: 99 -                      main()] Starting training no.32
[2018-06-08 14:06:32  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 14:06:32    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:06:32    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:06:32    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:06:32    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:06:32           model.py:142 -       _set_initial_values()] Initial parameters values: [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.].
[2018-06-08 14:06:32           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:06:32           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:06:32       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:06:32       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:06:32       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:06:32       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:06:32       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:06:32       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:06:32       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:06:32       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:06:32       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:06:32       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:06:35       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:06:36       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.5412093249084656
[2018-06-08 14:06:36       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.5484378163046381
[2018-06-08 14:06:37       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.5536225596337162
[2018-06-08 14:06:37       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.7287579424927216
[2018-06-08 14:06:38       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9975723752148822
[2018-06-08 14:06:39       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999211013111621
[2018-06-08 14:06:39       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999999902168
[2018-06-08 14:06:40       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999999997
[2018-06-08 14:06:40       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999999999997
[2018-06-08 14:06:41       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999999999
[2018-06-08 14:06:42       Optimizer.py:490 -                      _run()]   Epoch no. 10: 1.0
[2018-06-08 14:06:42       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:06:42       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:06:42       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:06:42       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:06:42       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_32.pickle"
[2018-06-08 14:06:42  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000004
[2018-06-08 14:06:44  start_training.py: 99 -                      main()] Starting training no.33
[2018-06-08 14:06:44  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 14:06:44    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:06:44    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:06:44    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:06:44    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:06:44           model.py:142 -       _set_initial_values()] Initial parameters values: [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.].
[2018-06-08 14:06:44           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:06:44           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:06:44       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:06:44       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:06:44       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:06:44       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:06:44       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:06:44       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:06:44       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:06:44       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:06:44       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:06:44       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:06:48       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:06:49       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9791664996238068
[2018-06-08 14:06:50       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9490665244609058
[2018-06-08 14:06:51       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9461673281136044
[2018-06-08 14:06:51       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9979483986210738
[2018-06-08 14:06:52       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999649173646123
[2018-06-08 14:06:53       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999998727750042
[2018-06-08 14:06:53       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999923100619
[2018-06-08 14:06:54       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999987561055
[2018-06-08 14:06:55       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999999543223
[2018-06-08 14:06:55       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999903472
[2018-06-08 14:06:56       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999990397
[2018-06-08 14:06:57       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999999999998552
[2018-06-08 14:06:58       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999999999746
[2018-06-08 14:06:59       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999999999969
[2018-06-08 14:07:00       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999999999997
[2018-06-08 14:07:01       Optimizer.py:490 -                      _run()]   Epoch no. 15: 1.0
[2018-06-08 14:07:01       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:07:01       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:07:01       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:07:01       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:07:01       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_33.pickle"
[2018-06-08 14:07:01  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:07:04  start_training.py: 99 -                      main()] Starting training no.34
[2018-06-08 14:07:04  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 14:07:04    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:07:04    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:07:04    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:07:04    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:07:04           model.py:142 -       _set_initial_values()] Initial parameters values: [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.].
[2018-06-08 14:07:04           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:07:04           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:07:04       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:07:04       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:07:04       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:07:04       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:07:04       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:07:04       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:07:04       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:07:05       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:07:05       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:07:05       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:07:09       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:07:10       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8364811561575531
[2018-06-08 14:07:10       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9873392499965422
[2018-06-08 14:07:11       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.88297896033609
[2018-06-08 14:07:12       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9837657862057643
[2018-06-08 14:07:13       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9003389691226207
[2018-06-08 14:07:13       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999998888665357
[2018-06-08 14:07:14       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999988265864
[2018-06-08 14:07:15       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999999549
[2018-06-08 14:07:15       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999999999997
[2018-06-08 14:07:16       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999999997
[2018-06-08 14:07:16       Optimizer.py:490 -                      _run()]   Epoch no. 10: 1.0
[2018-06-08 14:07:16       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:07:16       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:07:16       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:07:16       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:07:16       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_34.pickle"
[2018-06-08 14:07:16  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:07:18  start_training.py: 99 -                      main()] Starting training no.35
[2018-06-08 14:07:18  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 14:07:18    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:07:18    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:07:18    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:07:18    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:07:18           model.py:142 -       _set_initial_values()] Initial parameters values: [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.].
[2018-06-08 14:07:18           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:07:18           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:07:18       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:07:18       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:07:18       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:07:18       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:07:18       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:07:18       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:07:18       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:07:19       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:07:19       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:07:19       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:07:22       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:07:23       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9269127494281793
[2018-06-08 14:07:24       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9587433373807337
[2018-06-08 14:07:25       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.6017026460039776
[2018-06-08 14:07:26       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9976426550737253
[2018-06-08 14:07:27       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999862818868
[2018-06-08 14:07:28       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999886791
[2018-06-08 14:07:29       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999999999832
[2018-06-08 14:07:29       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999999999
[2018-06-08 14:07:30       Optimizer.py:490 -                      _run()]   Epoch no. 8: 1.0000000000000002
[2018-06-08 14:07:31       Optimizer.py:490 -                      _run()]   Epoch no. 9: 1.0
[2018-06-08 14:07:31       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:07:31       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:07:31       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:07:31       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:07:31       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_35.pickle"
[2018-06-08 14:07:31  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:07:32  start_training.py: 99 -                      main()] Starting training no.36
[2018-06-08 14:07:32  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 14:07:32    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:07:32    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:07:32    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:07:32    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:07:32           model.py:142 -       _set_initial_values()] Initial parameters values: [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.].
[2018-06-08 14:07:32           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:07:32           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:07:32       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:07:32       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:07:32       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:07:32       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:07:32       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:07:32       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:07:32       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:07:33       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:07:33       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:07:33       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:07:36       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:07:37       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8577440177422142
[2018-06-08 14:07:38       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.850613291462656
[2018-06-08 14:07:38       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9796308741636863
[2018-06-08 14:07:39       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999999756672792
[2018-06-08 14:07:40       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999992936
[2018-06-08 14:07:41       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0
[2018-06-08 14:07:41       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:07:41       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:07:41       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:07:41       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:07:41       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_36.pickle"
[2018-06-08 14:07:41  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:07:44  start_training.py: 99 -                      main()] Starting training no.37
[2018-06-08 14:07:44  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 14:07:44    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:07:44    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:07:44    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:07:44    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:07:44           model.py:142 -       _set_initial_values()] Initial parameters values: [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.].
[2018-06-08 14:07:44           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:07:44           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:07:44       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:07:44       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:07:44       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:07:44       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:07:44       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:07:44       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:07:44       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:07:44       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:07:44       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:07:44       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:07:48       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:07:49       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9402348498057035
[2018-06-08 14:07:50       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9024745927445227
[2018-06-08 14:07:51       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9634804828218564
[2018-06-08 14:07:52       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999998472679326
[2018-06-08 14:07:53       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999647996
[2018-06-08 14:07:54       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0
[2018-06-08 14:07:54       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:07:54       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:07:54       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:07:54       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:07:54       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_37.pickle"
[2018-06-08 14:07:54  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:07:56  start_training.py: 99 -                      main()] Starting training no.38
[2018-06-08 14:07:56  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 14:07:56    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:07:56    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:07:56    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:07:56    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:07:56           model.py:142 -       _set_initial_values()] Initial parameters values: [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.].
[2018-06-08 14:07:56           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:07:56           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:07:56       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:07:56       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:07:56       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:07:56       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:07:56       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:07:56       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:07:56       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:07:57       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:07:57       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:07:57       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:08:00       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:08:01       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9353504248538423
[2018-06-08 14:08:02       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9209417298933898
[2018-06-08 14:08:03       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9993002217789362
[2018-06-08 14:08:04       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.999580461583606
[2018-06-08 14:08:05       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9998354680381195
[2018-06-08 14:08:06       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999417876356251
[2018-06-08 14:08:07       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.999963581113866
[2018-06-08 14:08:08       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999777882822919
[2018-06-08 14:08:09       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999881937707298
[2018-06-08 14:08:10       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999900062122568
[2018-06-08 14:08:11       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999951301255254
[2018-06-08 14:08:12       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999971004318531
[2018-06-08 14:08:13       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999975468442173
[2018-06-08 14:08:13       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999986523488181
[2018-06-08 14:08:14       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999991958657622
[2018-06-08 14:08:15       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999994875277797
[2018-06-08 14:08:15       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999995457902728
[2018-06-08 14:08:16       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999997306856614
[2018-06-08 14:08:16       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999997972106448
[2018-06-08 14:08:17       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999998689329485
[2018-06-08 14:08:18       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999068924308
[2018-06-08 14:08:18       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999326242203
[2018-06-08 14:08:19       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.999999955202607
[2018-06-08 14:08:20       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999678995829
[2018-06-08 14:08:20       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999999763077209
[2018-06-08 14:08:21       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999999823977589
[2018-06-08 14:08:21       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999867145272
[2018-06-08 14:08:22       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999894863191
[2018-06-08 14:08:23       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999919382198
[2018-06-08 14:08:23       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999999938339795
[2018-06-08 14:08:24       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999999944247469
[2018-06-08 14:08:25       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999961070345
[2018-06-08 14:08:25       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999999970485041
[2018-06-08 14:08:26       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999977089664
[2018-06-08 14:08:26       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999999981574388
[2018-06-08 14:08:27       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999984905459
[2018-06-08 14:08:28       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999986874606
[2018-06-08 14:08:28       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999999990602529
[2018-06-08 14:08:29       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999999992574645
[2018-06-08 14:08:30       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999993553861
[2018-06-08 14:08:30       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999999995001667
[2018-06-08 14:08:31       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.999999999580112
[2018-06-08 14:08:32       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999996488266
[2018-06-08 14:08:32       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.999999999721821
[2018-06-08 14:08:33       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999999997635111
[2018-06-08 14:08:34       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999998042222
[2018-06-08 14:08:34       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999998323343
[2018-06-08 14:08:35       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999999998633533
[2018-06-08 14:08:36       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999999998814957
[2018-06-08 14:08:36       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999999999040515
[2018-06-08 14:08:37       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.9999999999172472
[2018-06-08 14:08:38       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999999999305154
[2018-06-08 14:08:38       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999999999386487
[2018-06-08 14:08:39       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999999999461592
[2018-06-08 14:08:39       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.999999999957235
[2018-06-08 14:08:40       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999999999621713
[2018-06-08 14:08:41       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999999658756
[2018-06-08 14:08:41       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.9999999999718611
[2018-06-08 14:08:42       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999999999762323
[2018-06-08 14:08:43       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.999999999979501
[2018-06-08 14:08:43       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999999999825546
[2018-06-08 14:08:44       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999999999842407
[2018-06-08 14:08:44       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999999999866438
[2018-06-08 14:08:45       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.9999999999883705
[2018-06-08 14:08:46       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999999999892372
[2018-06-08 14:08:47       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999999999912061
[2018-06-08 14:08:47       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999999999921282
[2018-06-08 14:08:48       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999999999931451
[2018-06-08 14:08:49       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999999999939339
[2018-06-08 14:08:49       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999999999947283
[2018-06-08 14:08:50       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999999999952306
[2018-06-08 14:08:51       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.999999999995875
[2018-06-08 14:08:52       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999999999962162
[2018-06-08 14:08:52       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999999999966401
[2018-06-08 14:08:53       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999999999971086
[2018-06-08 14:08:54       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999999999974434
[2018-06-08 14:08:54       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999999999975395
[2018-06-08 14:08:55       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999999999979601
[2018-06-08 14:08:56       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.999999999998216
[2018-06-08 14:08:56       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999999999983474
[2018-06-08 14:08:57       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.999999999998584
[2018-06-08 14:08:58       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999999999986394
[2018-06-08 14:08:58       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999999999988318
[2018-06-08 14:08:59       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999999999989726
[2018-06-08 14:08:59       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999999999990916
[2018-06-08 14:09:00       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999999999991758
[2018-06-08 14:09:01       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999999999992659
[2018-06-08 14:09:01       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999999999993234
[2018-06-08 14:09:02       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999999999993899
[2018-06-08 14:09:03       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999999999994528
[2018-06-08 14:09:03       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.999999999999501
[2018-06-08 14:09:04       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999999999995552
[2018-06-08 14:09:05       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.9999999999995903
[2018-06-08 14:09:05       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.9999999999996237
[2018-06-08 14:09:06       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.9999999999996483
[2018-06-08 14:09:07       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.9999999999996979
[2018-06-08 14:09:07       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.99999999999973
[2018-06-08 14:09:08       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.9999999999997516
[2018-06-08 14:09:08       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.9999999999997712
[2018-06-08 14:09:09       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.9999999999997934
[2018-06-08 14:09:09       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:09:09       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:09:09       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:09:09       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_38.pickle"
[2018-06-08 14:09:09  start_training.py:128 -                      main()] Fidelity obtained: 0.9999999999998085
[2018-06-08 14:09:11  start_training.py: 99 -                      main()] Starting training no.39
[2018-06-08 14:09:11  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 14:09:11    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:09:11    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:09:11    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:09:11    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:09:11           model.py:142 -       _set_initial_values()] Initial parameters values: [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.].
[2018-06-08 14:09:11           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:09:11           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:09:11       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:09:11       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:09:11       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:09:11       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:09:11       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:09:11       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:09:11       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:09:11       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:09:11       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:09:11       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:09:14       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:09:15       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7211317403123887
[2018-06-08 14:09:16       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7983609522035248
[2018-06-08 14:09:17       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7860258436436242
[2018-06-08 14:09:18       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.8071874333049807
[2018-06-08 14:09:19       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.7127291771851019
[2018-06-08 14:09:20       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.6255731445071504
[2018-06-08 14:09:21       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.817784964906243
[2018-06-08 14:09:22       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.7826629443496336
[2018-06-08 14:09:22       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.8364559207843199
[2018-06-08 14:09:23       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.8378861922538292
[2018-06-08 14:09:24       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.8546455174716292
[2018-06-08 14:09:24       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.8212640779257775
[2018-06-08 14:09:25       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.8300213958423796
[2018-06-08 14:09:25       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.8470452365924642
[2018-06-08 14:09:26       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.8620095686979249
[2018-06-08 14:09:27       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.84182966819298
[2018-06-08 14:09:27       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.7984599638929949
[2018-06-08 14:09:28       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.8335142207281598
[2018-06-08 14:09:28       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.8601575311319912
[2018-06-08 14:09:29       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.8537180292761006
[2018-06-08 14:09:30       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.8266287128796209
[2018-06-08 14:09:30       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.8230311301971264
[2018-06-08 14:09:31       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.8569897368338014
[2018-06-08 14:09:31       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.8589660571164491
[2018-06-08 14:09:32       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.8551866911180929
[2018-06-08 14:09:33       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.828641826264059
[2018-06-08 14:09:33       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.8472017966465747
[2018-06-08 14:09:34       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.8544053883917703
[2018-06-08 14:09:35       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.8590986311801088
[2018-06-08 14:09:35       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.8496584443793196
[2018-06-08 14:09:36       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.8511242982594435
[2018-06-08 14:09:37       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.8545988144987199
[2018-06-08 14:09:37       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.8501313779559326
[2018-06-08 14:09:38       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.841375842282059
[2018-06-08 14:09:38       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.8633196086919809
[2018-06-08 14:09:39       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.8613718922573484
[2018-06-08 14:09:40       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.8638404239955447
[2018-06-08 14:09:40       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.8585790405947167
[2018-06-08 14:09:41       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.8511713157613223
[2018-06-08 14:09:42       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.8629168507961309
[2018-06-08 14:09:42       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.858247288974705
[2018-06-08 14:09:43       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.8674812475683986
[2018-06-08 14:09:43       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.8657848269796808
[2018-06-08 14:09:44       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.8553615863660035
[2018-06-08 14:09:45       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.865989061468363
[2018-06-08 14:09:45       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.8521926054729049
[2018-06-08 14:09:46       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.8668506990382778
[2018-06-08 14:09:46       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.8489310504725036
[2018-06-08 14:09:47       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.8560981413281873
[2018-06-08 14:09:48       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.8569814045647949
[2018-06-08 14:09:48       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.862507047627642
[2018-06-08 14:09:49       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.8639443375365349
[2018-06-08 14:09:50       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.8671539922012065
[2018-06-08 14:09:50       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.8589920329809959
[2018-06-08 14:09:51       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.8601606504538114
[2018-06-08 14:09:52       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.86054259998786
[2018-06-08 14:09:53       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.8672726156200242
[2018-06-08 14:09:53       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.8636391005087011
[2018-06-08 14:09:54       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.8664670597545795
[2018-06-08 14:09:54       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.8634374334858897
[2018-06-08 14:09:55       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.865530315953024
[2018-06-08 14:09:56       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.8642715577499253
[2018-06-08 14:09:56       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.85364193340526
[2018-06-08 14:09:57       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.8511884044810778
[2018-06-08 14:09:57       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.8468277700239005
[2018-06-08 14:09:58       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.8458975695994672
[2018-06-08 14:09:58       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.8673590753721712
[2018-06-08 14:09:59       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.8616178796187929
[2018-06-08 14:10:00       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.8610582700190395
[2018-06-08 14:10:00       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.8660610321600076
[2018-06-08 14:10:01       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.8624110022930105
[2018-06-08 14:10:02       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.8569562441890655
[2018-06-08 14:10:02       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.844930333773028
[2018-06-08 14:10:03       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.8611967996492385
[2018-06-08 14:10:04       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.8639337556952711
[2018-06-08 14:10:04       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.8563807584201681
[2018-06-08 14:10:05       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.8665281604711378
[2018-06-08 14:10:06       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.8650682979004999
[2018-06-08 14:10:06       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.866944473614542
[2018-06-08 14:10:07       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.8614939753876601
[2018-06-08 14:10:08       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.8659391472863508
[2018-06-08 14:10:08       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.856301248874813
[2018-06-08 14:10:09       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.8589888859397986
[2018-06-08 14:10:10       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.8666884197536397
[2018-06-08 14:10:10       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.8648789254242124
[2018-06-08 14:10:11       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.8645408099500256
[2018-06-08 14:10:12       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.8573724097290958
[2018-06-08 14:10:12       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.8683445700358748
[2018-06-08 14:10:13       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.8591591224610649
[2018-06-08 14:10:14       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.8549177846550231
[2018-06-08 14:10:15       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.8626607883966705
[2018-06-08 14:10:15       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.855666830050099
[2018-06-08 14:10:16       Optimizer.py:490 -                      _run()]   Epoch no. 92: 0.8602580974817119
[2018-06-08 14:10:17       Optimizer.py:490 -                      _run()]   Epoch no. 93: 0.86820440250874
[2018-06-08 14:10:17       Optimizer.py:490 -                      _run()]   Epoch no. 94: 0.8632405535315243
[2018-06-08 14:10:18       Optimizer.py:490 -                      _run()]   Epoch no. 95: 0.8636849147983169
[2018-06-08 14:10:18       Optimizer.py:490 -                      _run()]   Epoch no. 96: 0.8624606558006849
[2018-06-08 14:10:19       Optimizer.py:490 -                      _run()]   Epoch no. 97: 0.8680937954982363
[2018-06-08 14:10:20       Optimizer.py:490 -                      _run()]   Epoch no. 98: 0.864770648378956
[2018-06-08 14:10:20       Optimizer.py:490 -                      _run()]   Epoch no. 99: 0.8680825434278878
[2018-06-08 14:10:20       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:10:20       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:10:20       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:10:20       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_39.pickle"
[2018-06-08 14:10:20  start_training.py:128 -                      main()] Fidelity obtained: 0.8682853854983181
[2018-06-08 14:10:23  start_training.py: 99 -                      main()] Starting training no.40
[2018-06-08 14:10:23  start_training.py:100 -                      main()] Initial values: 3.
[2018-06-08 14:10:23    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:10:23    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:10:23    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:10:23    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:10:23           model.py:142 -       _set_initial_values()] Initial parameters values: [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.].
[2018-06-08 14:10:23           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:10:23           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:10:23       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:10:23       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:10:23       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:10:23       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:10:23       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:10:23       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:10:23       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:10:23       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:10:23       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:10:23       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:10:27       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:10:28       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.757597175761876
[2018-06-08 14:10:29       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9564649548964086
[2018-06-08 14:10:30       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7678548492439979
[2018-06-08 14:10:31       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999869968048142
[2018-06-08 14:10:32       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999890827032
[2018-06-08 14:10:32       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.999999997585212
[2018-06-08 14:10:33       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999999830478
[2018-06-08 14:10:34       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999974492
[2018-06-08 14:10:34       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999999999375
[2018-06-08 14:10:35       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999999958
[2018-06-08 14:10:36       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999999999997
[2018-06-08 14:10:36       Optimizer.py:490 -                      _run()]   Epoch no. 11: 1.0
[2018-06-08 14:10:36       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:10:36       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:10:36       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:10:36       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:10:36       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_40.pickle"
[2018-06-08 14:10:37  start_training.py:128 -                      main()] Fidelity obtained: 0.9999999999999998
[2018-06-08 14:10:39  start_training.py: 99 -                      main()] Starting training no.41
[2018-06-08 14:10:39  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 14:10:39    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:10:39    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:10:39    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:10:39    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:10:39           model.py:142 -       _set_initial_values()] Initial parameters values: [ 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.].
[2018-06-08 14:10:39           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:10:39           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:10:39       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:10:39       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:10:39       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:10:39       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:10:39       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:10:39       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:10:39       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:10:39       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:10:39       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:10:39       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:10:42       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:10:43       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8997599373021594
[2018-06-08 14:10:44       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8777135247675301
[2018-06-08 14:10:45       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9410909299578029
[2018-06-08 14:10:46       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999894986134114
[2018-06-08 14:10:47       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.999999999999999
[2018-06-08 14:10:48       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0000000000000002
[2018-06-08 14:10:49       Optimizer.py:490 -                      _run()]   Epoch no. 6: 1.0
[2018-06-08 14:10:49       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:10:49       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:10:49       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:10:49       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:10:49       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_41.pickle"
[2018-06-08 14:10:49  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:10:52  start_training.py: 99 -                      main()] Starting training no.42
[2018-06-08 14:10:52  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 14:10:52    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:10:52    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:10:52    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:10:52    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:10:52           model.py:142 -       _set_initial_values()] Initial parameters values: [ 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.].
[2018-06-08 14:10:52           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:10:52           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:10:52       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:10:52       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:10:52       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:10:52       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:10:52       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:10:52       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:10:52       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:10:52       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:10:52       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:10:52       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:10:57       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:10:57       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8339287063204657
[2018-06-08 14:10:58       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9778884110260136
[2018-06-08 14:10:58       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9928217186055
[2018-06-08 14:10:59       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999957878404045
[2018-06-08 14:11:00       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999967665095946
[2018-06-08 14:11:00       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999995500312028
[2018-06-08 14:11:01       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999996196818473
[2018-06-08 14:11:02       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999998747006181
[2018-06-08 14:11:03       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999077719641
[2018-06-08 14:11:04       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999660741489
[2018-06-08 14:11:04       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999735911865
[2018-06-08 14:11:05       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999999846938001
[2018-06-08 14:11:06       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999930086182
[2018-06-08 14:11:06       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999953901815
[2018-06-08 14:11:07       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999969871411
[2018-06-08 14:11:08       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999981872155
[2018-06-08 14:11:08       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999988301905
[2018-06-08 14:11:09       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999991471126
[2018-06-08 14:11:10       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999994872123
[2018-06-08 14:11:10       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999996386663
[2018-06-08 14:11:11       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.999999999750702
[2018-06-08 14:11:12       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999998172953
[2018-06-08 14:11:12       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999998642843
[2018-06-08 14:11:13       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999998978865
[2018-06-08 14:11:14       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999999999288408
[2018-06-08 14:11:14       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999999999461822
[2018-06-08 14:11:15       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999999607715
[2018-06-08 14:11:16       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999999700961
[2018-06-08 14:11:17       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.9999999999765902
[2018-06-08 14:11:17       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999999999822344
[2018-06-08 14:11:18       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999999999853635
[2018-06-08 14:11:19       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999999892057
[2018-06-08 14:11:19       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999999999916832
[2018-06-08 14:11:20       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999999935718
[2018-06-08 14:11:21       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.999999999994885
[2018-06-08 14:11:21       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999999958621
[2018-06-08 14:11:22       Optimizer.py:490 -                      _run()]   Epoch no. 36: 0.9999999999965214
[2018-06-08 14:11:23       Optimizer.py:490 -                      _run()]   Epoch no. 37: 0.9999999999974425
[2018-06-08 14:11:23       Optimizer.py:490 -                      _run()]   Epoch no. 38: 0.9999999999979038
[2018-06-08 14:11:24       Optimizer.py:490 -                      _run()]   Epoch no. 39: 0.9999999999982502
[2018-06-08 14:11:25       Optimizer.py:490 -                      _run()]   Epoch no. 40: 0.9999999999986621
[2018-06-08 14:11:25       Optimizer.py:490 -                      _run()]   Epoch no. 41: 0.9999999999988457
[2018-06-08 14:11:26       Optimizer.py:490 -                      _run()]   Epoch no. 42: 0.9999999999990891
[2018-06-08 14:11:27       Optimizer.py:490 -                      _run()]   Epoch no. 43: 0.9999999999992507
[2018-06-08 14:11:27       Optimizer.py:490 -                      _run()]   Epoch no. 44: 0.9999999999993758
[2018-06-08 14:11:28       Optimizer.py:490 -                      _run()]   Epoch no. 45: 0.9999999999994819
[2018-06-08 14:11:29       Optimizer.py:490 -                      _run()]   Epoch no. 46: 0.9999999999995568
[2018-06-08 14:11:29       Optimizer.py:490 -                      _run()]   Epoch no. 47: 0.9999999999996452
[2018-06-08 14:11:30       Optimizer.py:490 -                      _run()]   Epoch no. 48: 0.9999999999996954
[2018-06-08 14:11:30       Optimizer.py:490 -                      _run()]   Epoch no. 49: 0.9999999999997559
[2018-06-08 14:11:31       Optimizer.py:490 -                      _run()]   Epoch no. 50: 0.999999999999761
[2018-06-08 14:11:32       Optimizer.py:490 -                      _run()]   Epoch no. 51: 0.9999999999998228
[2018-06-08 14:11:32       Optimizer.py:490 -                      _run()]   Epoch no. 52: 0.9999999999998447
[2018-06-08 14:11:33       Optimizer.py:490 -                      _run()]   Epoch no. 53: 0.9999999999998663
[2018-06-08 14:11:34       Optimizer.py:490 -                      _run()]   Epoch no. 54: 0.9999999999998873
[2018-06-08 14:11:34       Optimizer.py:490 -                      _run()]   Epoch no. 55: 0.9999999999999056
[2018-06-08 14:11:35       Optimizer.py:490 -                      _run()]   Epoch no. 56: 0.9999999999999161
[2018-06-08 14:11:36       Optimizer.py:490 -                      _run()]   Epoch no. 57: 0.999999999999933
[2018-06-08 14:11:36       Optimizer.py:490 -                      _run()]   Epoch no. 58: 0.9999999999999426
[2018-06-08 14:11:37       Optimizer.py:490 -                      _run()]   Epoch no. 59: 0.9999999999999493
[2018-06-08 14:11:38       Optimizer.py:490 -                      _run()]   Epoch no. 60: 0.9999999999999569
[2018-06-08 14:11:38       Optimizer.py:490 -                      _run()]   Epoch no. 61: 0.9999999999999623
[2018-06-08 14:11:39       Optimizer.py:490 -                      _run()]   Epoch no. 62: 0.9999999999999674
[2018-06-08 14:11:40       Optimizer.py:490 -                      _run()]   Epoch no. 63: 0.999999999999971
[2018-06-08 14:11:40       Optimizer.py:490 -                      _run()]   Epoch no. 64: 0.9999999999999757
[2018-06-08 14:11:41       Optimizer.py:490 -                      _run()]   Epoch no. 65: 0.9999999999999782
[2018-06-08 14:11:42       Optimizer.py:490 -                      _run()]   Epoch no. 66: 0.9999999999999806
[2018-06-08 14:11:42       Optimizer.py:490 -                      _run()]   Epoch no. 67: 0.9999999999999833
[2018-06-08 14:11:43       Optimizer.py:490 -                      _run()]   Epoch no. 68: 0.9999999999999858
[2018-06-08 14:11:43       Optimizer.py:490 -                      _run()]   Epoch no. 69: 0.9999999999999872
[2018-06-08 14:11:44       Optimizer.py:490 -                      _run()]   Epoch no. 70: 0.9999999999999888
[2018-06-08 14:11:45       Optimizer.py:490 -                      _run()]   Epoch no. 71: 0.9999999999999899
[2018-06-08 14:11:45       Optimizer.py:490 -                      _run()]   Epoch no. 72: 0.9999999999999912
[2018-06-08 14:11:46       Optimizer.py:490 -                      _run()]   Epoch no. 73: 0.9999999999999925
[2018-06-08 14:11:47       Optimizer.py:490 -                      _run()]   Epoch no. 74: 0.9999999999999933
[2018-06-08 14:11:47       Optimizer.py:490 -                      _run()]   Epoch no. 75: 0.9999999999999936
[2018-06-08 14:11:48       Optimizer.py:490 -                      _run()]   Epoch no. 76: 0.9999999999999946
[2018-06-08 14:11:48       Optimizer.py:490 -                      _run()]   Epoch no. 77: 0.9999999999999953
[2018-06-08 14:11:49       Optimizer.py:490 -                      _run()]   Epoch no. 78: 0.9999999999999968
[2018-06-08 14:11:50       Optimizer.py:490 -                      _run()]   Epoch no. 79: 0.9999999999999973
[2018-06-08 14:11:50       Optimizer.py:490 -                      _run()]   Epoch no. 80: 0.9999999999999974
[2018-06-08 14:11:51       Optimizer.py:490 -                      _run()]   Epoch no. 81: 0.9999999999999971
[2018-06-08 14:11:51       Optimizer.py:490 -                      _run()]   Epoch no. 82: 0.9999999999999986
[2018-06-08 14:11:52       Optimizer.py:490 -                      _run()]   Epoch no. 83: 0.9999999999999989
[2018-06-08 14:11:53       Optimizer.py:490 -                      _run()]   Epoch no. 84: 0.9999999999999994
[2018-06-08 14:11:53       Optimizer.py:490 -                      _run()]   Epoch no. 85: 0.9999999999999987
[2018-06-08 14:11:54       Optimizer.py:490 -                      _run()]   Epoch no. 86: 0.9999999999999991
[2018-06-08 14:11:55       Optimizer.py:490 -                      _run()]   Epoch no. 87: 0.9999999999999993
[2018-06-08 14:11:55       Optimizer.py:490 -                      _run()]   Epoch no. 88: 0.9999999999999997
[2018-06-08 14:11:56       Optimizer.py:490 -                      _run()]   Epoch no. 89: 0.9999999999999994
[2018-06-08 14:11:56       Optimizer.py:490 -                      _run()]   Epoch no. 90: 0.9999999999999994
[2018-06-08 14:11:57       Optimizer.py:490 -                      _run()]   Epoch no. 91: 0.9999999999999996
[2018-06-08 14:11:58       Optimizer.py:490 -                      _run()]   Epoch no. 92: 1.0
[2018-06-08 14:11:58       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:11:58       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:11:58       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:11:58       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:11:58       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_42.pickle"
[2018-06-08 14:11:58  start_training.py:128 -                      main()] Fidelity obtained: 0.9999999999999996
[2018-06-08 14:12:01  start_training.py: 99 -                      main()] Starting training no.43
[2018-06-08 14:12:01  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 14:12:01    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:12:01    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:12:01    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:12:01    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:12:01           model.py:142 -       _set_initial_values()] Initial parameters values: [ 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.].
[2018-06-08 14:12:01           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:12:01           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:12:01       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:12:01       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:12:01       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:12:01       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:12:01       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:12:01       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:12:01       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:12:01       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:12:01       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:12:01       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:12:05       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:12:06       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9983438539510351
[2018-06-08 14:12:07       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9999995826770625
[2018-06-08 14:12:08       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9999999999992906
[2018-06-08 14:12:08       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999999999999999
[2018-06-08 14:12:09       Optimizer.py:490 -                      _run()]   Epoch no. 4: 1.0
[2018-06-08 14:12:09       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:12:09       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:12:09       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:12:09       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:12:09       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_43.pickle"
[2018-06-08 14:12:09  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:12:12  start_training.py: 99 -                      main()] Starting training no.44
[2018-06-08 14:12:12  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 14:12:12    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:12:12    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:12:12    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:12:12    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:12:12           model.py:142 -       _set_initial_values()] Initial parameters values: [ 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.].
[2018-06-08 14:12:12           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:12:12           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:12:12       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:12:12       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:12:12       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:12:12       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:12:12       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:12:12       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:12:12       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:12:13       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:12:13       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:12:13       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:12:16       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:12:17       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8311797424189993
[2018-06-08 14:12:18       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8730017815945506
[2018-06-08 14:12:18       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.7144318967777967
[2018-06-08 14:12:19       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9157524311613743
[2018-06-08 14:12:20       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.8613888118656507
[2018-06-08 14:12:20       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9603597065688934
[2018-06-08 14:12:21       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9104045018569182
[2018-06-08 14:12:22       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9997562040869371
[2018-06-08 14:12:23       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999944370643545
[2018-06-08 14:12:23       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999998577770913
[2018-06-08 14:12:24       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999870904525
[2018-06-08 14:12:24       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999999988175494
[2018-06-08 14:12:25       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999999332472
[2018-06-08 14:12:26       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999999918301
[2018-06-08 14:12:26       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.99999999999924
[2018-06-08 14:12:27       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999999999136
[2018-06-08 14:12:28       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999999999908
[2018-06-08 14:12:28       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999999999994
[2018-06-08 14:12:29       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999999999997
[2018-06-08 14:12:30       Optimizer.py:490 -                      _run()]   Epoch no. 19: 1.0
[2018-06-08 14:12:30       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:12:30       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:12:30       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:12:30       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:12:30       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_44.pickle"
[2018-06-08 14:12:30  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:12:32  start_training.py: 99 -                      main()] Starting training no.45
[2018-06-08 14:12:32  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 14:12:32    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:12:32    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:12:32    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:12:32    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:12:32           model.py:142 -       _set_initial_values()] Initial parameters values: [ 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.].
[2018-06-08 14:12:32           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:12:32           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:12:32       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:12:32       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:12:32       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:12:32       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:12:32       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:12:32       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:12:32       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:12:32       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:12:32       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:12:32       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:12:36       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:12:37       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9734785410082176
[2018-06-08 14:12:38       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9991194010356099
[2018-06-08 14:12:39       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9999999439882467
[2018-06-08 14:12:40       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.999999999601918
[2018-06-08 14:12:41       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999998572
[2018-06-08 14:12:41       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999999999
[2018-06-08 14:12:42       Optimizer.py:490 -                      _run()]   Epoch no. 6: 1.0
[2018-06-08 14:12:42       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:12:42       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:12:42       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:12:42       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:12:42       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_45.pickle"
[2018-06-08 14:12:42  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:12:44  start_training.py: 99 -                      main()] Starting training no.46
[2018-06-08 14:12:44  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 14:12:44    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:12:44    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:12:44    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:12:44    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:12:44           model.py:142 -       _set_initial_values()] Initial parameters values: [ 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.].
[2018-06-08 14:12:44           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:12:44           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:12:44       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:12:44       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:12:44       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:12:44       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:12:44       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:12:44       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:12:44       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:12:44       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:12:44       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:12:44       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:12:48       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:12:49       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9056414479202489
[2018-06-08 14:12:49       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9995736834079287
[2018-06-08 14:12:50       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9999993044496466
[2018-06-08 14:12:51       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999999704494175
[2018-06-08 14:12:51       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.999999999718748
[2018-06-08 14:12:52       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999845751
[2018-06-08 14:12:53       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999999999994549
[2018-06-08 14:12:53       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999999656
[2018-06-08 14:12:54       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999999999999984
[2018-06-08 14:12:55       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999999999999
[2018-06-08 14:12:55       Optimizer.py:490 -                      _run()]   Epoch no. 10: 1.0
[2018-06-08 14:12:55       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:12:55       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:12:55       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:12:55       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:12:55       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_46.pickle"
[2018-06-08 14:12:55  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:12:57  start_training.py: 99 -                      main()] Starting training no.47
[2018-06-08 14:12:57  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 14:12:57    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:12:57    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:12:57    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:12:57    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:12:57           model.py:142 -       _set_initial_values()] Initial parameters values: [ 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.].
[2018-06-08 14:12:57           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:12:57           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:12:57       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:12:57       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:12:57       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:12:57       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:12:57       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:12:57       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:12:57       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:12:57       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:12:57       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:12:58       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:13:01       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:13:02       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.7625813408431458
[2018-06-08 14:13:02       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.8279402603409008
[2018-06-08 14:13:03       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9999154117182977
[2018-06-08 14:13:04       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999997411665713
[2018-06-08 14:13:04       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999996574493
[2018-06-08 14:13:05       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999937242
[2018-06-08 14:13:06       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.999999999999838
[2018-06-08 14:13:06       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999999999999966
[2018-06-08 14:13:07       Optimizer.py:490 -                      _run()]   Epoch no. 8: 1.0
[2018-06-08 14:13:07       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:13:07       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:13:07       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:13:07       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:13:07       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_47.pickle"
[2018-06-08 14:13:07  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000002
[2018-06-08 14:13:09  start_training.py: 99 -                      main()] Starting training no.48
[2018-06-08 14:13:09  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 14:13:09    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:13:09    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:13:09    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:13:09    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:13:09           model.py:142 -       _set_initial_values()] Initial parameters values: [ 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.].
[2018-06-08 14:13:09           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:13:09           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:13:09       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:13:09       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:13:09       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:13:09       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:13:09       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:13:09       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:13:09       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:13:09       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:13:09       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:13:09       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:13:13       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:13:14       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.6389178975096135
[2018-06-08 14:13:15       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.7756381436142564
[2018-06-08 14:13:15       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9727875616082275
[2018-06-08 14:13:16       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9992693516845121
[2018-06-08 14:13:17       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9962484609259031
[2018-06-08 14:13:17       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999710038101209
[2018-06-08 14:13:18       Optimizer.py:490 -                      _run()]   Epoch no. 6: 0.9999880564538809
[2018-06-08 14:13:19       Optimizer.py:490 -                      _run()]   Epoch no. 7: 0.9999985515760256
[2018-06-08 14:13:19       Optimizer.py:490 -                      _run()]   Epoch no. 8: 0.9999995299692064
[2018-06-08 14:13:20       Optimizer.py:490 -                      _run()]   Epoch no. 9: 0.9999999587848781
[2018-06-08 14:13:21       Optimizer.py:490 -                      _run()]   Epoch no. 10: 0.9999999862245178
[2018-06-08 14:13:21       Optimizer.py:490 -                      _run()]   Epoch no. 11: 0.9999999953931326
[2018-06-08 14:13:22       Optimizer.py:490 -                      _run()]   Epoch no. 12: 0.9999999986892538
[2018-06-08 14:13:23       Optimizer.py:490 -                      _run()]   Epoch no. 13: 0.9999999992699076
[2018-06-08 14:13:23       Optimizer.py:490 -                      _run()]   Epoch no. 14: 0.9999999998019585
[2018-06-08 14:13:24       Optimizer.py:490 -                      _run()]   Epoch no. 15: 0.9999999999176772
[2018-06-08 14:13:25       Optimizer.py:490 -                      _run()]   Epoch no. 16: 0.9999999999538177
[2018-06-08 14:13:25       Optimizer.py:490 -                      _run()]   Epoch no. 17: 0.9999999999805101
[2018-06-08 14:13:26       Optimizer.py:490 -                      _run()]   Epoch no. 18: 0.9999999999937689
[2018-06-08 14:13:27       Optimizer.py:490 -                      _run()]   Epoch no. 19: 0.9999999999955199
[2018-06-08 14:13:28       Optimizer.py:490 -                      _run()]   Epoch no. 20: 0.9999999999986221
[2018-06-08 14:13:28       Optimizer.py:490 -                      _run()]   Epoch no. 21: 0.9999999999992124
[2018-06-08 14:13:29       Optimizer.py:490 -                      _run()]   Epoch no. 22: 0.9999999999996575
[2018-06-08 14:13:30       Optimizer.py:490 -                      _run()]   Epoch no. 23: 0.9999999999997852
[2018-06-08 14:13:30       Optimizer.py:490 -                      _run()]   Epoch no. 24: 0.9999999999998848
[2018-06-08 14:13:31       Optimizer.py:490 -                      _run()]   Epoch no. 25: 0.9999999999999492
[2018-06-08 14:13:31       Optimizer.py:490 -                      _run()]   Epoch no. 26: 0.9999999999999697
[2018-06-08 14:13:32       Optimizer.py:490 -                      _run()]   Epoch no. 27: 0.9999999999999837
[2018-06-08 14:13:33       Optimizer.py:490 -                      _run()]   Epoch no. 28: 0.999999999999993
[2018-06-08 14:13:33       Optimizer.py:490 -                      _run()]   Epoch no. 29: 0.9999999999999971
[2018-06-08 14:13:34       Optimizer.py:490 -                      _run()]   Epoch no. 30: 0.9999999999999989
[2018-06-08 14:13:34       Optimizer.py:490 -                      _run()]   Epoch no. 31: 0.9999999999999993
[2018-06-08 14:13:35       Optimizer.py:490 -                      _run()]   Epoch no. 32: 0.9999999999999996
[2018-06-08 14:13:36       Optimizer.py:490 -                      _run()]   Epoch no. 33: 0.9999999999999997
[2018-06-08 14:13:36       Optimizer.py:490 -                      _run()]   Epoch no. 34: 0.9999999999999999
[2018-06-08 14:13:37       Optimizer.py:490 -                      _run()]   Epoch no. 35: 0.9999999999999999
[2018-06-08 14:13:38       Optimizer.py:490 -                      _run()]   Epoch no. 36: 1.0
[2018-06-08 14:13:38       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:13:38       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:13:38       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:13:38       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:13:38       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_48.pickle"
[2018-06-08 14:13:38  start_training.py:128 -                      main()] Fidelity obtained: 1.0
[2018-06-08 14:13:39  start_training.py: 99 -                      main()] Starting training no.49
[2018-06-08 14:13:39  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 14:13:39    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:13:39    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:13:39    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:13:39    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:13:40           model.py:142 -       _set_initial_values()] Initial parameters values: [ 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.].
[2018-06-08 14:13:40           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:13:40           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:13:40       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:13:40       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:13:40       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:13:40       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:13:40       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:13:40       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:13:40       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:13:40       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:13:40       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:13:40       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:13:43       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:13:44       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.8883730754954893
[2018-06-08 14:13:45       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9925212088376497
[2018-06-08 14:13:45       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9999999987310908
[2018-06-08 14:13:46       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999999999999999
[2018-06-08 14:13:47       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999999999999
[2018-06-08 14:13:47       Optimizer.py:490 -                      _run()]   Epoch no. 5: 1.0
[2018-06-08 14:13:47       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:13:47       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:13:47       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:13:47       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:13:47       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_49.pickle"
[2018-06-08 14:13:47  start_training.py:128 -                      main()] Fidelity obtained: 1.0000000000000002
[2018-06-08 14:13:49  start_training.py: 99 -                      main()] Starting training no.50
[2018-06-08 14:13:49  start_training.py:100 -                      main()] Initial values: 4.
[2018-06-08 14:13:49    QubitNetwork.py: 99 -         _parse_sympy_expr()] Parsing from sympy expression
[2018-06-08 14:13:49    QubitNetwork.py:102 -         _parse_sympy_expr()]   Detected sympy.Matrix object.
[2018-06-08 14:13:49    QubitNetwork.py:107 -         _parse_sympy_expr()]   No `free_parameters_order` was given, generating one automatically.
[2018-06-08 14:13:49    QubitNetwork.py:112 -         _parse_sympy_expr()]   Deriving matrices from sympy expression..
[2018-06-08 14:13:49           model.py:142 -       _set_initial_values()] Initial parameters values: [ 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.].
[2018-06-08 14:13:50           model.py:376 -                  __init__()] Number of system qubits: 3.
[2018-06-08 14:13:50           model.py:379 -                  __init__()] Number of ancillary qubits: 0.
[2018-06-08 14:13:50       Optimizer.py:168 -                  __init__()] Training SGD method: momentum.
[2018-06-08 14:13:50       Optimizer.py:170 -                  __init__()] Initial learning rate: 1.
[2018-06-08 14:13:50       Optimizer.py:171 -                  __init__()] Decay rate: 0.1.
[2018-06-08 14:13:50       Optimizer.py:172 -                  __init__()] Training dataset size: 200.
[2018-06-08 14:13:50       Optimizer.py:173 -                  __init__()] Test dataset size: 100.
[2018-06-08 14:13:50       Optimizer.py:174 -                  __init__()] Maximum number of epochs: 100.
[2018-06-08 14:13:50       Optimizer.py:175 -                  __init__()] Batch size: 2.
[2018-06-08 14:13:50       Optimizer.py:465 -                      _run()] Starting training phase.
[2018-06-08 14:13:50       Optimizer.py:467 -                      _run()] Generating batch of testing states.
[2018-06-08 14:13:50       Optimizer.py:443 -            _compile_model()] Model compilation - Start
[2018-06-08 14:13:54       Optimizer.py:462 -            _compile_model()] Model compilation - Finished
[2018-06-08 14:13:55       Optimizer.py:490 -                      _run()]   Epoch no. 0: 0.9260174059177799
[2018-06-08 14:13:56       Optimizer.py:490 -                      _run()]   Epoch no. 1: 0.9231248585161635
[2018-06-08 14:13:56       Optimizer.py:490 -                      _run()]   Epoch no. 2: 0.9832117494493815
[2018-06-08 14:13:57       Optimizer.py:490 -                      _run()]   Epoch no. 3: 0.9999581857030573
[2018-06-08 14:13:57       Optimizer.py:490 -                      _run()]   Epoch no. 4: 0.9999999946650204
[2018-06-08 14:13:58       Optimizer.py:490 -                      _run()]   Epoch no. 5: 0.9999999999989714
[2018-06-08 14:13:59       Optimizer.py:490 -                      _run()]   Epoch no. 6: 1.0000000000000002
[2018-06-08 14:13:59       Optimizer.py:490 -                      _run()]   Epoch no. 7: 1.0
[2018-06-08 14:13:59       Optimizer.py:493 -                      _run()] Fidelity 1 obtained, stopping.
[2018-06-08 14:13:59       Optimizer.py:316 -              save_results()] Saving results..
[2018-06-08 14:13:59       Optimizer.py:323 -              save_results()]     Building `net_data` dictionary..
[2018-06-08 14:13:59       Optimizer.py:330 -              save_results()]     Building `optimization_data` dictionary..
[2018-06-08 14:13:59       Optimizer.py:347 -              save_results()]     Successfully saved to "/adsusers/linnocenti01/Documents/research/quantum-gate-learning/InnocentiBanchi2018/quantum-gate-learning-python-code/data/nets/Fredkin/fredkin_noancillae_diagonalReducedModel_initvaluesRandom/training_no_50.pickle"
[2018-06-08 14:13:59  start_training.py:128 -                      main()] Fidelity obtained: 0.9999999999999996
[2018-06-08 14:13:59  start_training.py:142 -                  <module>()] Training finished. Deleting placeholder file.
